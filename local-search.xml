<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>2022 年终总结：记清华硕士的秋招之年</title>
    <link href="/2022-annual-summary/"/>
    <url>/2022-annual-summary/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>忙忙碌碌又是一年，终于到了 2022 年底。去年第一次写年终总结受到了不少的关注，我在这一年里也时常会重读自己的 2021 年终总结来鞭策自己。今年由于家里的特殊原因需要在医院过年，时间比较仓促，勉强抽出了一天的时间来简短写写年终总结。一方面是给 2022 年的自己一个交代，另一方面也是给 2023 年的自己一个警醒。希望我的经历和感悟能给大家一些启发。</p><p>首先依然是自我介绍环节，我叫谭新宇，清华本硕，现在清华大学软件学院 Apache IoTDB 组就读研三，师从王建民/黄向东老师，我对共识算法，分布式存储系统，时序数据库和分布式事务都比较感兴趣。</p><p>接着简单介绍一下我们组的工作：Apache IoTDB（物联网数据库）是一体化收集、存储、管理与分析物联网时序数据的软件系统。Apache IoTDB 采用轻量式架构，具有高性能和丰富的功能，并与 Apache Hadoop、Spark 和 Flink 等进行了深度集成，可以满足工业物联网领域的海量数据存储、高速数据读取和复杂数据分析需求。</p><h2 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h2><p>介绍完背景之后，在这里回顾下 2022 年的经历。</p><p>2 月，Apache IoTDB 社区的新分布式架构设计正在整个社区的努力下如火如荼的进行着，社区针对分布式时序数据库架构的方方面面都进行了广泛的调研和讨论，我也很幸运地参加了若干模块的调研设计，收获良多。对于分区方式，我们结合一致性哈希和查找表的优缺点，选择了一个更符合时序场景 trade-off 的分区方式，既不引入较大的存储成本，又具备一定的负载均衡灵活性，而且还留有足够的扩展性。对于扩展能力，我们将时序元数据与时序数据等同来看都做了多分片，使得集群拥有很强的横向扩展能力。对于查询引擎，我们调研了 Trino/Impala/Doris 等系统的 MPP 框架，又基于我们对时序场景的理解设计出了针对时序场景特殊优化的 MPP 框架和 Pipeline 执行引擎。对于共识算法，我们观察到不同的业务对于共识算法一致性和性能之间的 trade-off 有不一样的倾向，开始思考并着手设计一个能够支持不同共识算法的通用共识框架。</p><p>2 月下旬，在为 Talent Plan 社区提交若干代码修复并做了 3 次有关共识算法和分布式事务的公开分享之后，我荣幸的被 Talent Plan 社区接纳为了 mentor，期待以后能够继续和志同道合的小伙伴在 Talent Plan 社区沟通交流。</p><p>3 月，需要毕设开题的我结合 Apache IoTDB 新分布式架构对通用共识框架的需求，开始调研学术界和工业界在通用共识框架领域的相关工作。在调研中，我发现了 Facebook 的 Delos 框架不仅支持在一套接口下实现不同的共识算法，还能够支持生产环境动态变更共识算法，他们的工作也得到了学术界的认可，成为了 2020 OSDI 的 Best Paper。沿着他们的思路，在摒弃了当前 ROI 收益较低的生产环境动态变更共识算法后，我便开始着手设计通用共识框架的接口，该框架不仅需要先支持强一致性的 Raft 算法和弱一致性的异步复制共识算法，还需要为未来更好更丰富的共识算法接入留下扩展性（例如 2021 FAST 的 Best Paper 就是基于异步复制的思路在提升写性能的同时又在读时添加了一些约束，从而提供了跨客户端单调读一致性，基于 ZK 实现后相比 ZK 性能能够提升 1.8-3.3 倍）。由于这个思路在学术界和工业界都相对新颖，我的开题便较为顺利的被通过了。</p><p>3-4 月，由于毕设开题读了一大堆论文状态比较好，我开始在知乎上回答自己感兴趣领域的很多问题，并幸运的在最开始就得到了很多赞，这些对我的认可又成为了我进一步在知乎上学习和活跃的动力，从而形成了一个正反馈效应。正如去年年终总结的感悟中所提到的，这种正向反馈对于我自己的激励作用是非常大的。现在回过头来看，那段时间尽管我也有一些输出得到了很多赞，但收获最大的还是在此过程中阅读了知乎上分布式系统领域非常多的优秀回答，学到了很多技术知识，了解了很多思考维度。</p><p>4 月，忙完毕设开题的我开始面试暑期实习，尽管八股和项目由于日常的积累都没有什么问题，但由于实在提不起兴趣和动力刷题，所以在面试过程中还是多少有些磕磕绊绊。幸运的是最后投的几家公司除了微软之外总体都面的不错，最后思考再三后还是选择去 PingCAP 实习。一方面是 PingCAP 的三轮面试官（赵磊老师，徐锐老师，金鹏老师）给我的面试体验都非常好，另一方面则是我一直对 PingCAP 的很多体系（例如工程服务体系，架构演进体系，开源体系等等）非常敬佩和好奇，想要借此机会去学习感悟。</p><p>5-6 月，我专心投入到了 Apache IoTDB 新分布式框架的实现中。最主要的工作便是通用共识框架，这期间一方面抽象了其对上对下的通用接口，另一方面则是为其支持了若干共识算法。对于强一致性共识算法，我调研了 Java 实现的若干 Raft 库的成熟度，并最终得出只有 SofaJRaft 和 Apache Ratis 可以使用的结论。基于此结论，我和子阳探索了 Apache Ratis 的实现并将其集成到了我们的共识框架中，这使得 Apache IoTDB 的新分布式架构具备了强一致性的能力（这半年以来，子阳在 Apache Ratis 的稳定性和性能优化上投入了大量的精力，令人开心的是目前他已经得到了 Apache Ratis 社区的认可，成为了 Committer，可以说是双赢了）。对于弱一致性共识算法，我们结合时序场景写写冲突极少的业务特点，设计并实现了基于异步复制思路的弱一致性共识算法 IoTConsensus。我和乔老师，恺丰，海铭，金瑞，洪胤，厚亮和珍姐都参与了 IoTConsensus 的设计实现与迭代测试。IoTConsensus 做了非常多的工程优化，包括但不限于 Batching，Pipeline，Thrift AsyncClient/AsyncServer 等等，所以流程非常复杂。虽然实现和 debug 的过程非常艰苦，但我们在异步编程，内存控制，可观测性，debug 技巧等方面都有了显著的进步，可以说是既痛苦又有收获吧。此外，为了兼容统一的共识框架，避免单副本时共识框架的额外开销，我们还专门针对单副本的场景（只需要 scale out 而不需要 high availability 的场景）设计了极为轻量的 SimpleConsensus，避免出现 RaftLog 和存储引擎 WAL 双写的现象出现。在未来，我们还计划为 Apache IoTDB 的共识框架加入更多的共识算法实现，例如 SofaJRaft 和我们组今年中的 ICDE NB-Raft 等等。我非常期待 Apache IoTDB 共识框架的文档，功能，性能，稳定性和正确性等等都能够迅速成熟，甚至可以成为大家未来使用通用共识框架的范式，这样如果业务上对共识算法一致性和性能的 trade-off 有不同的需求，便可以直接使用我们已经封装好的共识框架而不用再去造轮子了。这里也非常欢迎对共识算法感兴趣的同学一起参与进来~</p><p>7-10 月，我在 PingCAP 进行了全职实习。在 PingCAP 的暑期实习是我个人体验最好的一次实习。在技术上，我不仅可以去学习公司内部海量的技术积累（Rust，分布式数据库，TiKV，调优培训等）和流程规范（如何建立可扩展的工程服务体系和可持续的架构演进体系 -&gt; 可观测性 + 分级 Support &amp;&amp; 业务场景持续打磨），也可以系统学习 TiKV 事务引擎演进的历史（乐观事务-&gt;悲观事务-&gt;大事务-&gt;Async Commit/1PC-&gt; 悲观事务内存悲观锁等）来培养自己的产品思维，最后还可以基于这些成长去做一些深入的探索并取得了不错的成果。在生活上，同事们会非常耐心友善地回答我的种种问题，工程经验十分丰富的 mentor 徐锐老师也花了非常多的时间和我 one-one 沟通我的种种疑问来帮助我快速成长（技术问题。如何平衡技术驱动和业务驱动？如何评估架构演进和工程服务的 ROI 等等），金鹏老师和 HRBP 也会和我定期沟通最近的工作进展。PingCAP 是国内开源数据库和开源社区的佼佼者，非常推荐大家有机会前去实习，一定会不虚此行~</p><p>8-10 月，我海投了很多感兴趣的数据库团队，并以没有任何职业背景的身份参加了 41 场秋招面试。虽然非常忙碌，但这些面试尤其是终面加面环节对我技术的成长和产品思维的提升有很大的帮助。在面试过程中我也有幸认识了很多大佬，并幸运地拿到了不少 offer，在这里表达对相关面试官和 HR 的真诚感谢。</p><p>10 月中旬，我被评选为了 2022 软件学院科研科创年度人物，这令我诚惶诚恐。在我看来，这个奖项更适合论文发到手软的大佬。询问之后发现现在的评审规则中也包含了开源贡献，所以现在做系统做工程的同学也可以得到学院的认可。在这里也真诚感谢学院对我的认可。</p><p>10 月下旬，我和祥威洪胤子阳参加了 2022 TiDB Hackathon，并最终拿到了产品组的最佳校园奖。在这次 Hackathon 中，从技术上我们为 TiKV 做了 Parallel Apply 的优化 Demo；从产品上我们在高并发批量写入热点场景会有不错的收益。我们模拟了银行清算结算等跑批业务的极致情况，在 60 并发下，不同 BatchSize 的批量写入性能提升 89.4%~119.0%。TiKV CPU 利用率从 700% 左右提升至 1500% 左右。我们也尝试了通用的批量导入热点场景，对于 TPCC prepare，在 1024 BatchSize 下，不同并发批量写入性能提升 29.8%~36.0%，TiKV CPU 利用率也从 750% 左右提升至 1000% 左右。通过这次 Hackathon，结合 OB 4.0 版本自适应日志流的设计，我们对 Raft 和 Multi-Paxos 的异同有了更深刻的理解。总体而看，一个系统的架构设计就是要在关键模块的各种 trade-off 中做出纠结的选择，并且一旦做出了某个选择，就需要基于这个选择更进一步做非常多的产品化工作和优化打磨来提升这些技术对于用户的实际价值。例如，TiDB 选了 TSO 的时间戳获取方案并不代表就不能服务跨数据中心场景了，其也做了 Local/Global TSO 的产品化工作来满足部分用户场景的跨数据中心需求。CRDB 用了 HLC 之后并不仅仅体现在获取事务时间戳更快，其至少还基于 HLC 在 Strong/Stale Follower Read 这一块做了许多工作来减少跨域流量从而降低成本。对于 OB，其选择了 Multi-Paxos 而不是 Raft，并且更进一步在 4.0 架构中提出了单机分布式一体化架构来解决其他数据库很难彻底解决的写热点缓解，大事务支持和 1PC 比例增大等难点。当然，这些技术和产品化的工作短期内很难形成事实标准，也都能够在各自的用户场景产生价值，至于孰优孰劣就很难客观判断了。</p><p>11 月，我手上的秋招 offer 陆陆续续开奖了，这期间涉及到了非常复杂的心理变化。有期待，有失望，有惊喜，有反思，有迷茫，有透彻。对于最终选择去哪里，我纠结了许久，请教了很多朋友，前辈，同学，师兄，父母和导师的意见。其实选择哪条路都不会太差，主要还是需要剖析自己更喜欢怎样的工作方式，并且说服自己一旦做出选择后就不再患得患失。此外王老师东哥乔老师都对我的就业方向和未来发展路径给予了中肯的建议，最终我选择了 Apache IoTDB 的商业化公司天谋科技继续做 IoTDB。我非常感谢研究生期间 IoTDB 这个大平台对我的帮助，也希望自己未来能够继续在这个大平台发光发热。</p><p>12 月，Apache IoTDB 的 1.0 版本发布了，这次新版本凝聚了整个社区的智慧和力量，标志着 Apache IoTDB 从此彻底拥有分布式，为后续产品快速发展奠定了良好基础。这次分布式 1.0 架构的发布也是促使我决定留下的重要原因之一，因为我觉得这个架构有太多可以做的工作可以去做，一些积累的技术宅已经还清，我相信未来 Apache IoTDB 一定能够在工业物联网的时序场景大放异彩。想通以后，我也和洪胤子阳湘鹏组成了系统优化小组，不断扩大我们的 scope 去和 IoTDB 一块成长了~</p><p>今年我在 Apache IoTDB 社区 Review 了 187 个 PR，提交并被合并了 48 个 PR。今年的工作有很多新颖的东西，希望明年能够继续保持下去。</p><p>今年我在知乎上写了几十篇博客和回答，粉丝数和点赞数相比去年同期有了接近 10 倍的增长。Github 上的 Follower 数和个人仓库 Star 数也有了 6 倍多的增长。希望自己明年还能继续坚持输出有价值有意思的知识。</p><p>今年我看了权谋剧的巅峰之作《大明王朝 1566》，尽管剧中演绎的是封建社会，但其中一些社会运行的本质规律放到今天也依然适用，我自认为受益良多，非常推荐大家去看。此外我也读了 IT 人的必读书籍《浪潮之巅》，了解了信息革命以来很多著名公司的兴衰更迭及背后的哲学原因。天下大势，浩浩汤汤，顺之者昌，逆之者亡。不论是公司，组织还是个人，自己的努力不可或缺，但只有抓准大势站上浪潮之巅，才有可能干一番大事。</p><h2 id="一些感悟"><a href="#一些感悟" class="headerlink" title="一些感悟"></a>一些感悟</h2><p>介绍完了 2022 年的经历，在这里谈谈自己这一年的新感悟，这些感悟不一定适用于每个人，但都是我个人在今年得到成长的诀窍。</p><h3 id="没有不写-bug-的人，但要成为追求不写-bug-的人"><a href="#没有不写-bug-的人，但要成为追求不写-bug-的人" class="headerlink" title="没有不写 bug 的人，但要成为追求不写 bug 的人"></a>没有不写 bug 的人，但要成为追求不写 bug 的人</h3><p>这一年在日常的开发过程中修复了无数的 bug，一些是陈年老 bug，一些则是自己在开发过程中引入的新 bug。这期间我一直在思考为什么会有这么多的 bug？什么时候能够修复完所有的 bug？现在我有了更明确的感悟：</p><p>对于一个 bug，从设计-&gt;编码-&gt;UT-&gt;IT-&gt;压力测试-&gt;混沌测试-&gt;发版测试-&gt;用户 POC 环境-&gt;用户生产环境这套全链路的流程中，越晚被发现，则修复的成本就越高。世界上没有不写 bug 的人，也不存在没有 bug 的系统，我们需要尊重这一客观规律。出现 bug 不可怕，但不对其进行反思改进就非常可怕了。虽然没有不写 bug 的人，但要成为追求不写 bug 的人，因为只有具备了这个追求，才会在日常的开发过程中注重 bug 产生原因的积累，并通过种种技术手段来规避 bug 的产生。正是因为对 bug 的反思，学术界和工业界才产生了很多对系统稳定性至关重要的工作（形式化验证，确定性模拟器，混沌测试，持续集成等等）。一个工程师的成长必然伴随着对种种异常情况的考虑，知识边界被拓宽后自然写出 bug 的概率就会越来越低。</p><p>新的系统，新的模块，新的引擎，新的算法需要一段时间的稳定性打磨，没有用户去用就很难成熟，但如果用户去用了，团队也一定要利用好这次机会，让产品的稳定性和工程师的能力一起成长，进入一个正反馈循环才有可能让产品越来越好。</p><h3 id="性能优化与代码可维护性需要有一个平衡"><a href="#性能优化与代码可维护性需要有一个平衡" class="headerlink" title="性能优化与代码可维护性需要有一个平衡"></a>性能优化与代码可维护性需要有一个平衡</h3><p>一般而言，复杂的性能优化往往会导致代码维护成本的上升。例如事件驱动的并发编程模型具有更高的自主性，性能上限相比完全被 Runtime 接管的协程可能会高一点，但带来的回调地狱问题又可能会大幅增大代码复杂度，导致代码维护成本大幅上升。从全局的 ROI 评估来看，这样的工作不一定收益很高。</p><p>今年我在开发 IoTConsensus 过程中就有点过于追求性能优化，加了一堆异步逻辑和工程优化，虽然优化完后性能还不错，但这种代码上的复杂度也使得大家在 debug 时非常痛苦，新人也比较难一下子看懂主要逻辑，只能靠进一步完善文档细节并做代码走读才有可能让新人逐渐上手。</p><p>在未来的工作中，我也会吸取这次的教训更关注性能优化与代码可维护性之间的平衡。</p><h3 id="有太多能力可以提升，不要只看到技术"><a href="#有太多能力可以提升，不要只看到技术" class="headerlink" title="有太多能力可以提升，不要只看到技术"></a>有太多能力可以提升，不要只看到技术</h3><p>今年在实习和秋招面试过程中有幸和非常多的技术大佬有过交流，在他们身上技术能力只是一个值得学习的维度，其他维度的能力还包括管理，演讲，分享，社交，营销，商业感知，为人处世等等。</p><p>要想进一步实现职场的抱负，综合能力是十分重要的。总之，有太多领域的太多能力可以去提升，技术只是其中比较重要的方面之一，最好不要仅仅把自己拘泥在技术上。</p><p>不断扩展自己的 scope，锻炼培养自己的综合能力，便能在单位时间内获得更大的成长拥有更丰富的阅历，从而可能在机遇出现时顶住压力抓住机会。</p><h3 id="技术是满足业务的手段，一定要带有产品思维"><a href="#技术是满足业务的手段，一定要带有产品思维" class="headerlink" title="技术是满足业务的手段，一定要带有产品思维"></a>技术是满足业务的手段，一定要带有产品思维</h3><p>技术最终是要为业务服务的。没有业务侧的需求，技术最终也难以发挥实际价值走向成熟。</p><p>在做日常的功能开发和性能优化时，最好能够带着产品思维去思考问题：自己所做的工作在整个产品中处于怎样的一个位置？做了这个工作之后整个产品会有什么样的不同？一旦能够培养出来这种端到端的产品思维，自己也会更明确工作目标并更有动力去做事成长。</p><h3 id="针对不同硬件环境和业务负载的排列组合，有太多有意思的工作可以去做"><a href="#针对不同硬件环境和业务负载的排列组合，有太多有意思的工作可以去做" class="headerlink" title="针对不同硬件环境和业务负载的排列组合，有太多有意思的工作可以去做"></a>针对不同硬件环境和业务负载的排列组合，有太多有意思的工作可以去做</h3><p>刚入门数据库的时候一直比较好奇，像 Oracle 这样的数据库厂商是如何每年都有那么多新的工作可以做？为什么我就想不到做那些呢？</p><p>通过在 Apache IoTDB 实验室的成长和在 PingCAP 的实习，我理解了业务驱动对于产品的意义。只要有用户和业务的支持，就会有源源不断的需求出来。对于数据库系统而言，在不同的硬件环境和业务负载下，有太多的功能和性能优化可以去做，几乎不存在技术上没有事情可做的情况。当然，任何组织任何个人所能调度的资源都是有限的，如何评估当前所有工作的 ROI，如何在有限的资源上持续的做紧急重要且正确的事，也是产品成败存亡的关键。</p><h3 id="好的系统需要在天花板高的架构设计上进行日复一日的持续打磨"><a href="#好的系统需要在天花板高的架构设计上进行日复一日的持续打磨" class="headerlink" title="好的系统需要在天花板高的架构设计上进行日复一日的持续打磨"></a>好的系统需要在天花板高的架构设计上进行日复一日的持续打磨</h3><p>OceanBase 的杨传辉老师提过一个观点：每个系统设计时都需要考虑架构、稳定性和性能，这三者之间的关系是什么？一个经典的规律是“把稳定的系统做高效，远比把高效的系统做稳定更容易”。最难的是从 0 到 1 把系统做稳定。有了稳定的系统，接下来逐步优化性能往往会比较顺利，直到遇到系统架构的性能天花板。因此，系统架构设计之前，首先要考虑清楚系统的目标和性能天花板，接着基于正确的架构把系统做稳定，最后优化性能。</p><p>在 PingCAP 的暑期实习期间我很明显的一个感受就是，TiDB 的可观测性做得非常好，同事们都比较明确特定业务场景下当前 TiDB 的短板在哪里，也明白自己工作的端到端价值，从而能够持续打磨 TiDB 在特定业务场景下的性能。大家的工作并行汇聚起来便能够促使 TiDB 每个版本都能够在很多业务场景下有不错的进步。</p><p>在现在的我看来，Oracle 最有价值的东西其实是在当前的市场规模下能够接触到最多最复杂的业务场景，从而能够持续的对系统进行打磨，这是其他任何单机数据库都没法做到的，自然也就无法在单机数据库领域打败 Oracle 了。</p><p>在系统初期，调研设计出一个性能天花板高的系统架构非常重要。在系统搭建完成基本稳定之后，在业务场景下进行持续的打磨就更为重要了。比如 Apache IoTDB 1.0 的分布式架构性能天花板我自认为就很高，目前性能也基本打磨到了和 0.13 版本一致的地步，下一步就是在特定业务场景下进行持续打磨做稳定性和性能的进一步提升了。</p><h3 id="提出问题比解决问题更为重要"><a href="#提出问题比解决问题更为重要" class="headerlink" title="提出问题比解决问题更为重要"></a>提出问题比解决问题更为重要</h3><p>好奇心是人类进化创新的驱动力。发现当前存在的问题，才有可能去进一步改进解决。爱因斯坦早在《物理学的进化》中就说过：”提出一个问题比解决一个问题更为重要。 因为解决一个问题也许是一个数学上或实验上的技巧，而提出新的问题，新的可能性，从新的方向看旧问题，则需要创造性的想象力，而且标志着科学的真正进步”。</p><p>对于数据库系统，在特定硬件环境和业务负载下，性能瓶颈到底在何处？若想优化当前最大的性能瓶颈，它到底是一个工程问题还是学术问题？如果是工程问题，需要投入多少资源去完成？会有多少收益？如果是学术问题，它的 trade-off 到底是什么？有什么更符合当前业务场景的可能性吗？一旦有了这样思考问题的方式，就会发现技术上其实存在很多可能。</p><h3 id="个人的努力不可或缺，但平台和机遇往往更为重要"><a href="#个人的努力不可或缺，但平台和机遇往往更为重要" class="headerlink" title="个人的努力不可或缺，但平台和机遇往往更为重要"></a>个人的努力不可或缺，但平台和机遇往往更为重要</h3><p>在看了《大明王朝 1566》 和《浪潮之巅》后，越发认识到时势造英雄的客观规律。个人的努力能够决定个人的发展下限，但平台和机遇才能够决定个人的发展上限。很多时候，玄而又玄的天下大势和因缘际会反而可能会在若干年后造就一番佳话。</p><p>就目前而言，认识到平台的重要性，学会顺势而为，在职责范围内乐于沟通踏实做事，可能是个人职业生涯短期的最优解了吧。</p><h3 id="没有绝对的成功，以个人最舒服的姿态和最擅长的方式去活一生就已足够"><a href="#没有绝对的成功，以个人最舒服的姿态和最擅长的方式去活一生就已足够" class="headerlink" title="没有绝对的成功，以个人最舒服的姿态和最擅长的方式去活一生就已足够"></a>没有绝对的成功，以个人最舒服的姿态和最擅长的方式去活一生就已足够</h3><p>对于个人而言，绝对的成功很难定义，技术和商业也仅仅是很小的一部分。在认识到时势造英雄的客观规律后，我愈发觉得精神上的富足对于一个人一生的幸福最为重要。有一句话叫做”但行好事，莫问前程”，没有必要去和其他人比来比去，任何人都是比上不足比下有余，能够以个人最舒服的姿态和最擅长的方式去活一生就已足够，剩下的交给命运即可。</p><h3 id="多站在别人的角度思考问题"><a href="#多站在别人的角度思考问题" class="headerlink" title="多站在别人的角度思考问题"></a>多站在别人的角度思考问题</h3><p>在日常工作中，很多时候会涉及到任务的分工与合作，这就需要频繁地沟通。</p><p>每个人都有完全不同的成长环境，不同的成长环境造就了不同的三观以及思维方式，进而产生出不同的职业动机和职业规划，最终使得对待工作的态度和动力也会有所差别。这些差异无关对错，但有时候过于从自己角度思考问题并进行沟通反而会适得其反。</p><p>在与他人沟通时，如果能够站在别人的角度去思考问题，懂得换位思考，则很多矛盾在沟通过程中就可以被缓解甚至解决。当然，有些天然对立的矛盾是没办法彻底解决的，只能选择一个平衡点进行缓解。</p><h2 id="来年展望"><a href="#来年展望" class="headerlink" title="来年展望"></a>来年展望</h2><p>今年的年终总结写的比较仓促，但也算是勉强写完了。</p><p>新的一年就主要聊聊与 Apache IoTDB 有关的技术展望吧：</p><ul><li>共识框架：功能，性能，稳定性，正确性和文档稳定推进，希望能够吸引感兴趣的同学加入进来~</li><li>可观测性：深受 TiDB Performance Overview 面板的影响，下一步计划大幅加强 Apache IoTDB 的可观测性，并基于此来建立可扩展的工程服务体系和可持续的架构演进体系。</li><li>Java 全异步执行框架：暑期在学 Rust 时就已经被其 async/await 的无栈协程设计所折服。对于 Java 来说，自带的有栈协程框架 Loom 刚刚 GA，离正式生产环境用到还很久远。事件驱动的回调机制尽管性能很好，但回掉地狱的出现又会极大的影响代码可读性和可维护性。这一块在调研很多 Java 实现的大数据栈后并没有查到相关的资料。幸运的是，通过对 CompletableFuture 和 Thrift AsyncServer/AsyncClient 接口和源码的探索，对于如何基于 Thrift 的 NIO 机制来提升性能又利用 CompletableFuture 的编排能力提升代码的可读性可维护性，我已经有了一些想法和探索，期待明年能够结合这两者的优点进行一些 Java 数据库下 SOTA 线程模型的探索论证和实现测试，并形成系统性的博客向社区输出。</li></ul><p>最后，感谢您的阅读，希望这篇总结能够对您有所帮助。</p><p>在除夕这天，预祝大家新年身体健康，阖家幸福，心想事成~</p>]]></content>
    
    
    
    <tags>
      
      <tag>IoTDB</tag>
      
      <tag>年终总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022 互联网求职经验分享</title>
    <link href="/2022-internet-job-hunting-experience-sharing/"/>
    <url>/2022-internet-job-hunting-experience-sharing/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在前前后后忙活了接近四个月后，我的秋招终于结束了。</p><p>这篇 <a href="https://www.zhihu.com/question/351956937/answer/2798391706" target="_blank" rel="noopener">回答</a> 分享了我几乎所有技术面的面经，本博客将结合本人在今年秋招中的经验和在院系就业分享会中的分享内容介绍一下实习和秋招各个环节的注意事项，希望能够帮助到对分布式数据库内核研发岗感兴趣的同学。</p><p>注：本文内容仅代表个人看法。</p><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><p><img src="/2022-internet-job-hunting-experience-sharing/1.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/2.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/3.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/4.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/5.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/6.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/7.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/8.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/9.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/10.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/11.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/12.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/13.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/14.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/15.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/16.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/17.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/18.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/19.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/20.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/2022-internet-job-hunting-experience-sharing/21.png" srcset="/img/loading.gif" lazyload alt></p>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022 TiDB Hackathon 产品组最佳校园奖总结</title>
    <link href="/2022-tidb-hackathon/"/>
    <url>/2022-tidb-hackathon/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>2022 年 10 月，<a href="https://tidb.net/events/hackathon2022" target="_blank" rel="noopener">2022 TiDB Hackathon Possibility at Scale</a> 成功举办。</p><p>作为暑期实习在贵司事务组的 intern，在对 TiKV 的 codebase 有一定了解后，我兴致勃勃地拉了实验室的同学报名参加了此次 Hackathon，并且最终拿到了产品组的最佳校园奖，虽然没有拿到更大的奖项，但已经玩得十分开心了。</p><p>非常感谢 Hackathon 期间队友，mentor，组织者和评委对我们组的帮助和认可。</p><p>本文将简单介绍我们组的工作和思考以做回顾。</p><p>以下是我们项目的一些相关资料，欢迎点击了解：</p><ul><li><a href="https://github.com/orgs/FWH-TiKV/repositories" target="_blank" rel="noopener">代码</a></li><li><a href="https://github.com/FWH-TiKV/RFC" target="_blank" rel="noopener">RFC</a></li><li><a href="https://www.bilibili.com/video/BV1cP4y1S7Xo/" target="_blank" rel="noopener">答辩视频</a></li></ul><p>注：本文仅代表个人看法。</p><h2 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h2><p>本小节将沿着答辩 PPT 的思路介绍我们的工作。</p><p>我们的名字是热点清零队。我们的项目是无畏写热点，我们希望能够解决 TiKV 写热点问题的最后一公里。</p><p><img src="/2022-tidb-hackathon/1.png" srcset="/img/loading.gif" lazyload alt></p><p>我们的团队成员均来自清华大学软件学院。今年 hackathon 的主题是探索 scale 的可能性，我们的主要工作是解决热点 Region 在单机多核上的扩展性问题。在极致场景下我们提升了 TiDB 接近 1.2 倍的吞吐。</p><p><img src="/2022-tidb-hackathon/2.png" srcset="/img/loading.gif" lazyload alt></p><p>从用户视角来看，写热点问题会给他们带来多少困扰呢？比如某用户就提出，批量写场景下 TiKV 的 CPU/IO 都没用满，但写入依然很慢，这些现象给用户带来了不便和困扰。我们统计了 AskTug 论坛上写满 tag 帖子的原因分布，大致如右上图所示，可以看到写热点问题占比第一。</p><p><img src="/2022-tidb-hackathon/3.png" srcset="/img/loading.gif" lazyload alt></p><p>那现在的 TiDB 是如何解决热点问题的呢？其整体思路都是通过划分 region 来均匀承担负载，从而能够扩展。如右图所示，理想情况下随着 region 的分裂，热点会被稀释，进而线性扩展起来。然而，在当前上层数据分片的语义下，对于聚簇索引，唯一自增索引等场景，写热点问题难以避免。</p><p><img src="/2022-tidb-hackathon/4.png" srcset="/img/loading.gif" lazyload alt></p><p>当分裂 region 不能均分负载时，实际情况会如右上图所示，尽管分裂出了多的 region，但写热点始终集中在个别 region 上。在这种场景下，往往会遇到单节点存算资源并没有被充分利用的情况。其实不论上层怎么去分裂 region，单 region 热点始终是写热点问题的最后一公里，无法回避。</p><p><img src="/2022-tidb-hackathon/5.png" srcset="/img/loading.gif" lazyload alt></p><p>那让我们看看在 TiKV 中单 region 的执行路径。总体来说是需要在 StorePool 中进行 commit，在 ApplyPool 中进行 apply。然而在现有的实现中，不论是 StorePool 的持久化还是 ApplyPool 的写 memtable，并行度都是 1，因而不具备在单机上的扩展性。</p><p><img src="/2022-tidb-hackathon/6.png" srcset="/img/loading.gif" lazyload alt></p><p>那如果我们想要在单机上扩展热点 region，那可以从存储资源和计算资源两个方面来入手。对于存储资源，可以利用 IO 并行来提高吞吐，比如将单 region 不同批的日志用异步 IO 并行化处理，去年的 TPC 项目已经做过尝试，取得了不错的效果。对于计算资源，理论上也可以采用多核并行来提高吞吐，这也是我们的尝试，即去做 Parallel Apply</p><p><img src="/2022-tidb-hackathon/7.png" srcset="/img/loading.gif" lazyload alt></p><p>Parallel Apply 的整体思路是将无依赖的日志并行处理，从而提升整体吞吐。2018 年 VLDB 和 2021 年 JOS 已经对 Parallel Apply 的可行性和正确性进行了证明。</p><p><img src="/2022-tidb-hackathon/8.png" srcset="/img/loading.gif" lazyload alt></p><p>那在 TiKV 上落地 Parallel Apply 会有哪些难点呢？我们主要遇到了 4 个问题，比如如何保证依赖顺序的正确性，数据正确性，语义正确性和 index 正确性等等，以下分别进行介绍</p><p><img src="/2022-tidb-hackathon/9.png" srcset="/img/loading.gif" lazyload alt></p><p>我们的整体思路是在 ApplyPool 以外额外引入一个 ParallelApplyPool，并在 StorePool 中判断路由，进而使得单 region 的日志存在并行的可能性。同时在实现过程中，为了避免锁导致的线程切换，我们的共享状态均使用了原子变量。</p><p><img src="/2022-tidb-hackathon/10.png" srcset="/img/loading.gif" lazyload alt></p><p>对于刚刚提到的难点，我们简单介绍一下解决方案。</p><p>对于如何保证具有依赖的日志执行顺序正确？在 Leader 侧和在 Follower 侧需要有不同的处理方案。</p><ul><li>在 Leader 侧，得益于上层事务语义的约束，我们不需要引入依赖检测结果便可以无约束的并行 apply 普通日志，因为他们的 key 范围必定不会重叠。</li><li>在 Follower 侧，最简单可以串行执行来保证正确性，更进一步也可以考虑基于拓扑排序的依赖检测机制来并行 apply 日志从而满足依赖关系。</li></ul><p>对于如何保证 leader 切换或重启时数据依然正确？我们则很简单的使用了 Raft 的 term 变量，当且仅当日志的 term 为当前 term 时才考虑路由到 ParallelApplyPool 并行处理。这样的机制保证了 Leader 切换或者节点重启时系统不会将本不能并行处理的日志并行化处理，从而导致数据不一致。</p><p><img src="/2022-tidb-hackathon/11.png" srcset="/img/loading.gif" lazyload alt></p><p>对于如何保证 admin 等特殊日志的执行依然符合串行语义？即在 admin 日志执行之前其前面的所有日志均需要已经执行，在 admin 之后的日志执行前必须保证该 admin 日志已经执行。这个具体实现非常复杂，简单来说，我们在 Parallel Apply Pool 和 ApplyPool 中用原子变量共享了一些状态，对于单 region，StorePool 会将无冲突的普通日志在 Parallel ApplyPool 中并行执行，当出现 admin 日志时，当 StorePool 未感知到其执行完时，所有的日志都会被路由到 ApplyPool 中串行执行，当 admin 日志的 apply 结果返回 StorePool 后，之后的普通日志可以被继续路由到 Parallel Apply Pool 中并行执行。在 ApplyPool 中，我们还用原子变量来保证了只有 Parallel Apply Pool 中有关该 region 的所有普通日志都已执行完才去执行 Admin 日志。这些工作使得 admin 等特殊日志的执行依然符合了串行语义。在实际测试中，大部分普通日志都能够在 Parallel Apply Pool 中并行处理。，这也是我们在写热点场景性能提升的根源。</p><p><img src="/2022-tidb-hackathon/12.png" srcset="/img/loading.gif" lazyload alt></p><p>对于如何保证 applyIndex 的更新，我们发现不需要在磁盘上实时更新 applyState，这主要与底层 KV 引擎的幂等语义有关。我们在内存中维护了可能存在空洞的 applyIndex，当其连续时才推进 StorePool 中的 applyIndex，这也与现有的代码实现了兼容。</p><p><img src="/2022-tidb-hackathon/13.png" srcset="/img/loading.gif" lazyload alt></p><p>我们模拟了银行清算结算等跑批业务的极致情况，在 60 并发下，不同 BatchSize 的批量写入性能提升 <strong>89.4%~119.0%</strong>。TiKV CPU 利用率从 700% 左右提升至 1500% 左右。</p><p><img src="/2022-tidb-hackathon/14.png" srcset="/img/loading.gif" lazyload alt></p><p>我们也尝试了通用的批量导入热点场景，对于 TPCC prepare，在 1024 BatchSize 下，不同并发批量写入性能提升 <strong>29.8%~36.0%</strong>，TiKV CPU 利用率也从 750% 左右提升至 1000% 左右</p><p><img src="/2022-tidb-hackathon/15.png" srcset="/img/loading.gif" lazyload alt></p><p>在测试过程中，我们也更深刻地体会到了木桶效应。在 apply 是瓶颈的热点场景下，我们能取得很好的效果。但是对于 apply 不是瓶颈的场景，尽管这个阶段可能会加速，但根据阿姆达尔定律，最终的整体收益也不明显。</p><p><img src="/2022-tidb-hackathon/16.png" srcset="/img/loading.gif" lazyload alt></p><p>展望未来，我们认为我们的工作拼好了 TiKV 解决写热点问题的最后一块拼图，给出了解决写热点问题的终极形态。在多节点上，我们可以用 Split Region 的方式来在多节点上 scale。在单机上，我们可以用 Parallel Redo log 甚至是 Multi-Paxos 来更好地利用磁盘资源，也可以用 Parallel Apply 来更好的利用 CPU 资源，最终也能够在单机上彻底 scale。</p><p><img src="/2022-tidb-hackathon/17.png" srcset="/img/loading.gif" lazyload alt></p><p>同时在引擎演进方面，我们解决了不相关事务的日志回放顺序依赖问题，为 TiKV 更好的 CPU Scheduling 和极致性能做了铺垫。比如未来可以结合乱序确认乱序 commit 和 TPC 策略来对资源进行更精细的控制。</p><p><img src="/2022-tidb-hackathon/18.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>本小节将更随心的介绍一些我们的思考。</p><p>在这次 Hackathon 中，从技术上我们为 TiKV 做了 Parallel Apply 的优化；从产品上我们在高并发批量写入热点场景会有不错的收益。</p><p>上小节已经介绍了基于 region split 的方式来缓解热点问题的局限性，那么如何解决这种局限性呢？这就要回到一个圣战问题了：Raft 和 Multi-Paxos 有什么区别？</p><p>如同我在 <a href="https://github.com/FWH-TiKV/RFC" target="_blank" rel="noopener">RFC</a> 中介绍的一样，相比 Multi-Paxos，Raft 不能乱序 ack，不能乱序 commit，不能乱序 apply，因而有同学认为 Raft 不如 Multi-Paxos。</p><p>dragonboat 的作者对此观点进行了 <a href="https://www.zhihu.com/question/278984902/answer/404439990" target="_blank" rel="noopener">反驳</a>，其主要有两个观点：</p><ul><li>乱序并行 apply 不如拆分出更多的 raft 组来并行。</li><li>对于一个通用的共识库，不能乱序 apply 是受限于 RSM 模型本身的限制，并不是 Raft 本身的问题。对于特定场景，乱序 apply 可以达到一定效果，但并不是一个通用性的优化。</li></ul><p>对于第一个观点，从 TiKV 的角度来看，目前默认的 region 大小为 128M，尽管理论上 raft 组数拆的越多，单 raft 组内的串行化 apply 对性能的影响就越小。然而，raft 组过多带来的其他问题也会接踵而来，比如在 TiKV 实际测试中观察到过多的 region 和过大的 LSM Tree 都会导致性能的回退，因而未来 TiDB 的 Dynamic Region 工作计划一方面调大 region 大小到 512MB 至 10GB 从而减少 region 个数，另一方面则是拆分 RocksDB 实例。由此可见，影响 region 大小的因素并不只有 raft 串行化的问题。在未来，一方面 TiKV 的 region 会比现在更大，因此单 raft 组内的串行化问题会更加明显从而可能成为瓶颈；另一方面拆分 RocksDB 实例后 split 也不会再像现在这么轻量，因而实时动态的 split 负载均衡策略相比现在也会趋于保守。总体来看，在 TiKV 内实现乱序 apply 在未来是一个非常有可能的性能优化方向。</p><p>对于第二个观点，的确从通用的共识库的角度出发，乱序 apply 并无太大意义。但从 TiKV 中内嵌的共识算法来看，由于共识层之上的事务层已经定了一次序，因而共识层的重复定序在有些 case 下是没有意义，此时的乱序并行 apply 更可能提升热点场景的性能。</p><p>事实上，如果不支持乱序 apply，那共识算法的乱序 ack 和乱序 commit 可能没太大意义，因为整个共识组的瓶颈受限于最慢的模块。如果只能顺序 apply，那即使乱序 commit 了一批日志，如果这些日志之前存在空洞，那么这批日志也只能在内存中等待而不能被 apply。然而如果支持了乱序 apply，那结合乱序 ack 和乱序 commit 就更可能提高共识组的吞吐上限。比如一旦支持乱序 commit，那可以使用多个 IO depth 来持久化不同批的日志，这样每次 IO 的大小减少了，也可能能够减少每次 IO 的平均时间。此外支持乱序 commit 后也可以将前面存在空洞但确保与空洞日志无依赖关系的一批乱序 commit 日志提前 apply 处理，进而抬高 apply 的瓶颈天花板。</p><p>总体来看，Parallel Apply 能够解决 region 写热点在多核上的扩展性问题，Multi-Paxos 能够解决 region 写热点在现代硬盘上的扩展性问题。因此，Multi-Paxos + Parallel Apply 理论上能够解决写入热点在现代硬件上的扩展性问题。预计能够在写热点场景更充分的利用硬件资源，从而提升性能。</p><p>在写 Hackathon RFC 的时候我更多的关注了对于写热点场景下 Raft 与 Multi-Paxos 的区别，然而对于其他场景，我意外的发现 Raft 和 Multi-Paxos 也能体现不同的价值。</p><p>在 OB 社区 4.0 版本的 <a href="https://mp.weixin.qq.com/s/zKZrl26TIfkCK5EECLURzg" target="_blank" rel="noopener">介绍</a> 中，专门提到了一个很大的变动：自适应日志流，即将分片与共识解耦。在不考虑 leader 打散情况下，每个租户在一个进程中可以有多个分片但只会有一个共识组。</p><p><img src="/2022-tidb-hackathon/19.png" srcset="/img/loading.gif" lazyload alt></p><p>基于传统 Raft 的方案是很难去做出这样的架构设计的，但 Multi-Paxos 可以做到。</p><p><img src="/2022-tidb-hackathon/20.png" srcset="/img/loading.gif" lazyload alt></p><p>在收益方面，除了完全控制共识组个数和增大 1PC 比例以外，OB 4.0 更是基于自适应日志流架构重构了事务引擎，从而对大事务有了更好的支持，并基于这些工作产品化包装出了单机分布式一体化架构。这个架构的缺点就是灵活扩缩容和实时负载均衡会更难做，但如果考虑云上的部署形态，这些新的问题又可以通过其他方案来缓解。</p><p><img src="/2022-tidb-hackathon/21.png" srcset="/img/loading.gif" lazyload alt></p><p>总体而看，一个系统的架构设计就是要在关键模块的各种 trade-off 中做出纠结的选择，并且一旦做出了某个选择，就需要基于这个选择更进一步做非常多的产品化工作和优化打磨来提升这些技术对于用户的实际价值。例如，TiDB 选了 TSO 的时间戳获取方案并不代表就不能服务跨数据中心场景了，其也做了 Local/Global TSO 的产品化工作来满足部分用户场景的跨数据中心需求。CRDB 用了 HLC 之后并不仅仅体现在获取事务时间戳更快，其至少还基于 HLC 在 Strong/Stale Follower Read 这一块做了许多工作来减少跨域流量从而降低成本。对于 OB，其选择了 Multi-Paxos 而不是 Raft，并且更进一步在 4.0 架构中提出了单机分布式一体化架构来解决其他数据库很难彻底解决的写热点缓解，大事务支持和 1PC 比例增大等难点。当然，这些技术和产品化的工作短期内很难形成事实标准，也都能够在各自的用户场景产生价值，至于孰优孰劣就很难客观判断了。</p><p><img src="/2022-tidb-hackathon/22.png" srcset="/img/loading.gif" lazyload alt></p><p>仅就技术而言，如同我在之前有关 <a href="https://zhuanlan.zhihu.com/p/581125699" target="_blank" rel="noopener">共识算法综述博客</a> 开头中介绍的一样，对于 Raft 和 Multi Paxos 孰优孰劣这一圣战问题，我的主观看法是对于普通 KV，很可能区别不大。对于结合共识和事务模块的 NewSQL 数据库，Multi-Paxos 能够在整体上为一些难点问题提供一点不一样的思路（例如增大 1PC 比例，缓解写热点问题，大事务支持等等），可能有更高的性能天花板。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文简要总结了 2022 TiDB Hackathon 产品组最佳校园奖热点清零队的工作，并简要分享了本人对 Raft 和 Multi-Paxos 异同的看法，希望能够引起更多的讨论。</p><p>感谢您的阅读~</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>分布式存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Have we reached consensus on consensus？</title>
    <link href="/have-we-reached-consensus-on-consensus/"/>
    <url>/have-we-reached-consensus-on-consensus/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>分享一下前不久在 PingCAP 实习时做的有关共识算法及其应用的介绍（已经删除了部分不便公开的内容）。</p><p>这次分享主要针对 Raft 和 Paxos 做了相对详细的介绍，并从学术界和工业界的不同视角对比了他们的异同，最后也基于 TiKV 当前架构现状和其他系统的架构设计从一个 intern 的视角拍脑袋介绍了几个可能的演进方向。</p><p>回到 Raft 和 Multi Paxos 孰优孰劣这一圣战问题，可以明确的是对于普通 KV，很可能区别不大。对于结合共识和事务模块的 NewSQL 数据库，Multi-Paxos 能够在整体上为一些难点问题提供一点不一样的思路（例如增大 1PC 比例，缓解写热点问题等等），可能有更高的性能天花板。</p><p>注：本文内容仅代表个人看法。</p><p>注：以下仅为图片，可以在 <a href="https://vevotse3pn.feishu.cn/file/boxcnBKfW8q9E61Bfi314R0hOfe" target="_blank" rel="noopener">此处</a> 在线浏览 PPT 原件。</p><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><p><img src="/have-we-reached-consensus-on-consensus/1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/2.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/3.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/4.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/5.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/6.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/7.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/8.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/9.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/10.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/11.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/12.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/13.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/14.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/15.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/16.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/17.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/18.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/19.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/20.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/21.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/22.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/23.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/24.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/25.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/26.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/27.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/28.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/29.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/30.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/31.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/32.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/33.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/34.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/35.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/36.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/37.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/38.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/39.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/40.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/41.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/42.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/43.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/44.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/45.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/46.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/47.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/48.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/49.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/50.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/51.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/52.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/53.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/54.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/55.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/56.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/57.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/58.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/59.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/60.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/61.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/62.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/63.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/64.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/65.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/66.png" srcset="/img/loading.gif" lazyload alt><br><img src="/have-we-reached-consensus-on-consensus/67.png" srcset="/img/loading.gif" lazyload alt></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><ul><li><a href="https://lamport.azurewebsites.net/pubs/paxos-simple.pdf" target="_blank" rel="noopener">Paxos Made Simple</a></li><li><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf" target="_blank" rel="noopener">Paxos Made Live - An Engineering Perspective</a></li><li><a href="https://dada.cs.washington.edu/research/tr/2009/09/UW-CSE-09-09-02.PDF" target="_blank" rel="noopener">Multi-Paxos: An Implementation and Evaluation</a></li><li><a href="https://people.csail.mit.edu/malte/pub/papers/2015-osr-raft.pdf" target="_blank" rel="noopener">Raft Refloated: Do We Have Consensus?</a></li><li><a href="https://www.vldb.org/pvldb/vol11/p1849-cao.pdf" target="_blank" rel="noopener">PolarFS: An Ultra-low Latency and Failure Resilient Distributed File System for Shared Storage Cloud Database</a></li><li><a href="https://dl.acm.org/doi/abs/10.14778/3137765.3137778" target="_blank" rel="noopener">PaxosStore: High-availability Storage Made Practical in WeChat</a></li><li><a href="https://dl.acm.org/doi/abs/10.14778/1938545.1938549" target="_blank" rel="noopener">Using Paxos to Build a Scalable, Consistent, and Highly Available Datastore</a></li><li><a href="https://dl.acm.org/doi/abs/10.1145/3380787.3393681" target="_blank" rel="noopener">Paxos vs Raft: have we reached consensus on distributed consensus?</a></li><li><a href="https://dl.acm.org/doi/pdf/10.1145/3293611.3331595" target="_blank" rel="noopener">On the Parallels between Paxos and Raft, and how to Port Optimizations</a></li><li><a href="https://www.usenix.org/system/files/fast21-chen-hao.pdf" target="_blank" rel="noopener">SpanDB: A Fast, Cost-Effective LSM-tree Based KV Store on Hybrid Storage</a></li></ul><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><ul><li><a href="http://icyfenix.cn/distribution/consensus/raft.html" target="_blank" rel="noopener">凤凰架构 Multi-Paxos</a></li><li><a href="https://mp.weixin.qq.com/s/4D5_x-Ftg8Qzl6hPdoVTxQ" target="_blank" rel="noopener">将 paxos 和 raft 统一为一个协议：abstract-paxos</a></li><li><a href="https://mp.weixin.qq.com/s/3OZgqEWQcEf6V9v6eoSUUA" target="_blank" rel="noopener">可靠分布式系统-paxos 的直观解释</a></li><li><a href="https://blog.csdn.net/sinat_22338935/article/details/114320664" target="_blank" rel="noopener">Page Cache 引起的业务问题处理</a></li><li><a href="https://segmentfault.com/a/1190000038967218" target="_blank" rel="noopener">深入了解 MySQL 主从复制的原理</a></li><li><a href="https://github.com/oceanbase/oceanbase" target="_blank" rel="noopener">OceanBase 文档</a></li><li><a href="https://mp.weixin.qq.com/s/zKZrl26TIfkCK5EECLURzg" target="_blank" rel="noopener">OceanBase 社区版 4.0 发版：一个全新的里程碑</a></li><li><a href="https://www.bilibili.com/video/BV14d4y1D7wz/?spm_id_from=333.337.search-card.all.click&amp;vd_source=c856dfca0df73fe9dce87bfc54acabc5" target="_blank" rel="noopener">【PingCAP Infra Meetup】No.151 TiDB 事务模型演进</a></li><li><a href="https://cloud.tencent.com/developer/article/1352070" target="_blank" rel="noopener">Paxos 和 Raft 的前世今生</a></li><li><a href="https://www.infoq.cn/article/wechat-paxosstore-paxos-algorithm-protocol/" target="_blank" rel="noopener">微信 PaxosStore：深入浅出 Paxos 算法协议</a></li><li><a href="https://zhuanlan.zhihu.com/p/45720365" target="_blank" rel="noopener">共识算法 之 Basic Paxos</a></li><li><a href="https://www.zhihu.com/question/57321934/answer/152640954" target="_blank" rel="noopener">Paxos(Multi-Paxos) 在工程实现中需要注意哪些问题？</a></li><li><a href="https://ongardie.net/static/raft/userstudy/paxos.pptx" target="_blank" rel="noopener">Implementing Replicated Logs  with Paxos</a></li><li><a href="https://github.com/TPC-TiKV/rfc" target="_blank" rel="noopener">2021 TiDB Hackathon TPC-TiKV RFC</a></li><li><a href="https://github.com/FWH-TiKV/RFC" target="_blank" rel="noopener">2022 TiDB Hackathon FWH-TiKV RFC</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TiKV 源码阅读三部曲（三）写流程</title>
    <link href="/tikv-source-code-reading-write/"/>
    <url>/tikv-source-code-reading-write/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://github.com/tikv/tikv" target="_blank" rel="noopener">TiKV</a> 是一个支持事务的分布式 Key-Value 数据库，目前已经是 <a href="https://www.cncf.io/projects/" target="_blank" rel="noopener">CNCF 基金会</a> 的顶级项目。</p><p>作为一个新同学，需要一定的前期准备才能够有能力参与 TiKV 社区的代码开发，包括但不限于学习 Rust 语言，理解 TiKV 的原理和在前两者的基础上了解熟悉 TiKV 的源码。</p><p><a href="https://pingcap.com/zh/blog/?tag=TiKV%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90" target="_blank" rel="noopener">TiKV 官方源码解析文档</a> 详细地介绍了 TiKV 3.x 版本重要模块的设计要点，主要流程和相应代码片段，是学习 TiKV 源码必读的学习资料。当前 TiKV 已经迭代到了 6.x 版本，不仅引入了很多新的功能和优化，而且对源码也进行了多次重构，因而一些官方源码解析文档中的代码片段已经不复存在，这使得读者在阅读源码解析文档时无法对照最新源码加深理解；此外尽管 TiKV 官方源码解析文档系统地介绍了若干重要模块的工作，但并没有将读写流程全链路串起来去介绍经过的模块和对应的代码片段，实际上尽快地熟悉读写流程全链路会更利于新同学从全局角度理解代码。</p><p>基于以上存在的问题，笔者将基于 6.1 版本的源码撰写三篇博客，分别介绍以下三个方面：</p><ul><li><a href="https://tanxinyu.work/tikv-source-code-reading-module/">TiKV 源码阅读三部曲（一）重要模块</a>：TiKV 的基本概念，TiKV 读写路径上的三个重要模块（KVService，Storage，RaftStore）和断点调试 TiKV 学习源码的方案</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-read/">TiKV 源码阅读三部曲（二）读流程</a>：TiKV 中一条读请求的全链路流程</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-write/">TiKV 源码阅读三部曲（三）写流程</a>：TiKV 中一条写请求的全链路流程</li></ul><p>希望此三篇博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>本文为第三篇博客，将主要介绍 TiKV 中一条写请求的全链路流程。</p><h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><p>以下四篇博客由上到下分别介绍了 TiKV 3.x 版本 KVService，Storage 和 RaftStore 模块对于分布式事务请求的执行流程。</p><ul><li><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-9" target="_blank" rel="noopener">TiKV 源码解析系列文章（九）Service 层处理流程解析</a></li><li><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-11" target="_blank" rel="noopener">TiKV 源码解析系列文章（十一）Storage - 事务控制层</a></li><li><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-12" target="_blank" rel="noopener">TiKV 源码解析系列文章（十二）分布式事务</a></li><li><a href="https://cn.pingcap.com/blog/tikv-source-code-reading-18" target="_blank" rel="noopener">TiKV 源码解析系列文章（十八）Raft Propose 的 Commit 和 Apply 情景分析</a></li></ul><p>本小节将在 TiKV 6.1 版本的基础上，以一条 PreWrite 请求为例，介绍当前版本的写请求全链路执行流程。</p><h3 id="KVService"><a href="#KVService" class="headerlink" title="KVService"></a>KVService</h3><p>在 KVService 层，通过 handle_request 和 txn_command_future 宏，PreWrite 接口的请求会直接被路由到 <code>Storage::sched_txn_command</code> 函数中。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-keyword">impl</span>&lt;T: RaftStoreRouter&lt;E::Local&gt; + <span class="hljs-symbol">'static</span>, E: Engine, L: LockManager, F: KvFormat&gt; Tikv<br>    <span class="hljs-keyword">for</span> Service&lt;T, E, L, F&gt;<br>&#123;<br>    handle_request!(<br>        kv_prewrite,<br>        future_prewrite,<br>        PrewriteRequest,<br>        PrewriteResponse,<br>        has_time_detail<br>    );<br>&#125; <br><br>txn_command_future!(future_prewrite, PrewriteRequest, PrewriteResponse, (v, resp, tracker) &#123;&#123;<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Ok</span>(v) = &amp;v &#123;<br>        resp.set_min_commit_ts(v.min_commit_ts.into_inner());<br>        resp.set_one_pc_commit_ts(v.one_pc_commit_ts.into_inner());<br>        GLOBAL_TRACKERS.with_tracker(tracker, |tracker| &#123;<br>            tracker.write_scan_detail(resp.mut_exec_details_v2().mut_scan_detail_v2());<br>            tracker.write_write_detail(resp.mut_exec_details_v2().mut_write_detail());<br>        &#125;);<br>    &#125;<br>    resp.set_errors(extract_key_errors(v.map(|v| v.locks)).into());<br>&#125;&#125;);<br></code></pre></div></td></tr></table></figure><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p>在 Storage 模块，其会将请求路由到 <code>Scheduler::run_cmd</code> 函数中，并进一步路由到 <code>Scheduler::schedule_command</code> 函数中。在 <code>schedule_command</code> 函数中，当前 command 连同 callback 等上下文会被保存到 task_slots 中，如果当前线程申请到了所有 latch 则会调用 execute 函数继续执行该 task，否则如前文所述，当前任务便会被阻塞在某些 latch 上等待其他线程去唤醒进而执行，当前线程会直接返回并执行其他的工作。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">// The entry point of the storage scheduler. Not only transaction commands need</span><br><span class="hljs-comment">// to access keys serially.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">sched_txn_command</span></span>&lt;T: StorageCallbackType&gt;(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    cmd: TypedCommand&lt;T&gt;,<br>    callback: Callback&lt;T&gt;,<br>) -&gt; <span class="hljs-built_in">Result</span>&lt;()&gt; &#123;<br><br>    ...<br>    <br>    <span class="hljs-keyword">self</span>.sched.run_cmd(cmd, T::callback(callback));<br><br>    <span class="hljs-literal">Ok</span>(())<br>&#125;<br><br><span class="hljs-keyword">pub</span>(<span class="hljs-keyword">in</span> crate::storage) <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">run_cmd</span></span>(&amp;<span class="hljs-keyword">self</span>, cmd: Command, callback: StorageCallback) &#123;<br>    <span class="hljs-comment">// write flow control</span><br>    <span class="hljs-keyword">if</span> cmd.need_flow_control() &amp;&amp; <span class="hljs-keyword">self</span>.inner.too_busy(cmd.ctx().region_id) &#123;<br>        SCHED_TOO_BUSY_COUNTER_VEC.get(cmd.tag()).inc();<br>        callback.execute(ProcessResult::Failed &#123;<br>            err: StorageError::from(StorageErrorInner::SchedTooBusy),<br>        &#125;);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">self</span>.schedule_command(cmd, callback);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">schedule_command</span></span>(&amp;<span class="hljs-keyword">self</span>, cmd: Command, callback: StorageCallback) &#123;<br>    <span class="hljs-keyword">let</span> cid = <span class="hljs-keyword">self</span>.inner.gen_id();<br>    <span class="hljs-keyword">let</span> tracker = get_tls_tracker_token();<br>    debug!(<span class="hljs-string">"received new command"</span>; <span class="hljs-string">"cid"</span> =&gt; cid, <span class="hljs-string">"cmd"</span> =&gt; ?cmd, <span class="hljs-string">"tracker"</span> =&gt; ?tracker);<br>    <span class="hljs-keyword">let</span> tag = cmd.tag();<br>    <span class="hljs-keyword">let</span> priority_tag = get_priority_tag(cmd.priority());<br>    SCHED_STAGE_COUNTER_VEC.get(tag).new.inc();<br>    SCHED_COMMANDS_PRI_COUNTER_VEC_STATIC<br>        .get(priority_tag)<br>        .inc();<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> task_slot = <span class="hljs-keyword">self</span>.inner.get_task_slot(cid);<br>    <span class="hljs-keyword">let</span> tctx = task_slot.entry(cid).or_insert_with(|| &#123;<br>        <span class="hljs-keyword">self</span>.inner<br>            .new_task_context(Task::new(cid, tracker, cmd), callback)<br>    &#125;);<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.inner.latches.acquire(&amp;<span class="hljs-keyword">mut</span> tctx.lock, cid) &#123;<br>        fail_point!(<span class="hljs-string">"txn_scheduler_acquire_success"</span>);<br>        tctx.on_schedule();<br>        <span class="hljs-keyword">let</span> task = tctx.task.take().unwrap();<br>        <span class="hljs-built_in">drop</span>(task_slot);<br>        <span class="hljs-keyword">self</span>.execute(task);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">let</span> task = tctx.task.as_ref().unwrap();<br>    <span class="hljs-keyword">let</span> deadline = task.cmd.deadline();<br>    <span class="hljs-keyword">let</span> cmd_ctx = task.cmd.ctx().clone();<br>    <span class="hljs-keyword">self</span>.fail_fast_or_check_deadline(cid, tag, cmd_ctx, deadline);<br>    fail_point!(<span class="hljs-string">"txn_scheduler_acquire_fail"</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>在 execute 函数中，当前线程会生成一个异步任务 spawn 到另一个 worker 线程池中去，该任务主要包含以下两个步骤：</p><ul><li>使用 <code>Self::with_tls_engine(|engine| Self::snapshot(engine, snap_ctx)).await</code> 获取 snapshot。此步骤与上文读流程中获取 snapshot 的步骤相同，可能通过 ReadLocal 也可能通过 ReadIndex 来获取引擎的 snapshot，此小节不在赘述</li><li>使用 <code>sched.process(snapshot, task).await</code> 基于获取到的 snapshot 和对应 task 去调用 <code>scheduler::process</code> 函数，进而被路由到 <code>scheduler::process_write</code> 函数中</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Executes the task in the sched pool.</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">execute</span></span>(&amp;<span class="hljs-keyword">self</span>, <span class="hljs-keyword">mut</span> task: Task) &#123;<br>    set_tls_tracker_token(task.tracker);<br>    <span class="hljs-keyword">let</span> sched = <span class="hljs-keyword">self</span>.clone();<br>    <span class="hljs-keyword">self</span>.get_sched_pool(task.cmd.priority())<br>        .pool<br>        .spawn(<span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>        <br>            ...<br><br>            <span class="hljs-comment">// The program is currently in scheduler worker threads.</span><br>            <span class="hljs-comment">// Safety: `self.inner.worker_pool` should ensure that a TLS engine exists.</span><br>            <span class="hljs-keyword">match</span> <span class="hljs-keyword">unsafe</span> &#123; with_tls_engine(|engine: &amp;E| kv::snapshot(engine, snap_ctx)) &#125;.<span class="hljs-keyword">await</span><br>            &#123;<br>                <span class="hljs-literal">Ok</span>(snapshot) =&gt; &#123;<br>              <br>                    ...<br><br>                    sched.process(snapshot, task).<span class="hljs-keyword">await</span>;<br>                &#125;<br>                <span class="hljs-literal">Err</span>(err) =&gt; &#123;<br>                    ...<br>                &#125;<br>            &#125;<br>        &#125;)<br>        .unwrap();<br>&#125;<br><br> <span class="hljs-comment">/// Process the task in the current thread.</span><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">process</span></span>(<span class="hljs-keyword">self</span>, snapshot: E::Snap, task: Task) &#123;<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.check_task_deadline_exceeded(&amp;task) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">let</span> resource_tag = <span class="hljs-keyword">self</span>.inner.resource_tag_factory.new_tag(task.cmd.ctx());<br>    <span class="hljs-keyword">async</span> &#123;<br>        <br>        ...<br><br>        <span class="hljs-keyword">if</span> task.cmd.readonly() &#123;<br>            <span class="hljs-keyword">self</span>.process_read(snapshot, task, &amp;<span class="hljs-keyword">mut</span> statistics);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">self</span>.process_write(snapshot, task, &amp;<span class="hljs-keyword">mut</span> statistics).<span class="hljs-keyword">await</span>;<br>        &#125;;<br>   <br>        ...<br>    &#125;<br>    .in_resource_metering_tag(resource_tag)<br>    .<span class="hljs-keyword">await</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p><code>scheduler::process_write</code> 函数是事务处理的关键函数，目前已经有近四百行，里面夹杂了很多新特性和新优化的复杂逻辑，其中最重要的逻辑有两个：</p><ul><li>使用 <code>task.cmd.process_write(snapshot, context).map_err(StorageError::from)</code> 根据 snapshot 和 task 执行事务对应的语义：可以从 <code>Command::process_write</code> 函数看到不同的请求都有不同的实现，每种请求都可能根据 snapshot 去底层获取一些数据并尝试写入一些数据。有关 PreWrite 和其他请求的具体操作可以参照 <a href="https://pingcap.com/zh/blog/tikv-source-code-reading-12" target="_blank" rel="noopener">TiKV 源码解析系列文章（十二）分布式事务</a>，此处不再赘述。需要注意的是，此时的写入仅仅缓存在了 WriteData 中，并没有对底层引擎进行实际修改。</li><li>使用 <code>engine.async_write_ext(&amp;ctx, to_be_write, engine_cb, proposed_cb, committed_cb)</code> 将缓存的 WriteData 实际写入到 engine 层，对于 RaftKV 来说则是表示一次 propose，想要对这一批 WriteData commit 且 apply</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">process_write</span></span>(<span class="hljs-keyword">self</span>, snapshot: E::Snap, task: Task, statistics: &amp;<span class="hljs-keyword">mut</span> Statistics) &#123;<br> <br>    ...<br><br>    <span class="hljs-keyword">let</span> write_result = &#123;<br>        <span class="hljs-keyword">let</span> _guard = sample.observe_cpu();<br>        <span class="hljs-keyword">let</span> context = WriteContext &#123;<br>            lock_mgr: &amp;<span class="hljs-keyword">self</span>.inner.lock_mgr,<br>            concurrency_manager: <span class="hljs-keyword">self</span>.inner.concurrency_manager.clone(),<br>            extra_op: task.extra_op,<br>            statistics,<br>            async_apply_prewrite: <span class="hljs-keyword">self</span>.inner.enable_async_apply_prewrite,<br>        &#125;;<br>        <span class="hljs-keyword">let</span> begin_instant = Instant::now();<br>        <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">unsafe</span> &#123;<br>            with_perf_context::&lt;E, _, _&gt;(tag, || &#123;<br>                task.cmd<br>                    .process_write(snapshot, context)<br>                    .map_err(StorageError::from)<br>            &#125;)<br>        &#125;;<br>        SCHED_PROCESSING_READ_HISTOGRAM_STATIC<br>            .get(tag)<br>            .observe(begin_instant.saturating_elapsed_secs());<br>        res<br>    &#125;;<br><br>    ...<br><br>    <span class="hljs-comment">// Safety: `self.sched_pool` ensures a TLS engine exists.</span><br>    <span class="hljs-keyword">unsafe</span> &#123;<br>        with_tls_engine(|engine: &amp;E| &#123;<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Err</span>(e) =<br>                engine.async_write_ext(&amp;ctx, to_be_write, engine_cb, proposed_cb, committed_cb)<br>            &#123;<br>                SCHED_STAGE_COUNTER_VEC.get(tag).async_write_err.inc();<br><br>                info!(<span class="hljs-string">"engine async_write failed"</span>; <span class="hljs-string">"cid"</span> =&gt; cid, <span class="hljs-string">"err"</span> =&gt; ?e);<br>                scheduler.finish_with_err(cid, e);<br>            &#125;<br>        &#125;)<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">pub</span>(<span class="hljs-keyword">crate</span>) <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">process_write</span></span>&lt;S: Snapshot, L: LockManager&gt;(<br>    <span class="hljs-keyword">self</span>,<br>    snapshot: S,<br>    context: WriteContext&lt;<span class="hljs-symbol">'_</span>, L&gt;,<br>) -&gt; <span class="hljs-built_in">Result</span>&lt;WriteResult&gt; &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-keyword">self</span> &#123;<br>        Command::Prewrite(t) =&gt; t.process_write(snapshot, context),<br>        Command::PrewritePessimistic(t) =&gt; t.process_write(snapshot, context),<br>        Command::AcquirePessimisticLock(t) =&gt; t.process_write(snapshot, context),<br>        Command::Commit(t) =&gt; t.process_write(snapshot, context),<br>        Command::Cleanup(t) =&gt; t.process_write(snapshot, context),<br>        Command::Rollback(t) =&gt; t.process_write(snapshot, context),<br>        Command::PessimisticRollback(t) =&gt; t.process_write(snapshot, context),<br>        Command::ResolveLock(t) =&gt; t.process_write(snapshot, context),<br>        Command::ResolveLockLite(t) =&gt; t.process_write(snapshot, context),<br>        Command::TxnHeartBeat(t) =&gt; t.process_write(snapshot, context),<br>        Command::CheckTxnStatus(t) =&gt; t.process_write(snapshot, context),<br>        Command::CheckSecondaryLocks(t) =&gt; t.process_write(snapshot, context),<br>        Command::Pause(t) =&gt; t.process_write(snapshot, context),<br>        Command::RawCompareAndSwap(t) =&gt; t.process_write(snapshot, context),<br>        Command::RawAtomicStore(t) =&gt; t.process_write(snapshot, context),<br>        _ =&gt; <span class="hljs-built_in">panic!</span>(<span class="hljs-string">"unsupported write command"</span>),<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">async_write_ext</span></span>(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    ctx: &amp;Context,<br>    batch: WriteData,<br>    write_cb: Callback&lt;()&gt;,<br>    proposed_cb: <span class="hljs-built_in">Option</span>&lt;ExtCallback&gt;,<br>    committed_cb: <span class="hljs-built_in">Option</span>&lt;ExtCallback&gt;,<br>) -&gt; kv::<span class="hljs-built_in">Result</span>&lt;()&gt; &#123;<br>    fail_point!(<span class="hljs-string">"raftkv_async_write"</span>);<br>    <span class="hljs-keyword">if</span> batch.modifies.is_empty() &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">Err</span>(KvError::from(KvErrorInner::EmptyRequest));<br>    &#125;<br><br>    ASYNC_REQUESTS_COUNTER_VEC.write.all.inc();<br>    <span class="hljs-keyword">let</span> begin_instant = Instant::now_coarse();<br><br>    <span class="hljs-keyword">self</span>.exec_write_requests(<br>        ctx,<br>        batch,<br>        <span class="hljs-built_in">Box</span>::new(<span class="hljs-keyword">move</span> |res| <span class="hljs-keyword">match</span> res &#123;<br><br>            ...<br><br>        &#125;),<br>        proposed_cb,<br>        committed_cb,<br>    )<br>    .map_err(|e| &#123;<br>        <span class="hljs-keyword">let</span> status_kind = get_status_kind_from_error(&amp;e);<br>        ASYNC_REQUESTS_COUNTER_VEC.write.get(status_kind).inc();<br>        e.into()<br>    &#125;)<br>&#125;<br></code></pre></div></td></tr></table></figure><p>进入 <code>raftkv::async_write_ext</code> 函数后，其进而通过 <code>raftkv::exec_write_requests -&gt; RaftStoreRouter::send_command</code> 的调用栈将 task 连带 callback 发送给 RaftBatchSystem 交由 RaftStore 模块处理。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">exec_write_requests</span></span>(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    ctx: &amp;Context,<br>    batch: WriteData,<br>    write_cb: Callback&lt;CmdRes&lt;E::Snapshot&gt;&gt;,<br>    proposed_cb: <span class="hljs-built_in">Option</span>&lt;ExtCallback&gt;,<br>    committed_cb: <span class="hljs-built_in">Option</span>&lt;ExtCallback&gt;,<br>) -&gt; <span class="hljs-built_in">Result</span>&lt;()&gt; &#123;<br>    <br>    ...<br><br>    <span class="hljs-keyword">let</span> cb = StoreCallback::write_ext(<br>        <span class="hljs-built_in">Box</span>::new(<span class="hljs-keyword">move</span> |resp| &#123;<br>            write_cb(on_write_result(resp).map_err(Error::into));<br>        &#125;),<br>        proposed_cb,<br>        committed_cb,<br>    );<br>    <span class="hljs-keyword">let</span> extra_opts = RaftCmdExtraOpts &#123;<br>        deadline: batch.deadline,<br>        disk_full_opt: batch.disk_full_opt,<br>    &#125;;<br>    <span class="hljs-keyword">self</span>.router.send_command(cmd, cb, extra_opts)?;<br><br>    <span class="hljs-literal">Ok</span>(())<br>&#125;<br><br>    <span class="hljs-comment">/// Sends RaftCmdRequest to local store.</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">send_command</span></span>(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    req: RaftCmdRequest,<br>    cb: Callback&lt;EK::Snapshot&gt;,<br>    extra_opts: RaftCmdExtraOpts,<br>) -&gt; RaftStoreResult&lt;()&gt; &#123;<br>    send_command_impl::&lt;EK, _&gt;(<span class="hljs-keyword">self</span>, req, cb, extra_opts)<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="RaftStore"><a href="#RaftStore" class="headerlink" title="RaftStore"></a>RaftStore</h3><p>直接定位到 <code>RaftPoller</code> 的 <code>handle_normal</code> 函数。</p><p>与处理 ReadIndex 请求相似， <code>RaftPoller</code> 会首先尝试获取 <code>messages_per_tick</code> 次路由到该状态机的消息，接着调用 <code>PeerFsmDelegate::handle_msgs</code> 函数进行处理，</p><p>这里依然只列出了我们需要关注的几种消息类型：</p><ul><li>RaftMessage: 其他 Peer 发送过来 Raft 消息，包括心跳、日志、投票消息等。</li><li>RaftCommand: 上层提出的 proposal，其中包含了需要通过 Raft 同步的操作，以及操作成功之后需要调用的 callback 函数。PreWrite 包装出的 RaftCommand 便是最正常的 proposal。</li><li>ApplyRes: ApplyFsm 在将日志应用到状态机之后发送给 PeerFsm 的消息，用于在进行操作之后更新某些内存状态。</li></ul><p>对于 PreWrite 请求，其会进入 <code>PeerMsg::RaftCommand(cmd)</code> 分支，进而以 <code>PeerFsmDelegate::propose_raft_command -&gt; PeerFsmDelegate::propose_raft_command_internal -&gt; Peer::propose -&gt; Peer::propose_normal</code> 的调用链最终被 propose 到 raft-rs 的 RawNode 接口中，同时其 callback 会连带该请求的 logIndex 被 push 到该 Peer 的 <code>proposals</code> 中去。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;EK: KvEngine, ER: RaftEngine, T: Transport&gt; PollHandler&lt;PeerFsm&lt;EK, ER&gt;, StoreFsm&lt;EK&gt;&gt;<br>    <span class="hljs-keyword">for</span> RaftPoller&lt;EK, ER, T&gt;<br>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_normal</span></span>(<br>        &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>        peer: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">impl</span> DerefMut&lt;Target = PeerFsm&lt;EK, ER&gt;&gt;,<br>    ) -&gt; HandleResult &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> handle_result = HandleResult::KeepProcessing;<br><br>        ...<br><br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.peer_msg_buf.len() &lt; <span class="hljs-keyword">self</span>.messages_per_tick &#123;<br>            <span class="hljs-keyword">match</span> peer.receiver.try_recv() &#123;<br>                <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> we may need a way to optimize the message copy.</span><br>                <span class="hljs-literal">Ok</span>(msg) =&gt; &#123;<br>                    ...<br>                    <span class="hljs-keyword">self</span>.peer_msg_buf.push(msg);<br>                &#125;<br>                <span class="hljs-literal">Err</span>(TryRecvError::Empty) =&gt; &#123;<br>                    handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>                <span class="hljs-literal">Err</span>(TryRecvError::Disconnected) =&gt; &#123;<br>                    peer.stop();<br>                    handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> delegate = PeerFsmDelegate::new(peer, &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.poll_ctx);<br>        delegate.handle_msgs(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.peer_msg_buf);<br>        <span class="hljs-comment">// No readiness is generated and using sync write, skipping calling ready and</span><br>        <span class="hljs-comment">// release early.</span><br>        <span class="hljs-keyword">if</span> !delegate.collect_ready() &amp;&amp; <span class="hljs-keyword">self</span>.poll_ctx.sync_write_worker.is_some() &#123;<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> HandleResult::StopAt &#123; skip_end, .. &#125; = &amp;<span class="hljs-keyword">mut</span> handle_result &#123;<br>                *skip_end = <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br><br>        handle_result<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">impl</span>&lt;<span class="hljs-symbol">'a</span>, EK, ER, T: Transport&gt; PeerFsmDelegate&lt;<span class="hljs-symbol">'a</span>, EK, ER, T&gt;<br><span class="hljs-keyword">where</span><br>    EK: KvEngine,<br>    ER: RaftEngine,<br>&#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_msgs</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, msgs: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-built_in">Vec</span>&lt;PeerMsg&lt;EK&gt;&gt;) &#123;<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> msgs.drain(..) &#123;<br>            <span class="hljs-keyword">match</span> m &#123;<br>                PeerMsg::RaftMessage(msg) =&gt; &#123;<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Err</span>(e) = <span class="hljs-keyword">self</span>.on_raft_message(msg) &#123;<br>                        error!(%e;<br>                            <span class="hljs-string">"handle raft message err"</span>;<br>                            <span class="hljs-string">"region_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.region_id(),<br>                            <span class="hljs-string">"peer_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.peer_id(),<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::RaftCommand(cmd) =&gt; &#123;<br>                        ...<br>                        <span class="hljs-keyword">self</span>.propose_raft_command(<br>                            cmd.request,<br>                            cmd.callback,<br>                            cmd.extra_opts.disk_full_opt,<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::ApplyRes &#123; res &#125; =&gt; &#123;<br>                    <span class="hljs-keyword">self</span>.on_apply_res(res);<br>                &#125;<br>                ...<br>            &#125;<br>        &#125;<br>&#125;<br><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">propose</span></span>&lt;T: Transport&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>    <span class="hljs-keyword">mut</span> cb: Callback&lt;EK::Snapshot&gt;,<br>    req: RaftCmdRequest,<br>    <span class="hljs-keyword">mut</span> err_resp: RaftCmdResponse,<br>    <span class="hljs-keyword">mut</span> disk_full_opt: DiskFullOpt,<br>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> policy = <span class="hljs-keyword">self</span>.inspect(&amp;req);<br>    <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">match</span> policy &#123;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ReadLocal) | <span class="hljs-literal">Ok</span>(RequestPolicy::StaleRead) =&gt; &#123;<br>            <span class="hljs-keyword">self</span>.read_local(ctx, req, cb);<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex) =&gt; <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.read_index(ctx, req, err_resp, cb),<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeTransferLeader) =&gt; &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.propose_transfer_leader(ctx, req, cb);<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeNormal) =&gt; &#123;<br>            <span class="hljs-comment">// For admin cmds, only region split/merge comes here.</span><br>            <span class="hljs-keyword">if</span> req.has_admin_request() &#123;<br>                disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;<br>            &#125;<br>            <span class="hljs-keyword">self</span>.check_normal_proposal_with_disk_full_opt(ctx, disk_full_opt)<br>                .and_then(|_| <span class="hljs-keyword">self</span>.propose_normal(ctx, req))<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeConfChange) =&gt; <span class="hljs-keyword">self</span>.propose_conf_change(ctx, &amp;req),<br>        <span class="hljs-literal">Err</span>(e) =&gt; <span class="hljs-literal">Err</span>(e),<br>    &#125;;<br>    fail_point!(<span class="hljs-string">"after_propose"</span>);<br><br>     <span class="hljs-keyword">match</span> res &#123;<br>            <span class="hljs-literal">Err</span>(e) =&gt; &#123;<br>                cmd_resp::bind_error(&amp;<span class="hljs-keyword">mut</span> err_resp, e);<br>                cb.invoke_with_response(err_resp);<br>                <span class="hljs-keyword">self</span>.post_propose_fail(req_admin_cmd_type);<br>                <span class="hljs-literal">false</span><br>            &#125;<br>            <span class="hljs-literal">Ok</span>(Either::Right(idx)) =&gt; &#123;<br>                <span class="hljs-keyword">if</span> !cb.is_none() &#123;<br>                    <span class="hljs-keyword">self</span>.cmd_epoch_checker.attach_to_conflict_cmd(idx, cb);<br>                &#125;<br>                <span class="hljs-keyword">self</span>.post_propose_fail(req_admin_cmd_type);<br>                <span class="hljs-literal">false</span><br>            &#125;<br>            <span class="hljs-literal">Ok</span>(Either::Left(idx)) =&gt; &#123;<br>                <span class="hljs-keyword">let</span> has_applied_to_current_term = <span class="hljs-keyword">self</span>.has_applied_to_current_term();<br>                <span class="hljs-keyword">if</span> has_applied_to_current_term &#123;<br>                    <span class="hljs-comment">// After this peer has applied to current term and passed above checking</span><br>                    <span class="hljs-comment">// including `cmd_epoch_checker`, we can safely guarantee</span><br>                    <span class="hljs-comment">// that this proposal will be committed if there is no abnormal leader transfer</span><br>                    <span class="hljs-comment">// in the near future. Thus proposed callback can be called.</span><br>                    cb.invoke_proposed();<br>                &#125;<br>                <span class="hljs-keyword">if</span> is_urgent &#123;<br>                    <span class="hljs-keyword">self</span>.last_urgent_proposal_idx = idx;<br>                    <span class="hljs-comment">// Eager flush to make urgent proposal be applied on all nodes as soon as</span><br>                    <span class="hljs-comment">// possible.</span><br>                    <span class="hljs-keyword">self</span>.raft_group.skip_bcast_commit(<span class="hljs-literal">false</span>);<br>                &#125;<br>                <span class="hljs-keyword">self</span>.should_wake_up = <span class="hljs-literal">true</span>;<br>                <span class="hljs-keyword">let</span> p = Proposal &#123;<br>                    is_conf_change: req_admin_cmd_type == <span class="hljs-literal">Some</span>(AdminCmdType::ChangePeer)<br>                        || req_admin_cmd_type == <span class="hljs-literal">Some</span>(AdminCmdType::ChangePeerV2),<br>                    index: idx,<br>                    term: <span class="hljs-keyword">self</span>.term(),<br>                    cb,<br>                    propose_time: <span class="hljs-literal">None</span>,<br>                    must_pass_epoch_check: has_applied_to_current_term,<br>                &#125;;<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(cmd_type) = req_admin_cmd_type &#123;<br>                    <span class="hljs-keyword">self</span>.cmd_epoch_checker<br>                        .post_propose(cmd_type, idx, <span class="hljs-keyword">self</span>.term());<br>                &#125;<br>                <span class="hljs-keyword">self</span>.post_propose(ctx, p);<br>                <span class="hljs-literal">true</span><br>            &#125;<br>        &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>在调用完 <code>PeerFsmDelegate::handle_msgs</code> 处理完消息后，会再调用 <code>PeerFsmDelegate::collect_ready()</code> 函数，进而进入 <code>Peer::handle_raft_ready_append</code> 函数。在该函数中会收集 normal 状态机的一次 ready，接着对需要持久化的未提交日志进行持久化（延后攒批），需要发送的消息进行异步发送，需要应用的已提交日志发送给 ApplyBatchSystem。</p><p>在三副本情况下，该 PreWrite 请求会存在于本次 ready 需要持久化的日志和需要发往其他两个 peer 的 message 中，对于 message，一旦收到就会 spawn 给 Transport 让其异步发送，对于持久化，在不开启 async-io 的情况下，数据会被暂存到内存中在当前 loop 结尾的 end 函数中实际写入到底层引擎中去。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Collect ready if any.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// Returns false is no readiness is generated.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">collect_ready</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br>    ...<br><br>    <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">self</span>.fsm.peer.handle_raft_ready_append(<span class="hljs-keyword">self</span>.ctx);<br><br>    ...<br><br>&#125;<br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_raft_ready_append</span></span>&lt;T: Transport&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>) -&gt; <span class="hljs-built_in">Option</span>&lt;ReadyResult&gt; &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.raft_group.has_ready() &#123;<br>        fail_point!(<span class="hljs-string">"before_no_ready_gen_snap_task"</span>, |_| <span class="hljs-literal">None</span>);<br>        <span class="hljs-comment">// Generating snapshot task won't set ready for raft group.</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(gen_task) = <span class="hljs-keyword">self</span>.mut_store().take_gen_snap_task() &#123;<br>            <span class="hljs-keyword">self</span>.pending_request_snapshot_count<br>                .fetch_add(<span class="hljs-number">1</span>, Ordering::SeqCst);<br>            ctx.apply_router<br>                .schedule_task(<span class="hljs-keyword">self</span>.region_id, ApplyTask::Snapshot(gen_task));<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>;<br>    &#125;<br><br>    ...<br>    <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> ready = <span class="hljs-keyword">self</span>.raft_group.ready();<br><br>    ...<br><br>    <span class="hljs-keyword">if</span> !ready.must_sync() &#123;<br>        <span class="hljs-comment">// If this ready need not to sync, the term, vote must not be changed,</span><br>        <span class="hljs-comment">// entries and snapshot must be empty.</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(hs) = ready.hs() &#123;<br>            <span class="hljs-built_in">assert_eq!</span>(hs.get_term(), <span class="hljs-keyword">self</span>.get_store().hard_state().get_term());<br>            <span class="hljs-built_in">assert_eq!</span>(hs.get_vote(), <span class="hljs-keyword">self</span>.get_store().hard_state().get_vote());<br>        &#125;<br>        <span class="hljs-built_in">assert!</span>(ready.entries().is_empty());<br>        <span class="hljs-built_in">assert!</span>(ready.snapshot().is_empty());<br>    &#125;<br><br>    <span class="hljs-keyword">self</span>.on_role_changed(ctx, &amp;ready);<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(hs) = ready.hs() &#123;<br>        <span class="hljs-keyword">let</span> pre_commit_index = <span class="hljs-keyword">self</span>.get_store().commit_index();<br>        <span class="hljs-built_in">assert!</span>(hs.get_commit() &gt;= pre_commit_index);<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.is_leader() &#123;<br>            <span class="hljs-keyword">self</span>.on_leader_commit_idx_changed(pre_commit_index, hs.get_commit());<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> !ready.messages().is_empty() &#123;<br>        <span class="hljs-built_in">assert!</span>(<span class="hljs-keyword">self</span>.is_leader());<br>        <span class="hljs-keyword">let</span> raft_msgs = <span class="hljs-keyword">self</span>.build_raft_messages(ctx, ready.take_messages());<br>        <span class="hljs-keyword">self</span>.send_raft_messages(ctx, raft_msgs);<br>    &#125;<br><br>    <span class="hljs-keyword">self</span>.apply_reads(ctx, &amp;ready);<br><br>    <span class="hljs-keyword">if</span> !ready.committed_entries().is_empty() &#123;<br>        <span class="hljs-keyword">self</span>.handle_raft_committed_entries(ctx, ready.take_committed_entries());<br>    &#125;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> ready_number = ready.number();<br>    <span class="hljs-keyword">let</span> persisted_msgs = ready.take_persisted_messages();<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> has_write_ready = <span class="hljs-literal">false</span>;<br>    <span class="hljs-keyword">match</span> &amp;res &#123;<br>        HandleReadyResult::SendIoTask | HandleReadyResult::Snapshot &#123; .. &#125; =&gt; &#123;<br>            <span class="hljs-keyword">if</span> !persisted_msgs.is_empty() &#123;<br>                task.messages = <span class="hljs-keyword">self</span>.build_raft_messages(ctx, persisted_msgs);<br>            &#125;<br><br>            <span class="hljs-keyword">if</span> !trackers.is_empty() &#123;<br>                task.trackers = trackers;<br>            &#125;<br><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(write_worker) = &amp;<span class="hljs-keyword">mut</span> ctx.sync_write_worker &#123;<br>                write_worker.handle_write_task(task);<br><br>                <span class="hljs-built_in">assert_eq!</span>(<span class="hljs-keyword">self</span>.unpersisted_ready, <span class="hljs-literal">None</span>);<br>                <span class="hljs-keyword">self</span>.unpersisted_ready = <span class="hljs-literal">Some</span>(ready);<br>                has_write_ready = <span class="hljs-literal">true</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">self</span>.write_router.send_write_msg(<br>                    ctx,<br>                    <span class="hljs-keyword">self</span>.unpersisted_readies.back().map(|r| r.number),<br>                    WriteMsg::WriteTask(task),<br>                );<br><br>                <span class="hljs-keyword">self</span>.unpersisted_readies.push_back(UnpersistedReady &#123;<br>                    number: ready_number,<br>                    max_empty_number: ready_number,<br>                    raft_msgs: <span class="hljs-built_in">vec!</span>[],<br>                &#125;);<br><br>                <span class="hljs-keyword">self</span>.raft_group.advance_append_async(ready);<br>            &#125;<br>        &#125;<br>        HandleReadyResult::NoIoTask =&gt; &#123;<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(last) = <span class="hljs-keyword">self</span>.unpersisted_readies.back_mut() &#123;<br>                <span class="hljs-comment">// Attach to the last unpersisted ready so that it can be considered to be</span><br>                <span class="hljs-comment">// persisted with the last ready at the same time.</span><br>                <span class="hljs-keyword">if</span> ready_number &lt;= last.max_empty_number &#123;<br>                    <span class="hljs-built_in">panic!</span>(<br>                        <span class="hljs-string">"&#123;&#125; ready number is not monotonically increaing, &#123;&#125; &lt;= &#123;&#125;"</span>,<br>                        <span class="hljs-keyword">self</span>.tag, ready_number, last.max_empty_number<br>                    );<br>                &#125;<br>                last.max_empty_number = ready_number;<br><br>                <span class="hljs-keyword">if</span> !persisted_msgs.is_empty() &#123;<br>                    <span class="hljs-keyword">self</span>.unpersisted_message_count += persisted_msgs.capacity();<br>                    last.raft_msgs.push(persisted_msgs);<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">// If this ready don't need to be persisted and there is no previous unpersisted</span><br>                <span class="hljs-comment">// ready, we can safely consider it is persisted so the persisted msgs can be</span><br>                <span class="hljs-comment">// sent immediately.</span><br>                <span class="hljs-keyword">self</span>.persisted_number = ready_number;<br><br>                <span class="hljs-keyword">if</span> !persisted_msgs.is_empty() &#123;<br>                    fail_point!(<span class="hljs-string">"raft_before_follower_send"</span>);<br>                    <span class="hljs-keyword">let</span> msgs = <span class="hljs-keyword">self</span>.build_raft_messages(ctx, persisted_msgs);<br>                    <span class="hljs-keyword">self</span>.send_raft_messages(ctx, msgs);<br>                &#125;<br><br>                <span class="hljs-comment">// The commit index and messages of light ready should be empty because no data</span><br>                <span class="hljs-comment">// needs to be persisted.</span><br>                <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> light_rd = <span class="hljs-keyword">self</span>.raft_group.advance_append(ready);<br><br>                <span class="hljs-keyword">self</span>.add_light_ready_metric(&amp;light_rd, &amp;<span class="hljs-keyword">mut</span> ctx.raft_metrics);<br><br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(idx) = light_rd.commit_index() &#123;<br>                    <span class="hljs-built_in">panic!</span>(<br>                        <span class="hljs-string">"&#123;&#125; advance ready that has no io task but commit index is changed to &#123;&#125;"</span>,<br>                        <span class="hljs-keyword">self</span>.tag, idx<br>                    );<br>                &#125;<br>                <span class="hljs-keyword">if</span> !light_rd.messages().is_empty() &#123;<br>                    <span class="hljs-built_in">panic!</span>(<br>                        <span class="hljs-string">"&#123;&#125; advance ready that has no io task but message is not empty &#123;:?&#125;"</span>,<br>                        <span class="hljs-keyword">self</span>.tag,<br>                        light_rd.messages()<br>                    );<br>                &#125;<br>                <span class="hljs-comment">// The committed entries may not be empty when the size is too large to</span><br>                <span class="hljs-comment">// be fetched in the previous ready.</span><br>                <span class="hljs-keyword">if</span> !light_rd.committed_entries().is_empty() &#123;<br>                    <span class="hljs-keyword">self</span>.handle_raft_committed_entries(ctx, light_rd.take_committed_entries());<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></div></td></tr></table></figure><p>等到任何一个 follower 返回确认后，该 response 会被路由到 RaftBatchSystem，PollHandler 在接下来的一次 loop 中对其进行处理，该请求会被路由到 <code>PeerFsmDelegate::handle_msgs</code> 函数的 <code>PeerMsg::RaftMessage(msg)</code> 分支中，进而调用 step 函数交给 raft-rs 状态机进行处理。</p><p>由于此时已经满足了 quorum 的写入，raft-rs 会将该 PreWrite 请求对应的 raftlog 进行提交并在下一次被获取 ready 时返回，在本轮 loop 的 <code>PeerFsmDelegate::collect_ready()</code> 函数及 <code>Peer::handle_raft_ready_append</code> 函数中，会调用 <code>self.handle_raft_committed_entries(ctx, ready.take_committed_entries())</code> 函数。在该函数中，其会根据已提交日志从 Peer 的 <code>proposals</code> 中获取到对应的 callback，连带这一批所有的已提交日志构建一个 Apply Task 通过 apply_router 发送给 ApplyBatchSystem。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;<span class="hljs-symbol">'a</span>, EK, ER, T: Transport&gt; PeerFsmDelegate&lt;<span class="hljs-symbol">'a</span>, EK, ER, T&gt;<br><span class="hljs-keyword">where</span><br>    EK: KvEngine,<br>    ER: RaftEngine,<br>&#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_msgs</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, msgs: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-built_in">Vec</span>&lt;PeerMsg&lt;EK&gt;&gt;) &#123;<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> msgs.drain(..) &#123;<br>            <span class="hljs-keyword">match</span> m &#123;<br>                PeerMsg::RaftMessage(msg) =&gt; &#123;<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Err</span>(e) = <span class="hljs-keyword">self</span>.on_raft_message(msg) &#123;<br>                        error!(%e;<br>                            <span class="hljs-string">"handle raft message err"</span>;<br>                            <span class="hljs-string">"region_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.region_id(),<br>                            <span class="hljs-string">"peer_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.peer_id(),<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::RaftCommand(cmd) =&gt; &#123;<br>                        ...<br>                        <span class="hljs-keyword">self</span>.propose_raft_command(<br>                            cmd.request,<br>                            cmd.callback,<br>                            cmd.extra_opts.disk_full_opt,<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::ApplyRes &#123; res &#125; =&gt; &#123;<br>                    <span class="hljs-keyword">self</span>.on_apply_res(res);<br>                &#125;<br>                ...<br>            &#125;<br>        &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_raft_committed_entries</span></span>&lt;T&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>    committed_entries: <span class="hljs-built_in">Vec</span>&lt;Entry&gt;,<br>) &#123;<br>    <span class="hljs-keyword">if</span> committed_entries.is_empty() &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br><br>    ...<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(last_entry) = committed_entries.last() &#123;<br>        <span class="hljs-keyword">self</span>.last_applying_idx = last_entry.get_index();<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.last_applying_idx &gt;= <span class="hljs-keyword">self</span>.last_urgent_proposal_idx &#123;<br>            <span class="hljs-comment">// Urgent requests are flushed, make it lazy again.</span><br>            <span class="hljs-keyword">self</span>.raft_group.skip_bcast_commit(<span class="hljs-literal">true</span>);<br>            <span class="hljs-keyword">self</span>.last_urgent_proposal_idx = <span class="hljs-built_in">u64</span>::MAX;<br>        &#125;<br>        <span class="hljs-keyword">let</span> cbs = <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.proposals.is_empty() &#123;<br>            <span class="hljs-keyword">let</span> current_term = <span class="hljs-keyword">self</span>.term();<br>            <span class="hljs-keyword">let</span> cbs = committed_entries<br>                .iter()<br>                .filter_map(|e| &#123;<br>                    <span class="hljs-keyword">self</span>.proposals<br>                        .find_proposal(e.get_term(), e.get_index(), current_term)<br>                &#125;)<br>                .map(|<span class="hljs-keyword">mut</span> p| &#123;<br>                    <span class="hljs-keyword">if</span> p.must_pass_epoch_check &#123;<br>                        <span class="hljs-comment">// In this case the apply can be guaranteed to be successful. Invoke the</span><br>                        <span class="hljs-comment">// on_committed callback if necessary.</span><br>                        p.cb.invoke_committed();<br>                    &#125;<br>                    p<br>                &#125;)<br>                .collect();<br>            <span class="hljs-keyword">self</span>.proposals.gc();<br>            cbs<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-built_in">vec!</span>[]<br>        &#125;;<br>        <span class="hljs-comment">// Note that the `commit_index` and `commit_term` here may be used to</span><br>        <span class="hljs-comment">// forward the commit index. So it must be less than or equal to persist</span><br>        <span class="hljs-comment">// index.</span><br>        <span class="hljs-keyword">let</span> commit_index = cmp::min(<br>            <span class="hljs-keyword">self</span>.raft_group.raft.raft_log.committed,<br>            <span class="hljs-keyword">self</span>.raft_group.raft.raft_log.persisted,<br>        );<br>        <span class="hljs-keyword">let</span> commit_term = <span class="hljs-keyword">self</span>.get_store().term(commit_index).unwrap();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> apply = Apply::new(<br>            <span class="hljs-keyword">self</span>.peer_id(),<br>            <span class="hljs-keyword">self</span>.region_id,<br>            <span class="hljs-keyword">self</span>.term(),<br>            commit_index,<br>            commit_term,<br>            committed_entries,<br>            cbs,<br>            <span class="hljs-keyword">self</span>.region_buckets.as_ref().map(|b| b.meta.clone()),<br>        );<br>        apply.on_schedule(&amp;ctx.raft_metrics);<br>        <span class="hljs-keyword">self</span>.mut_store()<br>            .trace_cached_entries(apply.entries[<span class="hljs-number">0</span>].clone());<br>        <span class="hljs-keyword">if</span> needs_evict_entry_cache(ctx.cfg.evict_cache_on_memory_ratio) &#123;<br>            <span class="hljs-comment">// Compact all cached entries instead of half evict.</span><br>            <span class="hljs-keyword">self</span>.mut_store().evict_entry_cache(<span class="hljs-literal">false</span>);<br>        &#125;<br>        ctx.apply_router<br>            .schedule_task(<span class="hljs-keyword">self</span>.region_id, ApplyTask::apply(apply));<br>    &#125;<br>    fail_point!(<span class="hljs-string">"after_send_to_apply_1003"</span>, <span class="hljs-keyword">self</span>.peer_id() == <span class="hljs-number">1003</span>, |_| &#123;&#125;);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>此时直接定位到 <code>ApplyPoller</code> 的 <code>handle_normal</code> 函数，可以看到，<code>ApplyPoller</code> 也会首先尝试获取 <code>messages_per_tick</code> 次路由到该状态机的消息，接着调用 <code>ApplyFSM::handle_tasks</code> 函数进行处理。然后其会经历 <code>ApplyFSM::handle_apply -&gt;  ApplyDelegate::handle_raft_committed_entries</code> 的调用链来到 <code>ApplyDelegate::handle_raft_entry_normal</code> 函数中，在该函数中，会尝试将调用 <code>ApplyDelegate::process_raft_cmd</code> 函数来将本次写入缓存到 <code>kv_write_batch</code> 中，值得一提的是，在写入缓存之前会首先判断是否能够进行一次提交，如果可以则需要在写入缓存之前将这一批日志提交到底层引擎。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_normal</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, normal: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">impl</span> DerefMut&lt;Target = ApplyFsm&lt;EK&gt;&gt;) -&gt; HandleResult &#123;<br><br>    ...<br>    <br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.msg_buf.len() &lt; <span class="hljs-keyword">self</span>.messages_per_tick &#123;<br>        <span class="hljs-keyword">match</span> normal.receiver.try_recv() &#123;<br>            <span class="hljs-literal">Ok</span>(msg) =&gt; <span class="hljs-keyword">self</span>.msg_buf.push(msg),<br>            <span class="hljs-literal">Err</span>(TryRecvError::Empty) =&gt; &#123;<br>                handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-literal">Err</span>(TryRecvError::Disconnected) =&gt; &#123;<br>                normal.delegate.stopped = <span class="hljs-literal">true</span>;<br>                handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    normal.handle_tasks(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.apply_ctx, &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.msg_buf);<br><br>    <span class="hljs-keyword">if</span> normal.delegate.wait_merge_state.is_some() &#123;<br>        <span class="hljs-comment">// Check it again immediately as catching up logs can be very fast.</span><br>        handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> normal.delegate.yield_state.is_some() &#123;<br>        <span class="hljs-comment">// Let it continue to run next time.</span><br>        handle_result = HandleResult::KeepProcessing;<br>    &#125;<br>    handle_result<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_raft_entry_normal</span></span>(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    apply_ctx: &amp;<span class="hljs-keyword">mut</span> ApplyContext&lt;EK&gt;,<br>    entry: &amp;Entry,<br>) -&gt; ApplyResult&lt;EK::Snapshot&gt; &#123;<br>    fail_point!(<br>        <span class="hljs-string">"yield_apply_first_region"</span>,<br>        <span class="hljs-keyword">self</span>.region.get_start_key().is_empty() &amp;&amp; !<span class="hljs-keyword">self</span>.region.get_end_key().is_empty(),<br>        |_| ApplyResult::Yield<br>    );<br><br>    <span class="hljs-keyword">let</span> index = entry.get_index();<br>    <span class="hljs-keyword">let</span> term = entry.get_term();<br>    <span class="hljs-keyword">let</span> data = entry.get_data();<br><br>    <span class="hljs-keyword">if</span> !data.is_empty() &#123;<br>        <span class="hljs-keyword">let</span> cmd = util::parse_data_at(data, index, &amp;<span class="hljs-keyword">self</span>.tag);<br><br>        <span class="hljs-keyword">if</span> apply_ctx.yield_high_latency_operation &amp;&amp; has_high_latency_operation(&amp;cmd) &#123;<br>            <span class="hljs-keyword">self</span>.priority = Priority::Low;<br>        &#125;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> has_unflushed_data =<br>            <span class="hljs-keyword">self</span>.last_flush_applied_index != <span class="hljs-keyword">self</span>.apply_state.get_applied_index();<br>        <span class="hljs-keyword">if</span> has_unflushed_data &amp;&amp; should_write_to_engine(&amp;cmd)<br>            || apply_ctx.kv_wb().should_write_to_engine()<br>        &#123;<br>            apply_ctx.commit(<span class="hljs-keyword">self</span>);<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(start) = <span class="hljs-keyword">self</span>.handle_start.as_ref() &#123;<br>                <span class="hljs-keyword">if</span> start.saturating_elapsed() &gt;= apply_ctx.yield_duration &#123;<br>                    <span class="hljs-keyword">return</span> ApplyResult::Yield;<br>                &#125;<br>            &#125;<br>            has_unflushed_data = <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.priority != apply_ctx.priority &#123;<br>            <span class="hljs-keyword">if</span> has_unflushed_data &#123;<br>                apply_ctx.commit(<span class="hljs-keyword">self</span>);<br>            &#125;<br>            <span class="hljs-keyword">return</span> ApplyResult::Yield;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.process_raft_cmd(apply_ctx, index, term, cmd);<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></div></td></tr></table></figure><p>那么为什么不像 RaftBatchSystem 一样在 end 函数中统一进行攒批提交呢？原因是此时只要攒够一定的大小不对底层引擎造成过大的负载就可以快速提交并返回客户端了，等到最后再去处理只会增加写入延时而没有太大的收益。</p><p>让我们阅读一下提交 batch 的逻辑，其会经由 <code>ApplyContext::commit -&gt; ApplyContext::commit_opt</code> 的调用链来到 <code>ApplyContext::write_to_db</code> 函数，在该函数中，会调用 <code>self.kv_wb_mut().write_opt(&amp;write_opts)</code> 函数将该 <code>WriteBatch</code> 提交到底层引擎，接着在最后调用 <code>cb.invoke_with_response(resp)</code> 来执行 callback 尽快返回客户端。 </p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Commits all changes have done for delegate. `persistent` indicates</span><br><span class="hljs-comment">/// whether write the changes into rocksdb.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// This call is valid only when it's between a `prepare_for` and</span><br><span class="hljs-comment">/// `finish_for`.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">commit</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, delegate: &amp;<span class="hljs-keyword">mut</span> ApplyDelegate&lt;EK&gt;) &#123;<br>    <span class="hljs-keyword">if</span> delegate.last_flush_applied_index &lt; delegate.apply_state.get_applied_index() &#123;<br>        delegate.write_apply_state(<span class="hljs-keyword">self</span>.kv_wb_mut());<br>    &#125;<br>    <span class="hljs-keyword">self</span>.commit_opt(delegate, <span class="hljs-literal">true</span>);<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">commit_opt</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, delegate: &amp;<span class="hljs-keyword">mut</span> ApplyDelegate&lt;EK&gt;, persistent: <span class="hljs-built_in">bool</span>) &#123;<br>    delegate.update_metrics(<span class="hljs-keyword">self</span>);<br>    <span class="hljs-keyword">if</span> persistent &#123;<br>        <span class="hljs-keyword">self</span>.write_to_db();<br>        <span class="hljs-keyword">self</span>.prepare_for(delegate);<br>        delegate.last_flush_applied_index = delegate.apply_state.get_applied_index()<br>    &#125;<br>    <span class="hljs-keyword">self</span>.kv_wb_last_bytes = <span class="hljs-keyword">self</span>.kv_wb().data_size() <span class="hljs-keyword">as</span> <span class="hljs-built_in">u64</span>;<br>    <span class="hljs-keyword">self</span>.kv_wb_last_keys = <span class="hljs-keyword">self</span>.kv_wb().count() <span class="hljs-keyword">as</span> <span class="hljs-built_in">u64</span>;<br>&#125;<br><br><span class="hljs-comment">/// Writes all the changes into RocksDB.</span><br><span class="hljs-comment">/// If it returns true, all pending writes are persisted in engines.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">write_to_db</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br>    <span class="hljs-keyword">let</span> need_sync = <span class="hljs-keyword">self</span>.sync_log_hint;<br>    <span class="hljs-comment">// There may be put and delete requests after ingest request in the same fsm.</span><br>    <span class="hljs-comment">// To guarantee the correct order, we must ingest the pending_sst first, and</span><br>    <span class="hljs-comment">// then persist the kv write batch to engine.</span><br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.pending_ssts.is_empty() &#123;<br>        <span class="hljs-keyword">let</span> tag = <span class="hljs-keyword">self</span>.tag.clone();<br>        <span class="hljs-keyword">self</span>.importer<br>            .ingest(&amp;<span class="hljs-keyword">self</span>.pending_ssts, &amp;<span class="hljs-keyword">self</span>.engine)<br>            .unwrap_or_else(|e| &#123;<br>                <span class="hljs-built_in">panic!</span>(<br>                    <span class="hljs-string">"&#123;&#125; failed to ingest ssts &#123;:?&#125;: &#123;:?&#125;"</span>,<br>                    tag, <span class="hljs-keyword">self</span>.pending_ssts, e<br>                );<br>            &#125;);<br>        <span class="hljs-keyword">self</span>.pending_ssts = <span class="hljs-built_in">vec!</span>[];<br>    &#125;<br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.kv_wb_mut().is_empty() &#123;<br>        <span class="hljs-keyword">self</span>.perf_context.start_observe();<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> write_opts = engine_traits::WriteOptions::new();<br>        write_opts.set_sync(need_sync);<br>        <span class="hljs-keyword">self</span>.kv_wb_mut().write_opt(&amp;write_opts).unwrap_or_else(|e| &#123;<br>            <span class="hljs-built_in">panic!</span>(<span class="hljs-string">"failed to write to engine: &#123;:?&#125;"</span>, e);<br>        &#125;);<br>        <span class="hljs-keyword">let</span> trackers: <span class="hljs-built_in">Vec</span>&lt;_&gt; = <span class="hljs-keyword">self</span><br>            .applied_batch<br>            .cb_batch<br>            .iter()<br>            .flat_map(|(cb, _)| cb.write_trackers())<br>            .flat_map(|trackers| trackers.iter().map(|t| t.as_tracker_token()))<br>            .flatten()<br>            .collect();<br>        <span class="hljs-keyword">self</span>.perf_context.report_metrics(&amp;trackers);<br>        <span class="hljs-keyword">self</span>.sync_log_hint = <span class="hljs-literal">false</span>;<br>        <span class="hljs-keyword">let</span> data_size = <span class="hljs-keyword">self</span>.kv_wb().data_size();<br>        <span class="hljs-keyword">if</span> data_size &gt; APPLY_WB_SHRINK_SIZE &#123;<br>            <span class="hljs-comment">// Control the memory usage for the WriteBatch.</span><br>            <span class="hljs-keyword">self</span>.kv_wb = <span class="hljs-keyword">self</span>.engine.write_batch_with_cap(DEFAULT_APPLY_WB_SIZE);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// Clear data, reuse the WriteBatch, this can reduce memory allocations and</span><br>            <span class="hljs-comment">// deallocations.</span><br>            <span class="hljs-keyword">self</span>.kv_wb_mut().clear();<br>        &#125;<br>        <span class="hljs-keyword">self</span>.kv_wb_last_bytes = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">self</span>.kv_wb_last_keys = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.delete_ssts.is_empty() &#123;<br>        <span class="hljs-keyword">let</span> tag = <span class="hljs-keyword">self</span>.tag.clone();<br>        <span class="hljs-keyword">for</span> sst <span class="hljs-keyword">in</span> <span class="hljs-keyword">self</span>.delete_ssts.drain(..) &#123;<br>            <span class="hljs-keyword">self</span>.importer.delete(&amp;sst.meta).unwrap_or_else(|e| &#123;<br>                <span class="hljs-built_in">panic!</span>(<span class="hljs-string">"&#123;&#125; cleanup ingested file &#123;:?&#125;: &#123;:?&#125;"</span>, tag, sst, e);<br>            &#125;);<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// Take the applied commands and their callback</span><br>    <span class="hljs-keyword">let</span> ApplyCallbackBatch &#123;<br>        cmd_batch,<br>        batch_max_level,<br>        <span class="hljs-keyword">mut</span> cb_batch,<br>    &#125; = mem::replace(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.applied_batch, ApplyCallbackBatch::new());<br>    <span class="hljs-comment">// Call it before invoking callback for preventing Commit is executed before</span><br>    <span class="hljs-comment">// Prewrite is observed.</span><br>    <span class="hljs-keyword">self</span>.host<br>        .on_flush_applied_cmd_batch(batch_max_level, cmd_batch, &amp;<span class="hljs-keyword">self</span>.engine);<br>    <span class="hljs-comment">// Invoke callbacks</span><br>    <span class="hljs-keyword">let</span> now = std::time::Instant::now();<br>    <span class="hljs-keyword">for</span> (cb, resp) <span class="hljs-keyword">in</span> cb_batch.drain(..) &#123;<br>        <span class="hljs-keyword">for</span> tracker <span class="hljs-keyword">in</span> cb.write_trackers().iter().flat_map(|v| *v) &#123;<br>            tracker.observe(now, &amp;<span class="hljs-keyword">self</span>.apply_time, |t| &amp;<span class="hljs-keyword">mut</span> t.metrics.apply_time_nanos);<br>        &#125;<br>        cb.invoke_with_response(resp);<br>    &#125;<br>    <span class="hljs-keyword">self</span>.apply_time.flush();<br>    <span class="hljs-keyword">self</span>.apply_wait.flush();<br>    need_sync<br>&#125;<br></code></pre></div></td></tr></table></figure><p>在 <code>ApplyPoller</code> 一轮 loop 结尾的 end 函数中，其会调用 <code>ApplyContext::flush</code> 函数，进而通过 <code>self.notifier.notify(apply_res)</code> 将 ApplyRes 重新发送到 RaftBatchSystem 中去，进而更新某些内存结构，此处不再赘述。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">end</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, fsms: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">Option</span>&lt;<span class="hljs-keyword">impl</span> DerefMut&lt;Target = ApplyFsm&lt;EK&gt;&gt;&gt;]) &#123;<br>    <span class="hljs-keyword">self</span>.apply_ctx.flush();<br>    <span class="hljs-keyword">for</span> fsm <span class="hljs-keyword">in</span> fsms.iter_mut().flatten() &#123;<br>        fsm.delegate.last_flush_applied_index = fsm.delegate.apply_state.get_applied_index();<br>        fsm.delegate.update_memory_trace(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.trace_event);<br>    &#125;<br>    MEMTRACE_APPLYS.trace(mem::take(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.trace_event));<br>&#125;<br><br>    <span class="hljs-comment">/// Flush all pending writes to engines.</span><br><span class="hljs-comment">/// If it returns true, all pending writes are persisted in engines.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">flush</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br>    <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> this check is too hacky, need to be more verbose and less buggy.</span><br>    <span class="hljs-keyword">let</span> t = <span class="hljs-keyword">match</span> <span class="hljs-keyword">self</span>.timer.take() &#123;<br>        <span class="hljs-literal">Some</span>(t) =&gt; t,<br>        <span class="hljs-literal">None</span> =&gt; <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>,<br>    &#125;;<br><br>    <span class="hljs-comment">// Write to engine</span><br>    <span class="hljs-comment">// raftstore.sync-log = true means we need prevent data loss when power failure.</span><br>    <span class="hljs-comment">// take raft log gc for example, we write kv WAL first, then write raft WAL,</span><br>    <span class="hljs-comment">// if power failure happen, raft WAL may synced to disk, but kv WAL may not.</span><br>    <span class="hljs-comment">// so we use sync-log flag here.</span><br>    <span class="hljs-keyword">let</span> is_synced = <span class="hljs-keyword">self</span>.write_to_db();<br><br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.apply_res.is_empty() &#123;<br>        fail_point!(<span class="hljs-string">"before_nofity_apply_res"</span>);<br>        <span class="hljs-keyword">let</span> apply_res = mem::take(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.apply_res);<br>        <span class="hljs-keyword">self</span>.notifier.notify(apply_res);<br>    &#125;<br><br>    <span class="hljs-keyword">let</span> elapsed = t.saturating_elapsed();<br>    STORE_APPLY_LOG_HISTOGRAM.observe(duration_to_sec(elapsed) <span class="hljs-keyword">as</span> <span class="hljs-built_in">f64</span>);<br>    <span class="hljs-keyword">for</span> <span class="hljs-keyword">mut</span> inspector <span class="hljs-keyword">in</span> std::mem::take(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.pending_latency_inspect) &#123;<br>        inspector.record_apply_process(elapsed);<br>        inspector.finish();<br>    &#125;<br><br>    slow_log!(<br>        elapsed,<br>        <span class="hljs-string">"&#123;&#125; handle ready &#123;&#125; committed entries"</span>,<br>        <span class="hljs-keyword">self</span>.tag,<br>        <span class="hljs-keyword">self</span>.committed_count<br>    );<br>    <span class="hljs-keyword">self</span>.committed_count = <span class="hljs-number">0</span>;<br>    is_synced<br>&#125;<br></code></pre></div></td></tr></table></figure><p>通过本小节，希望您能够了解 PreWrite 请求的完整流程，并进而具备分析其他写请求全链路的能力。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客介绍了 TiKV 中一条写请求的全链路流程。</p><p>希望本博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>感谢您的阅读~</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>源码阅读</tag>
      
      <tag>TiKV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TiKV 源码阅读三部曲（二）读流程</title>
    <link href="/tikv-source-code-reading-read/"/>
    <url>/tikv-source-code-reading-read/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://github.com/tikv/tikv" target="_blank" rel="noopener">TiKV</a> 是一个支持事务的分布式 Key-Value 数据库，目前已经是 <a href="https://www.cncf.io/projects/" target="_blank" rel="noopener">CNCF 基金会</a> 的顶级项目。</p><p>作为一个新同学，需要一定的前期准备才能够有能力参与 TiKV 社区的代码开发，包括但不限于学习 Rust 语言，理解 TiKV 的原理和在前两者的基础上了解熟悉 TiKV 的源码。</p><p><a href="https://pingcap.com/zh/blog/?tag=TiKV%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90" target="_blank" rel="noopener">TiKV 官方源码解析文档</a> 详细地介绍了 TiKV 3.x 版本重要模块的设计要点，主要流程和相应代码片段，是学习 TiKV 源码必读的学习资料。当前 TiKV 已经迭代到了 6.x 版本，不仅引入了很多新的功能和优化，而且对源码也进行了多次重构，因而一些官方源码解析文档中的代码片段已经不复存在，这使得读者在阅读源码解析文档时无法对照最新源码加深理解；此外尽管 TiKV 官方源码解析文档系统地介绍了若干重要模块的工作，但并没有将读写流程全链路串起来去介绍经过的模块和对应的代码片段，实际上尽快地熟悉读写流程全链路会更利于新同学从全局角度理解代码。</p><p>基于以上存在的问题，笔者将基于 6.1 版本的源码撰写三篇博客，分别介绍以下三个方面：</p><ul><li><a href="https://tanxinyu.work/tikv-source-code-reading-module/">TiKV 源码阅读三部曲（一）重要模块</a>：TiKV 的基本概念，TiKV 读写路径上的三个重要模块（KVService，Storage，RaftStore）和断点调试 TiKV 学习源码的方案</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-read/">TiKV 源码阅读三部曲（二）读流程</a>：TiKV 中一条读请求的全链路流程</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-write/">TiKV 源码阅读三部曲（三）写流程</a>：TiKV 中一条写请求的全链路流程</li></ul><p>希望此三篇博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>本文为第二篇博客，将主要介绍 TiKV 中一条读请求的全链路流程。</p><h2 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h2><p><a href="https://pingcap.com/zh/blog/tikv-source-code-reading-19" target="_blank" rel="noopener">TiKV 源码解析系列文章（十九）read index 和 local read 情景分析</a> 介绍了 TiKV 3.x 版本的 ReadIndex/LeaseRead 实现方案。</p><p>本小节将在 TiKV 6.1 版本的源码基础上，以一条读请求为例，介绍当前版本读请求的全链路执行流程。</p><p>前文已经提到，可以从 <a href="https://github.com/pingcap/kvproto/blob/master/proto/tikvpb.proto#L20" target="_blank" rel="noopener">kvproto</a> 对应的 <code>service Tikv</code> 中了解当前 TiKV 支持的 RPC 接口。</p><p>经过简单整理，常用的读接口如下：</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-comment">// Key/value store API for TiKV.</span><br>service Tikv &#123; <br><br>    rpc KvGet(kvrpcpb.GetRequest) returns (kvrpcpb.GetResponse) &#123;&#125;<br>    rpc KvScan(kvrpcpb.ScanRequest) returns (kvrpcpb.ScanResponse) &#123;&#125;<br>    rpc KvBatchGet(kvrpcpb.BatchGetRequest) returns (kvrpcpb.BatchGetResponse) &#123;&#125;<br><br>    rpc RawGet(kvrpcpb.RawGetRequest) returns (kvrpcpb.RawGetResponse) &#123;&#125;<br>    rpc RawBatchGet(kvrpcpb.RawBatchGetRequest) returns (kvrpcpb.RawBatchGetResponse) &#123;&#125;<br>    rpc RawScan(kvrpcpb.RawScanRequest) returns (kvrpcpb.RawScanResponse) &#123;&#125;<br>    rpc RawBatchScan(kvrpcpb.RawBatchScanRequest) returns (kvrpcpb.RawBatchScanResponse) &#123;&#125;<br><br>    ...<br>&#125;<br></code></pre></div></td></tr></table></figure><p>以下将以最常用的 KvGet 接口为例介绍读流程，其他的读接口所经过的模块大致相似，之后也可以用断点调试的方案去自行阅读。</p><h3 id="KVService"><a href="#KVService" class="headerlink" title="KVService"></a>KVService</h3><p>在 KVService 中， handle_request 宏将业务逻辑封装到了 future_get 函数中。在 future_get 函数中，主要使用了 <code>storage.get(req.take_context(), Key::from_raw(req.get_key()), req.get_version().into())</code> 函数将请求路由到 Storage 模块去执行。</p><p>为了可观测性，当前 TiKV 在读写关键路径上加了很多全局和 request 级别的 metric，这一定程度上影响了刚开始阅读代码的体验。其实刚开始熟悉代码时只需要关注核心逻辑即可，metric 相关的代码可以先不用细究。 </p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-keyword">impl</span>&lt;T: RaftStoreRouter&lt;E::Local&gt; + <span class="hljs-symbol">'static</span>, E: Engine, L: LockManager, F: KvFormat&gt; Tikv<br>    <span class="hljs-keyword">for</span> Service&lt;T, E, L, F&gt;<br>&#123;<br>    handle_request!(kv_get, future_get, GetRequest, GetResponse, has_time_detail);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">future_get</span></span>&lt;E: Engine, L: LockManager, F: KvFormat&gt;(<br>    storage: &amp;Storage&lt;E, L, F&gt;,<br>    <span class="hljs-keyword">mut</span> req: GetRequest,<br>) -&gt; <span class="hljs-keyword">impl</span> Future&lt;Output = ServerResult&lt;GetResponse&gt;&gt; &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> v = storage.get(<br>        req.take_context(),<br>        Key::from_raw(req.get_key()),<br>        req.get_version().into(),<br>    );<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>        <span class="hljs-keyword">let</span> v = v.<span class="hljs-keyword">await</span>;<br>        <br>        ...<br>        <br>        <span class="hljs-literal">Ok</span>(resp)<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p>在 Storage 模块的 get 函数中，所有的 task 都会被 spawn 到 readPool 中执行，具体执行的任务主要包含以下两个工作：</p><ul><li>使用 <code>Self::with_tls_engine(|engine| Self::snapshot(engine, snap_ctx)).await?</code> 获取 snapshot</li><li>使用 <code>snap_store.get(&amp;key, &amp;mut statistics)</code> 基于获取到的 snapshot 获取符合对应事务语义的数据</li></ul><p>第二个工作比较简单，本小节不再赘述，以下主要介绍第一个工作的具体代码流程。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-comment">/// Get value of the given key from a snapshot.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// Only writes that are committed before `start_ts` are visible.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">get</span></span>(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    <span class="hljs-keyword">mut</span> ctx: Context,<br>    key: Key,<br>    start_ts: TimeStamp,<br>) -&gt; <span class="hljs-keyword">impl</span> Future&lt;Output = <span class="hljs-built_in">Result</span>&lt;(<span class="hljs-built_in">Option</span>&lt;Value&gt;, KvGetStatistics)&gt;&gt; &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">self</span>.read_pool.spawn_handle(<br>        <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br><br>            ...<br><br>            <span class="hljs-keyword">let</span> snap_ctx = prepare_snap_ctx(<br>                &amp;ctx,<br>                iter::once(&amp;key),<br>                start_ts,<br>                &amp;bypass_locks,<br>                &amp;concurrency_manager,<br>                CMD,<br>            )?;<br>            <span class="hljs-keyword">let</span> snapshot =<br>                Self::with_tls_engine(|engine| Self::snapshot(engine, snap_ctx)).<span class="hljs-keyword">await</span>?;<br><br>            &#123;<br>                <span class="hljs-keyword">let</span> begin_instant = Instant::now();<br>                <span class="hljs-keyword">let</span> stage_snap_recv_ts = begin_instant;<br>                <span class="hljs-keyword">let</span> buckets = snapshot.ext().get_buckets();<br>                <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> statistics = Statistics::default();<br>                <span class="hljs-keyword">let</span> result = Self::with_perf_context(CMD, || &#123;<br>                    <span class="hljs-keyword">let</span> _guard = sample.observe_cpu();<br>                    <span class="hljs-keyword">let</span> snap_store = SnapshotStore::new(<br>                        snapshot,<br>                        start_ts,<br>                        ctx.get_isolation_level(),<br>                        !ctx.get_not_fill_cache(),<br>                        bypass_locks,<br>                        access_locks,<br>                        <span class="hljs-literal">false</span>,<br>                    );<br>                    snap_store<br>                    .get(&amp;key, &amp;<span class="hljs-keyword">mut</span> statistics)<br>                    <span class="hljs-comment">// map storage::txn::Error -&gt; storage::Error</span><br>                    .map_err(Error::from)<br>                    .map(|r| &#123;<br>                        KV_COMMAND_KEYREAD_HISTOGRAM_STATIC.get(CMD).observe(<span class="hljs-number">1_f64</span>);<br>                        r<br>                    &#125;)<br>                &#125;);<br>                <br>                ...<br>        <br>                <span class="hljs-literal">Ok</span>((<br>                    result?,<br>                    KvGetStatistics &#123;<br>                        stats: statistics,<br>                        latency_stats,<br>                    &#125;,<br>                ))<br>            &#125;<br>        &#125;<br>        .in_resource_metering_tag(resource_tag),<br>        priority,<br>        thread_rng().next_u64(),<br>    );<br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>        res.map_err(|_| Error::from(ErrorInner::SchedTooBusy))<br>            .<span class="hljs-keyword">await</span>?<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>对于 <code>Self::snapshot(engine, snap_ctx)</code> 函数，其会经由 <code>storage::snapshot -&gt; kv::snapshot -&gt; raftkv::async_snapshot -&gt; raftkv::exec_snapshot</code> 的调用链来到 <code>ServerRaftStoreRouter::read</code> 函数中。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Get a snapshot of `engine`.</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">snapshot</span></span>(<br>    engine: &amp;E,<br>    ctx: SnapContext&lt;<span class="hljs-symbol">'_</span>&gt;,<br>) -&gt; <span class="hljs-keyword">impl</span> std::future::Future&lt;Output = <span class="hljs-built_in">Result</span>&lt;E::Snap&gt;&gt; &#123;<br>    kv::snapshot(engine, ctx)<br>        .map_err(txn::Error::from)<br>        .map_err(Error::from)<br>&#125;<br><br><span class="hljs-comment">/// Get a snapshot of `engine`.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">snapshot</span></span>&lt;E: Engine&gt;(<br>    engine: &amp;E,<br>    ctx: SnapContext&lt;<span class="hljs-symbol">'_</span>&gt;,<br>) -&gt; <span class="hljs-keyword">impl</span> std::future::Future&lt;Output = <span class="hljs-built_in">Result</span>&lt;E::Snap&gt;&gt; &#123;<br>    <span class="hljs-keyword">let</span> begin = Instant::now();<br>    <span class="hljs-keyword">let</span> (callback, future) =<br>        tikv_util::future::paired_must_called_future_callback(drop_snapshot_callback::&lt;E&gt;);<br>    <span class="hljs-keyword">let</span> val = engine.async_snapshot(ctx, callback);<br>    <span class="hljs-comment">// make engine not cross yield point</span><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>        val?; <span class="hljs-comment">// propagate error</span><br>        <span class="hljs-keyword">let</span> result = future<br>            .map_err(|cancel| Error::from(ErrorInner::Other(box_err!(cancel))))<br>            .<span class="hljs-keyword">await</span>?;<br>        with_tls_tracker(|tracker| &#123;<br>            tracker.metrics.get_snapshot_nanos += begin.elapsed().as_nanos() <span class="hljs-keyword">as</span> <span class="hljs-built_in">u64</span>;<br>        &#125;);<br>        fail_point!(<span class="hljs-string">"after-snapshot"</span>);<br>        result<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">async_snapshot</span></span>(&amp;<span class="hljs-keyword">self</span>, <span class="hljs-keyword">mut</span> ctx: SnapContext&lt;<span class="hljs-symbol">'_</span>&gt;, cb: Callback&lt;Self::Snap&gt;) -&gt; kv::<span class="hljs-built_in">Result</span>&lt;()&gt; &#123;<br>    <br>    ...<br><br>    <span class="hljs-keyword">self</span>.exec_snapshot(<br>        ctx,<br>        req,<br>        <span class="hljs-built_in">Box</span>::new(<span class="hljs-keyword">move</span> |res| <span class="hljs-keyword">match</span> res &#123;<br>            ...<br>        &#125;),<br>    )<br>    .map_err(|e| &#123;<br>        <span class="hljs-keyword">let</span> status_kind = get_status_kind_from_error(&amp;e);<br>        ASYNC_REQUESTS_COUNTER_VEC.snapshot.get(status_kind).inc();<br>        e.into()<br>    &#125;)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">exec_snapshot</span></span>(<br>    &amp;<span class="hljs-keyword">self</span>,<br>    ctx: SnapContext&lt;<span class="hljs-symbol">'_</span>&gt;,<br>    req: Request,<br>    cb: Callback&lt;CmdRes&lt;E::Snapshot&gt;&gt;,<br>) -&gt; <span class="hljs-built_in">Result</span>&lt;()&gt; &#123;<br><br>    ...<br>    <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> cmd = RaftCmdRequest::default();<br>    cmd.set_header(header);<br>    cmd.set_requests(<span class="hljs-built_in">vec!</span>[req].into());<br>    <span class="hljs-keyword">self</span>.router<br>        .read(<br>            ctx.read_id,<br>            cmd,<br>            StoreCallback::read(<span class="hljs-built_in">Box</span>::new(<span class="hljs-keyword">move</span> |resp| &#123;<br>                cb(on_read_result(resp).map_err(Error::into));<br>            &#125;)),<br>        )<br>        .map_err(<span class="hljs-built_in">From</span>::from)<br>&#125;<br><br><span class="hljs-keyword">impl</span>&lt;EK: KvEngine, ER: RaftEngine&gt; LocalReadRouter&lt;EK&gt; <span class="hljs-keyword">for</span> ServerRaftStoreRouter&lt;EK, ER&gt; &#123;<br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">read</span></span>(<br>        &amp;<span class="hljs-keyword">self</span>,<br>        read_id: <span class="hljs-built_in">Option</span>&lt;ThreadReadId&gt;,<br>        req: RaftCmdRequest,<br>        cb: Callback&lt;EK::Snapshot&gt;,<br>    ) -&gt; RaftStoreResult&lt;()&gt; &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> local_reader = <span class="hljs-keyword">self</span>.local_reader.borrow_mut();<br>        local_reader.read(read_id, req, cb);<br>        <span class="hljs-literal">Ok</span>(())<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>在 <code>ServerRaftStoreRouter::read</code> 函数中，其会调用 <code>local_reader</code> 的 <code>read</code> 函数，并进而路由到 <code>LocalReader::propose_raft_command</code> 函数。在该函数中，会使用 <code>LocalReader::pre_propose_raft_command</code> 函数来判断是否能够 ReadLocal，如果可以则直接获取本地引擎的 snapshot 并执行 callback 返回即可，否则便调用 <code>redirect</code> 函数连带 callback 路由到 RaftBatchSystem 的对应 normal 状态机中去执行 ReadIndex 读，之后本线程不再处理该任务。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-meta">#[inline]</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">read</span></span>(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    read_id: <span class="hljs-built_in">Option</span>&lt;ThreadReadId&gt;,<br>    req: RaftCmdRequest,<br>    cb: Callback&lt;E::Snapshot&gt;,<br>) &#123;<br>    <span class="hljs-keyword">self</span>.propose_raft_command(read_id, req, cb);<br>    maybe_tls_local_read_metrics_flush();<br>&#125;<br><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">propose_raft_command</span></span>(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    <span class="hljs-keyword">mut</span> read_id: <span class="hljs-built_in">Option</span>&lt;ThreadReadId&gt;,<br>    req: RaftCmdRequest,<br>    cb: Callback&lt;E::Snapshot&gt;,<br>) &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-keyword">self</span>.pre_propose_raft_command(&amp;req) &#123;<br>        <span class="hljs-literal">Ok</span>(<span class="hljs-literal">Some</span>((<span class="hljs-keyword">mut</span> delegate, policy))) =&gt; &#123;<br>            <span class="hljs-keyword">let</span> delegate_ext: LocalReadContext&lt;<span class="hljs-symbol">'_</span>, E&gt;;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> response = <span class="hljs-keyword">match</span> policy &#123;<br>                <span class="hljs-comment">// Leader can read local if and only if it is in lease.</span><br>                RequestPolicy::ReadLocal =&gt; &#123;<br>                 <br>                    ...<br><br>                    <span class="hljs-keyword">let</span> region = Arc::clone(&amp;delegate.region);<br>                    <span class="hljs-keyword">let</span> response =<br>                        delegate.execute(&amp;req, &amp;region, <span class="hljs-literal">None</span>, read_id, <span class="hljs-literal">Some</span>(delegate_ext));<br>                    <span class="hljs-comment">// Try renew lease in advance</span><br>                    delegate.maybe_renew_lease_advance(&amp;<span class="hljs-keyword">self</span>.router, snapshot_ts);<br>                    response<br>                &#125;<br>                <span class="hljs-comment">// Replica can serve stale read if and only if its `safe_ts` &gt;= `read_ts`</span><br>                RequestPolicy::StaleRead =&gt; &#123;<br>               <br>                    ...<br><br>                    <span class="hljs-keyword">let</span> region = Arc::clone(&amp;delegate.region);<br>                    <span class="hljs-comment">// Getting the snapshot</span><br>                    <span class="hljs-keyword">let</span> response =<br>                        delegate.execute(&amp;req, &amp;region, <span class="hljs-literal">None</span>, read_id, <span class="hljs-literal">Some</span>(delegate_ext));<br><br>                    ...<br>                    <br>                &#125;<br>                _ =&gt; <span class="hljs-built_in">unreachable!</span>(),<br>            &#125;;<br>           <br>            ...<br>            <br>            cb.invoke_read(response);<br>        &#125;<br>        <span class="hljs-comment">// Forward to raftstore.</span><br>        <span class="hljs-literal">Ok</span>(<span class="hljs-literal">None</span>) =&gt; <span class="hljs-keyword">self</span>.redirect(RaftCommand::new(req, cb)),<br>        <span class="hljs-literal">Err</span>(e) =&gt; &#123;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> response = cmd_resp::new_error(e);<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(delegate) = <span class="hljs-keyword">self</span>.delegates.get(&amp;req.get_header().get_region_id()) &#123;<br>                cmd_resp::bind_term(&amp;<span class="hljs-keyword">mut</span> response, delegate.term);<br>            &#125;<br>            cb.invoke_read(ReadResponse &#123;<br>                response,<br>                snapshot: <span class="hljs-literal">None</span>,<br>                txn_extra_op: TxnExtraOp::Noop,<br>            &#125;);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>需要注意的是，在此处能否 ReadLocal 的判断是可以并行的，也就是乐观情况下并行的读请求可以并行获取底层引擎的 snapshot，不需要经过 RaftBatchSystem 。</p><p>那么到底什么时候可以直接读取 snapshot 而不需要经过 RaftStore 走一轮 ReadIndex 来处理呢？原理就是 Lease 机制，可以先简单阅读一下 <a href="https://pingcap.com/zh/blog/lease-read" target="_blank" rel="noopener">TiKV Lease Read 的功能介绍</a>。</p><p>接着让我们回到 <code>LocalReader::pre_propose_raft_command</code> 函数，其会进行一系列的检查（此处已略去），如果皆通过则会进一步调用 <code>inspector.inspect(req)</code> 函数，在其内部，其会进行一系列的判断并返回是否可以 ReadLocal。</p><ul><li><code>req.get_header().get_read_quorum()</code>：如果该请求明确要求需要用 read index 方式处理，所以返回 ReadIndex。</li><li><code>self.has_applied_to_current_term()</code>：如果该 leader 尚未 apply 到它自己的 term，则使用 ReadIndex 处理，这是 Raft 有关线性一致性读的一个 corner case。</li><li><code>self.inspect_lease()</code>：如果该 leader 的 lease 已经过期或者不确定，说明可能出现了一些问题，比如网络不稳定，心跳没成功等，此时使用 ReadIndex 处理，否则便可以使用 ReadLocal 处理。</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">pre_propose_raft_command</span></span>(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    req: &amp;RaftCmdRequest,<br>) -&gt; <span class="hljs-built_in">Result</span>&lt;<span class="hljs-built_in">Option</span>&lt;(D, RequestPolicy)&gt;&gt; &#123;<br>    <br>    ...<br><br>    <span class="hljs-keyword">match</span> inspector.inspect(req) &#123;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ReadLocal) =&gt; <span class="hljs-literal">Ok</span>(<span class="hljs-literal">Some</span>((delegate, RequestPolicy::ReadLocal))),<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::StaleRead) =&gt; <span class="hljs-literal">Ok</span>(<span class="hljs-literal">Some</span>((delegate, RequestPolicy::StaleRead))),<br>        <span class="hljs-comment">// It can not handle other policies.</span><br>        <span class="hljs-literal">Ok</span>(_) =&gt; <span class="hljs-literal">Ok</span>(<span class="hljs-literal">None</span>),<br>        <span class="hljs-literal">Err</span>(e) =&gt; <span class="hljs-literal">Err</span>(e),<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">inspect</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, req: &amp;RaftCmdRequest) -&gt; <span class="hljs-built_in">Result</span>&lt;RequestPolicy&gt; &#123;<br><br>    ...<br><br>    fail_point!(<span class="hljs-string">"perform_read_index"</span>, |_| <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex));<br><br>    <span class="hljs-keyword">let</span> flags = WriteBatchFlags::from_bits_check(req.get_header().get_flags());<br>    <span class="hljs-keyword">if</span> flags.contains(WriteBatchFlags::STALE_READ) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">Ok</span>(RequestPolicy::StaleRead);<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> req.get_header().get_read_quorum() &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex);<br>    &#125;<br><br>    <span class="hljs-comment">// If applied index's term is differ from current raft's term, leader transfer</span><br>    <span class="hljs-comment">// must happened, if read locally, we may read old value.</span><br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.has_applied_to_current_term() &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex);<br>    &#125;<br><br>    <span class="hljs-comment">// Local read should be performed, if and only if leader is in lease.</span><br>    <span class="hljs-comment">// None for now.</span><br>    <span class="hljs-keyword">match</span> <span class="hljs-keyword">self</span>.inspect_lease() &#123;<br>        LeaseState::Valid =&gt; <span class="hljs-literal">Ok</span>(RequestPolicy::ReadLocal),<br>        LeaseState::Expired | LeaseState::Suspect =&gt; &#123;<br>            <span class="hljs-comment">// Perform a consistent read to Raft quorum and try to renew the leader lease.</span><br>            <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex)<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>乐观情况下的 ReadLocal 流程我们已经了解，接下来让我们看看 ReadIndex 在 RaftStore 中的执行路径。</p><h3 id="RaftStore"><a href="#RaftStore" class="headerlink" title="RaftStore"></a>RaftStore</h3><p>前文已经介绍过 RaftBatchSystem 的大体框架，我们已知会有多个 PollHandler 线程调用 poll 函数进入长期循环来事件驱动并动态均衡地管理所有 normal 状态机。</p><p>当 ReadIndex 请求被路由到 RaftBatchSystem 中的对应 normal 状态机后，某个 PollHandler 会在接下来的一次 loop 中处理该状态机的消息。</p><p>直接定位到 <code>RaftPoller</code> 的 <code>handle_normal</code> 函数。可以看到，其会首先尝试获取 <code>messages_per_tick</code> 次路由到该状态机的消息，接着调用 <code>PeerFsmDelegate::handle_msgs</code> 函数进行处理，</p><p>这里只列出了我们需要关注的几种消息类型：</p><ul><li>RaftMessage: 其他 Peer 发送过来 Raft 消息，包括心跳、日志、投票消息等。</li><li>RaftCommand: 上层提出的 proposal，其中包含了需要通过 Raft 同步的操作，以及操作成功之后需要调用的 callback 函数。ReadIndex 请求便是一种特殊的 proposal。</li><li>ApplyRes: ApplyFsm 在将日志应用到状态机之后发送给 PeerFsm 的消息，用于在进行操作之后更新某些内存状态。</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;EK: KvEngine, ER: RaftEngine, T: Transport&gt; PollHandler&lt;PeerFsm&lt;EK, ER&gt;, StoreFsm&lt;EK&gt;&gt;<br>    <span class="hljs-keyword">for</span> RaftPoller&lt;EK, ER, T&gt;<br>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_normal</span></span>(<br>        &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>        peer: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">impl</span> DerefMut&lt;Target = PeerFsm&lt;EK, ER&gt;&gt;,<br>    ) -&gt; HandleResult &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> handle_result = HandleResult::KeepProcessing;<br><br>        ...<br><br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.peer_msg_buf.len() &lt; <span class="hljs-keyword">self</span>.messages_per_tick &#123;<br>            <span class="hljs-keyword">match</span> peer.receiver.try_recv() &#123;<br>                <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> we may need a way to optimize the message copy.</span><br>                <span class="hljs-literal">Ok</span>(msg) =&gt; &#123;<br>                    ...<br>                    <span class="hljs-keyword">self</span>.peer_msg_buf.push(msg);<br>                &#125;<br>                <span class="hljs-literal">Err</span>(TryRecvError::Empty) =&gt; &#123;<br>                    handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>                <span class="hljs-literal">Err</span>(TryRecvError::Disconnected) =&gt; &#123;<br>                    peer.stop();<br>                    handle_result = HandleResult::stop_at(<span class="hljs-number">0</span>, <span class="hljs-literal">false</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> delegate = PeerFsmDelegate::new(peer, &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.poll_ctx);<br>        delegate.handle_msgs(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.peer_msg_buf);<br>        <span class="hljs-comment">// No readiness is generated and using sync write, skipping calling ready and</span><br>        <span class="hljs-comment">// release early.</span><br>        <span class="hljs-keyword">if</span> !delegate.collect_ready() &amp;&amp; <span class="hljs-keyword">self</span>.poll_ctx.sync_write_worker.is_some() &#123;<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> HandleResult::StopAt &#123; skip_end, .. &#125; = &amp;<span class="hljs-keyword">mut</span> handle_result &#123;<br>                *skip_end = <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br><br>        handle_result<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">impl</span>&lt;<span class="hljs-symbol">'a</span>, EK, ER, T: Transport&gt; PeerFsmDelegate&lt;<span class="hljs-symbol">'a</span>, EK, ER, T&gt;<br><span class="hljs-keyword">where</span><br>    EK: KvEngine,<br>    ER: RaftEngine,<br>&#123;<br>    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_msgs</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, msgs: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-built_in">Vec</span>&lt;PeerMsg&lt;EK&gt;&gt;) &#123;<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> msgs.drain(..) &#123;<br>            <span class="hljs-keyword">match</span> m &#123;<br>                PeerMsg::RaftMessage(msg) =&gt; &#123;<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Err</span>(e) = <span class="hljs-keyword">self</span>.on_raft_message(msg) &#123;<br>                        error!(%e;<br>                            <span class="hljs-string">"handle raft message err"</span>;<br>                            <span class="hljs-string">"region_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.region_id(),<br>                            <span class="hljs-string">"peer_id"</span> =&gt; <span class="hljs-keyword">self</span>.fsm.peer_id(),<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::RaftCommand(cmd) =&gt; &#123;<br>                        ...<br>                        <span class="hljs-keyword">self</span>.propose_raft_command(<br>                            cmd.request,<br>                            cmd.callback,<br>                            cmd.extra_opts.disk_full_opt,<br>                        );<br>                    &#125;<br>                &#125;<br>                PeerMsg::ApplyRes &#123; res &#125; =&gt; &#123;<br>                    <span class="hljs-keyword">self</span>.on_apply_res(res);<br>                &#125;<br>                ...<br>            &#125;<br>        &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>对于 ReadIndex 请求，其会进入 <code>PeerMsg::RaftCommand(cmd)</code> 分支，进而以 <code>PeerFsmDelegate::propose_raft_command -&gt; PeerFsmDelegate::propose_raft_command_internal</code> 的调用链走到 <code>store::propose</code> 函数中，在该函数中，会再进行一次 <code>self.inspect()</code>，如果此时 Leader 的 lease 已经稳定，则会调用 <code>read_local</code> 函数直接获取引擎的 snapshot 并执行 callback 返回，否则调用 <code>read_index</code> 函数执行 ReadIndex 流程。</p><p>在 read_index 函数中，ReadIndex 请求连带 callback 会被构建成一个 ReadIndexRequest 被 push 到 pending_reads 即一个 ReadIndexQueue 中，之后当前线程即可结束本轮流程，之后的事件会进而触发该 ReadIndexRequest 的执行。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">propose</span></span>&lt;T: Transport&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>    <span class="hljs-keyword">mut</span> cb: Callback&lt;EK::Snapshot&gt;,<br>    req: RaftCmdRequest,<br>    <span class="hljs-keyword">mut</span> err_resp: RaftCmdResponse,<br>    <span class="hljs-keyword">mut</span> disk_full_opt: DiskFullOpt,<br>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> policy = <span class="hljs-keyword">self</span>.inspect(&amp;req);<br>    <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">match</span> policy &#123;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ReadLocal) | <span class="hljs-literal">Ok</span>(RequestPolicy::StaleRead) =&gt; &#123;<br>            <span class="hljs-keyword">self</span>.read_local(ctx, req, cb);<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ReadIndex) =&gt; <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.read_index(ctx, req, err_resp, cb),<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeTransferLeader) =&gt; &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.propose_transfer_leader(ctx, req, cb);<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeNormal) =&gt; &#123;<br>            <span class="hljs-comment">// For admin cmds, only region split/merge comes here.</span><br>            <span class="hljs-keyword">if</span> req.has_admin_request() &#123;<br>                disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;<br>            &#125;<br>            <span class="hljs-keyword">self</span>.check_normal_proposal_with_disk_full_opt(ctx, disk_full_opt)<br>                .and_then(|_| <span class="hljs-keyword">self</span>.propose_normal(ctx, req))<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(RequestPolicy::ProposeConfChange) =&gt; <span class="hljs-keyword">self</span>.propose_conf_change(ctx, &amp;req),<br>        <span class="hljs-literal">Err</span>(e) =&gt; <span class="hljs-literal">Err</span>(e),<br>    &#125;;<br>    fail_point!(<span class="hljs-string">"after_propose"</span>);<br><br>    ...<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">read_index</span></span>&lt;T: Transport&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    poll_ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>    <span class="hljs-keyword">mut</span> req: RaftCmdRequest,<br>    <span class="hljs-keyword">mut</span> err_resp: RaftCmdResponse,<br>    cb: Callback&lt;EK::Snapshot&gt;,<br>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> read = ReadIndexRequest::with_command(id, req, cb, now);<br>    read.addition_request = request.map(<span class="hljs-built_in">Box</span>::new);<br>    <span class="hljs-keyword">self</span>.push_pending_read(read, <span class="hljs-keyword">self</span>.is_leader());<br>    <span class="hljs-keyword">self</span>.should_wake_up = <span class="hljs-literal">true</span>;<br><br>    ...<br><br>    <span class="hljs-literal">true</span><br>&#125;<br></code></pre></div></td></tr></table></figure><p>那么什么条件满足后该 ReadIndexRequest 会被 pop 出队列并执行呢？</p><p>前面已经提到 ApplyBatchSystem 在应用一批日志之后首先会调用对应的 callback 尽快回复客户端，之后会发送一条 ApplyRes 的消息到 RaftBatchSystem，该消息和以上的 ReadIndex 请求一样被 PollHandler 在一次 loop 中被处理，并最终进入 <code>PeerFsmDelegate::handle_msgs</code> 函数的 <code>PeerMsg::ApplyRes { res }</code> 分支，接着其会调用 <code>PeerFsmDelegate::on_apply_res</code> 函数并进入 <code>store::peer::post_apply</code> 函数，在该函数中，ApplyRes 中携带的信息会被用来更新一些内存状态例如 <code>raft_group</code> 和 <code>cmd_epoch_checker</code>，当然，这些信息也会通过 <code>store::peer::post_pending_read_index_on_replica</code> 和 <code>self.pending_reads.pop_front()</code> 来释放某些满足条件的 ReadIndexRequest，对于每个 ReadIndexRequest ，此时可以通过 <code>store::peer::response_read</code> 函数来获取底层引擎的 Snapshot 并执行 callback 返回。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">on_apply_res</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, res: ApplyTaskRes&lt;EK::Snapshot&gt;) &#123;<br>    fail_point!(<span class="hljs-string">"on_apply_res"</span>, |_| &#123;&#125;);<br>    <span class="hljs-keyword">match</span> res &#123;<br>        ApplyTaskRes::Apply(<span class="hljs-keyword">mut</span> res) =&gt; &#123;<br>            <br>            ...<br><br>            <span class="hljs-keyword">self</span>.fsm.has_ready |= <span class="hljs-keyword">self</span>.fsm.peer.post_apply(<br>                <span class="hljs-keyword">self</span>.ctx,<br>                res.apply_state,<br>                res.applied_term,<br>                &amp;res.metrics,<br>            );<br>        <br>            ...<br>        &#125;<br>        ApplyTaskRes::Destroy &#123;<br>            region_id,<br>            peer_id,<br>            merge_from_snapshot,<br>        &#125; =&gt; &#123;<br>            ...<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">post_apply</span></span>&lt;T&gt;(<br>    &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>,<br>    ctx: &amp;<span class="hljs-keyword">mut</span> PollContext&lt;EK, ER, T&gt;,<br>    apply_state: RaftApplyState,<br>    applied_term: <span class="hljs-built_in">u64</span>,<br>    apply_metrics: &amp;ApplyMetrics,<br>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> has_ready = <span class="hljs-literal">false</span>;<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.is_handling_snapshot() &#123;<br>        <span class="hljs-built_in">panic!</span>(<span class="hljs-string">"&#123;&#125; should not applying snapshot."</span>, <span class="hljs-keyword">self</span>.tag);<br>    &#125;<br><br>    <span class="hljs-keyword">let</span> applied_index = apply_state.get_applied_index();<br>    <span class="hljs-keyword">self</span>.raft_group.advance_apply_to(applied_index);<br><br>    <span class="hljs-keyword">self</span>.cmd_epoch_checker.advance_apply(<br>        applied_index,<br>        <span class="hljs-keyword">self</span>.term(),<br>        <span class="hljs-keyword">self</span>.raft_group.store().region(),<br>    );<br><br>    ...<br><br>    <span class="hljs-keyword">if</span> !<span class="hljs-keyword">self</span>.is_leader() &#123;<br>        <span class="hljs-keyword">self</span>.post_pending_read_index_on_replica(ctx)<br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.ready_to_handle_read() &#123;<br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(<span class="hljs-keyword">mut</span> read) = <span class="hljs-keyword">self</span>.pending_reads.pop_front() &#123;<br>            <span class="hljs-keyword">self</span>.response_read(&amp;<span class="hljs-keyword">mut</span> read, ctx, <span class="hljs-literal">false</span>);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">self</span>.pending_reads.gc();<br><br>    ...<br><br>    has_ready<br>&#125;<br></code></pre></div></td></tr></table></figure><p>综上，ReadIndexRequest 入队和出队的时机已经被介绍，那么 ReadIndex 的整体流程也基本介绍完整了。</p><p>通过本小节，希望您能够了解 KVGet 读请求的完整流程，并进而具备分析其他读请求全链路的能力。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客介绍了 TiKV 中一条读请求的全链路流程。</p><p>希望本博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>感谢您的阅读~</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>源码阅读</tag>
      
      <tag>TiKV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TiKV 源码阅读三部曲（一）重要模块</title>
    <link href="/tikv-source-code-reading-module/"/>
    <url>/tikv-source-code-reading-module/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://github.com/tikv/tikv" target="_blank" rel="noopener">TiKV</a> 是一个支持事务的分布式 Key-Value 数据库，目前已经是 <a href="https://www.cncf.io/projects/" target="_blank" rel="noopener">CNCF 基金会</a> 的顶级项目。</p><p>作为一个新同学，需要一定的前期准备才能够有能力参与 TiKV 社区的代码开发，包括但不限于学习 Rust 语言，理解 TiKV 的原理和在前两者的基础上了解熟悉 TiKV 的源码。</p><p><a href="https://pingcap.com/zh/blog/?tag=TiKV%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90" target="_blank" rel="noopener">TiKV 官方源码解析文档</a> 详细地介绍了 TiKV 3.x 版本重要模块的设计要点，主要流程和相应代码片段，是学习 TiKV 源码必读的学习资料。当前 TiKV 已经迭代到了 6.x 版本，不仅引入了很多新的功能和优化，而且对源码也进行了多次重构，因而一些官方源码解析文档中的代码片段已经不复存在，这使得读者在阅读源码解析文档时无法对照最新源码加深理解；此外尽管 TiKV 官方源码解析文档系统地介绍了若干重要模块的工作，但并没有将读写流程全链路串起来去介绍经过的模块和对应的代码片段，实际上尽快地熟悉读写流程全链路会更利于新同学从全局角度理解代码。</p><p>基于以上存在的问题，笔者将基于 6.1 版本的源码撰写三篇博客，分别介绍以下三个方面：</p><ul><li><a href="https://tanxinyu.work/tikv-source-code-reading-module/">TiKV 源码阅读三部曲（一）重要模块</a>：TiKV 的基本概念，TiKV 读写路径上的三个重要模块（KVService，Storage，RaftStore）和断点调试 TiKV 学习源码的方案</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-read/">TiKV 源码阅读三部曲（二）读流程</a>：TiKV 中一条读请求的全链路流程</li><li><a href="https://tanxinyu.work/tikv-source-code-reading-write/">TiKV 源码阅读三部曲（三）写流程</a>：TiKV 中一条写请求的全链路流程</li></ul><p>希望此三篇博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>本文为第一篇博客，将主要介绍 TiKV 的基本概念，TiKV 读写路径上的三个重要模块（KVService，Storage，RaftStore）和断点调试 TiKV 学习源码的方案。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>TiKV 的架构简介可以查看 <a href="https://docs.pingcap.com/zh/tidb/dev/tikv-overview" target="_blank" rel="noopener">官方文档</a>。总体来看，TiKV 是一个通过 Multi-Raft 实现的分布式 KV 数据库。</p><p>TiKV 的每个进程拥有一个 store，store 中拥有若干 region。每个 region 是一个 raft 组，会存在于副本数个 store 上管理一段 KV 区间的数据。</p><p><img src="https://download.pingcap.com/images/docs-cn/tikv-arch.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="重要模块"><a href="#重要模块" class="headerlink" title="重要模块"></a>重要模块</h2><h3 id="KVService"><a href="#KVService" class="headerlink" title="KVService"></a>KVService</h3><p>TiKV 的 Service 层代码位于 src/server 文件夹下，其职责包括提供 RPC 服务、将 store id 解析成地址、TiKV 之间的相互通信等。有关 Service 层的概念解析可以查看阅读 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-9" target="_blank" rel="noopener">TiKV 源码解析系列文章（九）Service 层处理流程解析</a>。</p><p><img src="https://img1.www.pingcap.com/prod/1_1c0d99f78e.png" srcset="/img/loading.gif" lazyload alt></p><p>TiKV 包含多个 gRPC service。其中最重要的一个是 KVService，位于 src/server/service/kv.rs 文件中。</p><p>KVService 定义了 TiKV 的 kv_get，kv_scan，kv_prewrite，kv_commit 等事务操作 API，用于执行 TiDB 下推下来的复杂查询和计算的 coprocessor API，以及 raw_get，raw_put 等 Raw KV API。batch_commands 接口则是用于将上述的接口 batch 起来，以优化高吞吐量的场景。另外，TiKV 的 Raft group 各成员之间通信用到的 raft 和 batch_raft 接口也是在这里提供的。</p><p>本小节将简单介绍 KVService 及其启动流程，并顺带介绍 TiKV 若干重要结构的初始化流程。</p><p>cmd/tikv-server/main.rs 是 TiKV 进程启动的入口，其主要做了以下两个工作：</p><ul><li>解析配置参数</li><li>使用 <code>server::server::run_tikv(config)</code> 启动 tikv 进程</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">main</span></span>() &#123;<br>    <span class="hljs-keyword">let</span> build_timestamp = <span class="hljs-built_in">option_env!</span>(<span class="hljs-string">"TIKV_BUILD_TIME"</span>);<br>    <span class="hljs-keyword">let</span> version_info = tikv::tikv_version_info(build_timestamp);<br>    <br>    <span class="hljs-comment">// config parsing</span><br>    <span class="hljs-comment">// ...</span><br>    <span class="hljs-comment">// config parsing</span><br>   <br>    server::server::run_tikv(config);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>对于 components/server/src/server.rs 的 run-tikv 函数，其会调用 run_impl 函数并根据配置参数来启动对应的 KV 引擎。</p><p>在 run_impl 函数中，首先会调用 <code>TikvServer::&lt;CER&gt;::init::&lt;F&gt;(config)</code> 函数做若干重要结构的初始化，包含但不限于 batch_system, concurrency_manager,  background_worker, quota_limiter 等等，接着在 <code>tikv.init_servers::&lt;F&gt;()</code> 里将 RPC handler 与 KVService 绑定起来，最后在 <code>tikv.run_server(server_config)</code> 中便会使用 <a href="https://pingcap.com/zh/blog/tikv-source-code-reading-7" target="_blank" rel="noopener">TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程</a> 中介绍的 grpc server 绑定对应的端口并开始监听连接了。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Rust"><span class="hljs-comment">/// Run a TiKV server. Returns when the server is shutdown by the user, in which</span><br><span class="hljs-comment">/// case the server will be properly stopped.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">run_tikv</span></span>(config: TikvConfig) &#123;<br><br>    ...<br><br>    <span class="hljs-comment">// Do some prepare works before start.</span><br>    pre_start();<br><br>    <span class="hljs-keyword">let</span> _m = Monitor::default();<br><br>    dispatch_api_version!(config.storage.api_version(), &#123;<br>        <span class="hljs-keyword">if</span> !config.raft_engine.enable &#123;<br>            run_impl::&lt;RocksEngine, API&gt;(config)<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            run_impl::&lt;RaftLogEngine, API&gt;(config)<br>        &#125;<br>    &#125;)<br>&#125;<br><br><span class="hljs-meta">#[inline]</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">run_impl</span></span>&lt;CER: ConfiguredRaftEngine, F: KvFormat&gt;(config: TikvConfig) &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> tikv = TikvServer::&lt;CER&gt;::init::&lt;F&gt;(config);<br><br>    ...<br><br>    <span class="hljs-keyword">let</span> server_config = tikv.init_servers::&lt;F&gt;();<br> <br>    ...<br>    <br>    tikv.run_server(server_config);<br><br>    signal_handler::wait_for_signal(<span class="hljs-literal">Some</span>(tikv.engines.take().unwrap().engines));<br>    tikv.stop();<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">run_server</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, server_config: Arc&lt;VersionTrack&lt;ServerConfig&gt;&gt;) &#123;<br>    <span class="hljs-keyword">let</span> server = <span class="hljs-keyword">self</span>.servers.as_mut().unwrap();<br>    server<br>        .server<br>        .build_and_bind()<br>        .unwrap_or_else(|e| fatal!(<span class="hljs-string">"failed to build server: &#123;&#125;"</span>, e));<br>    server<br>        .server<br>        .start(server_config, <span class="hljs-keyword">self</span>.security_mgr.clone())<br>        .unwrap_or_else(|e| fatal!(<span class="hljs-string">"failed to start server: &#123;&#125;"</span>, e));<br>&#125;<br></code></pre></div></td></tr></table></figure><p>KVService 服务启动后，所有发往监听端口的请求便会路由到 KVService 对应的 handler 上。有关 KVService 目前支持的接口，可以直接查看 <a href="https://github.com/pingcap/kvproto/blob/master/proto/tikvpb.proto#L20" target="_blank" rel="noopener">kvproto</a> 对应的 <code>service Tikv</code>，目前的 RPC 接口已经接近 60 个，每个接口在代码中都会对应一个 handler。</p><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs proto3">&#x2F;&#x2F; Key&#x2F;value store API for TiKV.<br>service Tikv &#123;<br>    &#x2F;&#x2F; Commands using a transactional interface.<br>    rpc KvGet(kvrpcpb.GetRequest) returns (kvrpcpb.GetResponse) &#123;&#125;<br>    rpc KvScan(kvrpcpb.ScanRequest) returns (kvrpcpb.ScanResponse) &#123;&#125;<br>    rpc KvPrewrite(kvrpcpb.PrewriteRequest) returns (kvrpcpb.PrewriteResponse) &#123;&#125;<br>    rpc KvPessimisticLock(kvrpcpb.PessimisticLockRequest) returns (kvrpcpb.PessimisticLockResponse) &#123;&#125;<br>    rpc KVPessimisticRollback(kvrpcpb.PessimisticRollbackRequest) returns (kvrpcpb.PessimisticRollbackResponse) &#123;&#125;<br>    ...<br>&#125;<br></code></pre></div></td></tr></table></figure><p>当 KVService 收到请求之后，会根据请求的类型把这些请求转发到不同的模块进行处理。对于从 TiDB 下推的读请求，比如 sum，avg 操作，会转发到 Coprocessor 模块进行处理，对于 KV 请求会直接转发到 Storage 模块进行处理。</p><p>KV 操作根据功能可以被划分为 Raw KV 操作以及 Txn KV 操作两大类。Raw KV 操作包括 raw put、raw get、raw delete、raw batch get、raw batch put、raw batch delete、raw scan 等普通 KV 操作。 Txn KV 操作是为了实现事务机制而设计的一系列操作，如 prewrite 和 commit 分别对应于 2PC 中的 prepare 和 commit 阶段的操作。</p><p>与 <a href="https://pingcap.com/zh/blog/tikv-source-code-reading-7" target="_blank" rel="noopener">TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程</a> 中介绍的 handler example 不同，当前 KVService 对事务 API 例如 kv_prewrite, kv_commit 和 Raw API 例如 raw_get, raw_scan 进行了封装，由于他们都会被路由到 Storage 模块，所以接口无关的逻辑都被封装到了 <code>handle_request</code> 宏中，接口相关的逻辑则被封装到了 future_prewirte, future_commit 等 future_xxx 函数中。需要注意的是，对于 coprocessor API，raft API 等相关接口依然采用了原生对接 grpc-rs 的方式。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-built_in">macro_rules!</span> handle_request &#123;<br>    ($fn_name: ident, $future_name: ident, $req_ty: ident, $resp_ty: ident) =&gt; &#123;<br>        handle_request!($fn_name, $future_name, $req_ty, $resp_ty, no_time_detail);<br>    &#125;;<br>    ($fn_name: ident, $future_name: ident, $req_ty: ident, $resp_ty: ident, $time_detail: tt) =&gt; &#123;<br>        <span class="hljs-function"><span class="hljs-keyword">fn</span> $<span class="hljs-title">fn_name</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, ctx: RpcContext&lt;<span class="hljs-symbol">'_</span>&gt;, <span class="hljs-keyword">mut</span> req: $req_ty, sink: UnarySink&lt;$resp_ty&gt;) &#123;<br>            forward_unary!(<span class="hljs-keyword">self</span>.proxy, $fn_name, ctx, req, sink);<br>            <span class="hljs-keyword">let</span> begin_instant = Instant::now();<br><br>            <span class="hljs-keyword">let</span> source = req.mut_context().take_request_source();<br>            <span class="hljs-keyword">let</span> resp = $future_name(&amp;<span class="hljs-keyword">self</span>.storage, req);<br>            <span class="hljs-keyword">let</span> task = <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>                <span class="hljs-keyword">let</span> resp = resp.<span class="hljs-keyword">await</span>?;<br>                <span class="hljs-keyword">let</span> elapsed = begin_instant.saturating_elapsed();<br>                set_total_time!(resp, elapsed, $time_detail);<br>                sink.success(resp).<span class="hljs-keyword">await</span>?;<br>                GRPC_MSG_HISTOGRAM_STATIC<br>                    .$fn_name<br>                    .observe(elapsed.as_secs_f64());<br>                record_request_source_metrics(source, elapsed);<br>                ServerResult::<span class="hljs-literal">Ok</span>(())<br>            &#125;<br>            .map_err(|e| &#123;<br>                log_net_error!(e, <span class="hljs-string">"kv rpc failed"</span>;<br>                    <span class="hljs-string">"request"</span> =&gt; <span class="hljs-built_in">stringify!</span>($fn_name)<br>                );<br>                GRPC_MSG_FAIL_COUNTER.$fn_name.inc();<br>            &#125;)<br>            .map(|_|());<br><br>            ctx.spawn(task);<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">impl</span>&lt;T: RaftStoreRouter&lt;E::Local&gt; + <span class="hljs-symbol">'static</span>, E: Engine, L: LockManager, F: KvFormat&gt; Tikv<br>    <span class="hljs-keyword">for</span> Service&lt;T, E, L, F&gt;<br>&#123;<br>    handle_request!(kv_get, future_get, GetRequest, GetResponse, has_time_detail);<br>    handle_request!(kv_scan, future_scan, ScanRequest, ScanResponse);<br>    handle_request!(<br>        kv_prewrite,<br>        future_prewrite,<br>        PrewriteRequest,<br>        PrewriteResponse,<br>        has_time_detail<br>    );<br><br>    ...<br><br>    handle_request!(raw_get, future_raw_get, RawGetRequest, RawGetResponse);<br>    handle_request!(<br>        raw_batch_get,<br>        future_raw_batch_get,<br>        RawBatchGetRequest,<br>        RawBatchGetResponse<br>    );<br>    handle_request!(raw_scan, future_raw_scan, RawScanRequest, RawScanResponse);<br><br>    ...<br><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">coprocessor</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, ctx: RpcContext&lt;<span class="hljs-symbol">'_</span>&gt;, <span class="hljs-keyword">mut</span> req: Request, sink: UnarySink&lt;Response&gt;) &#123;<br>        forward_unary!(<span class="hljs-keyword">self</span>.proxy, coprocessor, ctx, req, sink);<br>        <span class="hljs-keyword">let</span> source = req.mut_context().take_request_source();<br>        <span class="hljs-keyword">let</span> begin_instant = Instant::now();<br>        <span class="hljs-keyword">let</span> future = future_copr(&amp;<span class="hljs-keyword">self</span>.copr, <span class="hljs-literal">Some</span>(ctx.peer()), req);<br>        <span class="hljs-keyword">let</span> task = <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>            <span class="hljs-keyword">let</span> resp = future.<span class="hljs-keyword">await</span>?.consume();<br>            sink.success(resp).<span class="hljs-keyword">await</span>?;<br>            <span class="hljs-keyword">let</span> elapsed = begin_instant.saturating_elapsed();<br>            GRPC_MSG_HISTOGRAM_STATIC<br>                .coprocessor<br>                .observe(elapsed.as_secs_f64());<br>            record_request_source_metrics(source, elapsed);<br>            ServerResult::<span class="hljs-literal">Ok</span>(())<br>        &#125;<br>        .map_err(|e| &#123;<br>            log_net_error!(e, <span class="hljs-string">"kv rpc failed"</span>;<br>                <span class="hljs-string">"request"</span> =&gt; <span class="hljs-string">"coprocessor"</span><br>            );<br>            GRPC_MSG_FAIL_COUNTER.coprocessor.inc();<br>        &#125;)<br>        .map(|_| ());<br><br>        ctx.spawn(task);<br>    &#125;<br><br>    ...<br>&#125;<br></code></pre></div></td></tr></table></figure><p>在事务相关 API 的 future_xxx 函数实现中，对于带有写语义的 future_prewrite, future_commit 等函数，由于它们会被统一调度到 Storage 模块的 sched_txn_command 函数中，当前又抽象出了 <code>txn_command_future</code> 宏来减少冗余代码；对于带有读语义的 future_get, future_scan 等函数，由于他们会分别调用 Storage 模块的 get/scan 等函数，因而目前并没有进行进一步抽象。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-built_in">macro_rules!</span> txn_command_future &#123;<br>    ($fn_name: ident, $req_ty: ident, $resp_ty: ident, ($req: ident) $prelude: stmt; ($v: ident, $resp: ident, $tracker: ident) &#123; $else_branch: expr &#125;) =&gt; &#123;<br>        <span class="hljs-function"><span class="hljs-keyword">fn</span> $<span class="hljs-title">fn_name</span></span>&lt;E: Engine, L: LockManager, F: KvFormat&gt;(<br>            storage: &amp;Storage&lt;E, L, F&gt;,<br>            $req: $req_ty,<br>        ) -&gt; <span class="hljs-keyword">impl</span> Future&lt;Output = ServerResult&lt;$resp_ty&gt;&gt; &#123;<br>            $prelude<br>            <span class="hljs-keyword">let</span> $tracker = GLOBAL_TRACKERS.insert(Tracker::new(RequestInfo::new(<br>                $req.get_context(),<br>                RequestType::Unknown,<br>                <span class="hljs-number">0</span>,<br>            )));<br>            set_tls_tracker_token($tracker);<br>            <span class="hljs-keyword">let</span> (cb, f) = paired_future_callback();<br>            <span class="hljs-keyword">let</span> res = storage.sched_txn_command($req.into(), cb);<br><br>            <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>                defer!&#123;&#123;<br>                    GLOBAL_TRACKERS.remove($tracker);<br>                &#125;&#125;;<br>                <span class="hljs-keyword">let</span> $v = <span class="hljs-keyword">match</span> res &#123;<br>                    <span class="hljs-literal">Err</span>(e) =&gt; <span class="hljs-literal">Err</span>(e),<br>                    <span class="hljs-literal">Ok</span>(_) =&gt; f.<span class="hljs-keyword">await</span>?,<br>                &#125;;<br>                <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> $resp = $resp_ty::default();<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(err) = extract_region_error(&amp;$v) &#123;<br>                    $resp.set_region_error(err);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    $else_branch;<br>                &#125;<br>                <span class="hljs-literal">Ok</span>($resp)<br>            &#125;<br>        &#125;<br>    &#125;;<br>    ($fn_name: ident, $req_ty: ident, $resp_ty: ident, ($v: ident, $resp: ident, $tracker: ident) &#123; $else_branch: expr &#125;) =&gt; &#123;<br>        txn_command_future!($fn_name, $req_ty, $resp_ty, (req) &#123;&#125;; ($v, $resp, $tracker) &#123; $else_branch &#125;);<br>    &#125;;<br>    ($fn_name: ident, $req_ty: ident, $resp_ty: ident, ($v: ident, $resp: ident) &#123; $else_branch: expr &#125;) =&gt; &#123;<br>        txn_command_future!($fn_name, $req_ty, $resp_ty, (req) &#123;&#125;; ($v, $resp, tracker) &#123; $else_branch &#125;);<br>    &#125;;<br>&#125;<br><br>txn_command_future!(future_prewrite, PrewriteRequest, PrewriteResponse, (v, resp, tracker) &#123;&#123;<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Ok</span>(v) = &amp;v &#123;<br>        resp.set_min_commit_ts(v.min_commit_ts.into_inner());<br>        resp.set_one_pc_commit_ts(v.one_pc_commit_ts.into_inner());<br>        GLOBAL_TRACKERS.with_tracker(tracker, |tracker| &#123;<br>            tracker.write_scan_detail(resp.mut_exec_details_v2().mut_scan_detail_v2());<br>            tracker.write_write_detail(resp.mut_exec_details_v2().mut_write_detail());<br>        &#125;);<br>    &#125;<br>    resp.set_errors(extract_key_errors(v.map(|v| v.locks)).into());<br>&#125;&#125;);<br><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">future_get</span></span>&lt;E: Engine, L: LockManager, F: KvFormat&gt;(<br>    storage: &amp;Storage&lt;E, L, F&gt;,<br>    <span class="hljs-keyword">mut</span> req: GetRequest,<br>) -&gt; <span class="hljs-keyword">impl</span> Future&lt;Output = ServerResult&lt;GetResponse&gt;&gt; &#123;<br>    <span class="hljs-keyword">let</span> tracker = GLOBAL_TRACKERS.insert(Tracker::new(RequestInfo::new(<br>        req.get_context(),<br>        RequestType::KvGet,<br>        req.get_version(),<br>    )));<br>    set_tls_tracker_token(tracker);<br>    <span class="hljs-keyword">let</span> start = Instant::now();<br>    <span class="hljs-keyword">let</span> v = storage.get(<br>        req.take_context(),<br>        Key::from_raw(req.get_key()),<br>        req.get_version().into(),<br>    );<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>        <span class="hljs-keyword">let</span> v = v.<span class="hljs-keyword">await</span>;<br>        <span class="hljs-keyword">let</span> duration_ms = duration_to_ms(start.saturating_elapsed());<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> resp = GetResponse::default();<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(err) = extract_region_error(&amp;v) &#123;<br>            resp.set_region_error(err);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">match</span> v &#123;<br>                <span class="hljs-literal">Ok</span>((val, stats)) =&gt; &#123;<br>                    ...<br>                &#125;<br>                <span class="hljs-literal">Err</span>(e) =&gt; resp.set_error(extract_key_error(&amp;e)),<br>            &#125;<br>        &#125;<br>        GLOBAL_TRACKERS.remove(tracker);<br>        <span class="hljs-literal">Ok</span>(resp)<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>自 3.x 版本以来，KVService 利用了多个宏显著减少了不同 RPC handler 间的冗余代码，然而这些宏目前还不能被 Clion 等调试工具的函数调用关系链捕捉到，这可能会困惑刚开始查看函数调用链却无法找到对应 handler 的新同学。</p><p>通过本小节，希望您能够了解 KVService 的作用和 TiKV 的启动流程，不仅具备寻找全局重要结构体初始化代码片段的能力，还能够迅速找到 KVService 中需要的 RPC handler 开始从上到下追踪 RPC 请求的调用路径。</p><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p>Storage 模块位于 Service 与底层 KV 存储引擎之间，主要负责事务的并发控制。TiKV 端事务相关的实现都在 Storage 模块中。有关 3.x 版本的 Storage 模块可以参照 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-11" target="_blank" rel="noopener">TiKV 源码解析系列文章（十一）Storage - 事务控制层</a>。</p><p>经过三个大版本的迭代，Storage 和 Scheduler 结构体已经发生了一些变化，本小节将基于之前的源码解析文档做一些更新和补充。</p><p>Storage 结构体：</p><ul><li>engine：代表的是底层的 KV 存储引擎，利用 Trait Bound 来约束接口，拥有多种实现。实际 TiKV 使用的是 RaftKV 引擎，当调用 RaftKV 的 async_write 进行写入操作时，如果 async_write 通过回调方式成功返回了，说明写入操作已经通过 raft 复制给了大多数副本，并且在 leader 节点（调用者所在 TiKV）完成写入，后续 leader 节点上的读就能够看到之前写入的内容</li><li>sched：事务调度器，负责并发事务请求的调度工作</li><li>readPool：读取线程池，所有只读 KV 请求，包括事务的和非事务的，如 raw get、txn kv get 等最终都会在这个线程池内执行。由于只读请求不需要获取 latches，所以为其分配一个独立的线程池直接执行，而不是与非只读事务共用事务调度器。值得注意的是，当前版本的 readPool 已经支持根据读请求中的 priority 字段来差别调度读请求，而不是全部看做相同优先级的任务来公平调度</li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Storage</span></span>&lt;E: Engine, L: LockManager, F: KvFormat&gt; &#123;<br>    <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Too many Arcs, would be slow when clone.</span><br>    engine: E,<br><br>    sched: TxnScheduler&lt;E, L&gt;,<br><br>    <span class="hljs-comment">/// The thread pool used to run most read operations.</span><br>    read_pool: ReadPoolHandle,<br><br>    ...<br>&#125;<br><br><span class="hljs-meta">#[derive(Clone)]</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">ReadPoolHandle</span></span> &#123;<br>    FuturePools &#123;<br>        read_pool_high: FuturePool,<br>        read_pool_normal: FuturePool,<br>        read_pool_low: FuturePool,<br>    &#125;,<br>    Yatp &#123;<br>        remote: Remote&lt;TaskCell&gt;,<br>        running_tasks: IntGauge,<br>        max_tasks: <span class="hljs-built_in">usize</span>,<br>        pool_size: <span class="hljs-built_in">usize</span>,<br>    &#125;,<br>&#125;<br></code></pre></div></td></tr></table></figure><p>Scheduler 结构体：</p><ul><li>id_alloc：到达 Scheduler 的请求都会被分配一个唯一的 command id</li><li>latches：写请求到达 Scheduler 之后会尝试获取所需要的 latch，如果暂时获取不到所需要的 latch，其对应的 command id 会被插入到 latch 的 waiting list 里，当前面的请求执行结束后会唤醒 waiting list 里的请求继续执行。至于为什么需要 latches，可以参考 <a href="https://pingcap.com/zh/blog/tikv-source-code-reading-12" target="_blank" rel="noopener">TiKV 源码解析系列文章（十二）分布式事务</a> 中的 <code>Scheduler 与 Latch</code> 章节</li><li>task_slots：用于存储 Scheduler 中所有请求的上下文，比如暂时未能获取到所有所需 latch 的请求会被暂存在 task_slots 中</li><li>lock_mgr：悲观事务冲突管理器，当多个并行悲观事务之间存在冲突时可能会暂时阻塞某些事务。TiKV 悲观事务具体原理可参考博客 <a href="https://zhuanlan.zhihu.com/p/79034576" target="_blank" rel="noopener">TiDB 新特性漫谈：悲观事务</a></li><li>pipelined_pessimistic_lock/in_memory_pessimistic_lock/enable_async_apply_prewrite：TiKV 悲观事务若干优化引入的新字段，具体优化可参考博客 <a href="https://baijiahao.baidu.com/s?id=1735680656672605012&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">TiDB 6.0 实战分享丨内存悲观锁原理浅析与实践</a></li></ul><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Scheduler which schedules the execution of `storage::Command`s.</span><br><span class="hljs-meta">#[derive(Clone)]</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Scheduler</span></span>&lt;E: Engine, L: LockManager&gt; &#123;<br>    inner: Arc&lt;SchedulerInner&lt;L&gt;&gt;,<br>    <span class="hljs-comment">// The engine can be fetched from the thread local storage of scheduler threads.</span><br>    <span class="hljs-comment">// So, we don't store the engine here.</span><br>    _engine: PhantomData&lt;E&gt;,<br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">SchedulerInner</span></span>&lt;L: LockManager&gt; &#123;<br>    <span class="hljs-comment">// slot_id -&gt; &#123; cid -&gt; `TaskContext` &#125; in the slot.</span><br>    task_slots: <span class="hljs-built_in">Vec</span>&lt;CachePadded&lt;Mutex&lt;HashMap&lt;<span class="hljs-built_in">u64</span>, TaskContext&gt;&gt;&gt;&gt;,<br><br>    <span class="hljs-comment">// cmd id generator</span><br>    id_alloc: CachePadded&lt;AtomicU64&gt;,<br><br>    <span class="hljs-comment">// write concurrency control</span><br>    latches: Latches,<br><br>    sched_pending_write_threshold: <span class="hljs-built_in">usize</span>,<br><br>    <span class="hljs-comment">// worker pool</span><br>    worker_pool: SchedPool,<br><br>    <span class="hljs-comment">// high priority commands and system commands will be delivered to this pool</span><br>    high_priority_pool: SchedPool,<br><br>    <span class="hljs-comment">// used to control write flow</span><br>    running_write_bytes: CachePadded&lt;AtomicUsize&gt;,<br><br>    flow_controller: Arc&lt;FlowController&gt;,<br><br>    control_mutex: Arc&lt;tokio::sync::Mutex&lt;<span class="hljs-built_in">bool</span>&gt;&gt;,<br><br>    lock_mgr: L,<br><br>    concurrency_manager: ConcurrencyManager,<br><br>    pipelined_pessimistic_lock: Arc&lt;AtomicBool&gt;,<br><br>    in_memory_pessimistic_lock: Arc&lt;AtomicBool&gt;,<br><br>    enable_async_apply_prewrite: <span class="hljs-built_in">bool</span>,<br><br>    resource_tag_factory: ResourceTagFactory,<br><br>    quota_limiter: Arc&lt;QuotaLimiter&gt;,<br>    feature_gate: FeatureGate,<br>&#125;<br></code></pre></div></td></tr></table></figure><p>最开始看到 id_alloc 和 task_slots 的介绍时往往会好奇为每个 command 生成唯一 id 的意义是什么？ task_slots 里面存的上下文到底是什么？实际上这与 TiKV 的异步执行框架有关系。</p><p>以下是 Storage 模块执行事务请求的关键函数 schedule_command，可以看到，每个请求一进入函数首先会申请一个递增唯一的 cid，接着依据该 cid 将本次请求的 command 包在一个 task 中，然后将该 task 附带 callback 生成一个 TaskContext 插入到 task_slot 中，之后便会尝试去申请 latches，如果成功便会继续调用 execute 函数去真正执行 task，否则便似乎没有下文了？那么如果 task 申请 latches 失败，之后该 task 会在什么时候被执行呢？</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">schedule_command</span></span>(&amp;<span class="hljs-keyword">self</span>, cmd: Command, callback: StorageCallback) &#123;<br>    <span class="hljs-keyword">let</span> cid = <span class="hljs-keyword">self</span>.inner.gen_id();<br>    <span class="hljs-keyword">let</span> tracker = get_tls_tracker_token();<br>    debug!(<span class="hljs-string">"received new command"</span>; <span class="hljs-string">"cid"</span> =&gt; cid, <span class="hljs-string">"cmd"</span> =&gt; ?cmd, <span class="hljs-string">"tracker"</span> =&gt; ?tracker);<br>    <span class="hljs-keyword">let</span> tag = cmd.tag();<br>    <span class="hljs-keyword">let</span> priority_tag = get_priority_tag(cmd.priority());<br>    SCHED_STAGE_COUNTER_VEC.get(tag).new.inc();<br>    SCHED_COMMANDS_PRI_COUNTER_VEC_STATIC<br>        .get(priority_tag)<br>        .inc();<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> task_slot = <span class="hljs-keyword">self</span>.inner.get_task_slot(cid);<br>    <span class="hljs-keyword">let</span> tctx = task_slot.entry(cid).or_insert_with(|| &#123;<br>        <span class="hljs-keyword">self</span>.inner<br>            .new_task_context(Task::new(cid, tracker, cmd), callback)<br>    &#125;);<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.inner.latches.acquire(&amp;<span class="hljs-keyword">mut</span> tctx.lock, cid) &#123;<br>        fail_point!(<span class="hljs-string">"txn_scheduler_acquire_success"</span>);<br>        tctx.on_schedule();<br>        <span class="hljs-keyword">let</span> task = tctx.task.take().unwrap();<br>        <span class="hljs-built_in">drop</span>(task_slot);<br>        <span class="hljs-keyword">self</span>.execute(task);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">let</span> task = tctx.task.as_ref().unwrap();<br>    <span class="hljs-keyword">let</span> deadline = task.cmd.deadline();<br>    <span class="hljs-keyword">let</span> cmd_ctx = task.cmd.ctx().clone();<br>    <span class="hljs-keyword">self</span>.fail_fast_or_check_deadline(cid, tag, cmd_ctx, deadline);<br>    fail_point!(<span class="hljs-string">"txn_scheduler_acquire_fail"</span>);<br>&#125;<br><br><span class="hljs-comment">/// Task is a running command.</span><br><span class="hljs-keyword">pub</span>(<span class="hljs-keyword">super</span>) <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Task</span></span> &#123;<br>    <span class="hljs-keyword">pub</span>(<span class="hljs-keyword">super</span>) cid: <span class="hljs-built_in">u64</span>,<br>    <span class="hljs-keyword">pub</span>(<span class="hljs-keyword">super</span>) tracker: TrackerToken,<br>    <span class="hljs-keyword">pub</span>(<span class="hljs-keyword">super</span>) cmd: Command,<br>    <span class="hljs-keyword">pub</span>(<span class="hljs-keyword">super</span>) extra_op: ExtraOp,<br>&#125;<br><br><span class="hljs-comment">// It stores context of a task.</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">TaskContext</span></span> &#123;<br>    task: <span class="hljs-built_in">Option</span>&lt;Task&gt;,<br><br>    lock: Lock,<br>    cb: <span class="hljs-built_in">Option</span>&lt;StorageCallback&gt;,<br>    pr: <span class="hljs-built_in">Option</span>&lt;ProcessResult&gt;,<br>    <span class="hljs-comment">// The one who sets `owned` from false to true is allowed to take</span><br>    <span class="hljs-comment">// `cb` and `pr` safely.</span><br>    owned: AtomicBool,<br>    write_bytes: <span class="hljs-built_in">usize</span>,<br>    tag: CommandKind,<br>    <span class="hljs-comment">// How long it waits on latches.</span><br>    <span class="hljs-comment">// latch_timer: Option&lt;Instant&gt;,</span><br>    latch_timer: Instant,<br>    <span class="hljs-comment">// Total duration of a command.</span><br>    _cmd_timer: CmdTimer,<br>&#125;<br><br><span class="hljs-comment">/// Latches which are used for concurrency control in the scheduler.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// Each latch is indexed by a slot ID, hence the term latch and slot are used</span><br><span class="hljs-comment">/// interchangeably, but conceptually a latch is a queue, and a slot is an index</span><br><span class="hljs-comment">/// to the queue.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Latches</span></span> &#123;<br>    slots: <span class="hljs-built_in">Vec</span>&lt;CachePadded&lt;Mutex&lt;Latch&gt;&gt;&gt;,<br>    size: <span class="hljs-built_in">usize</span>,<br>&#125;<br></code></pre></div></td></tr></table></figure><p>进入 <code>Latches::acquire</code> 函数中去细究，可以看到其会渐进的去收集所有 latch，如果在本次函数调用中没有收集到所有的 latch， 当前线程不会受到任何阻塞而是直接返回 false。当然在返回 false 之前其也会利用 <code>latch.wair_for_wake</code> 函数将当前 task 的 id 放到对应 latch 的 waiting 队列里面，之后当前线程便可以处理其他的任务而不是阻塞在该任务上。由于每个获取到所有 latch 去执行的任务会在执行结束后调用 <code>scheduler::release_lock</code> 函数来释放所拥有的全部 latch，在释放过程中，其便能够获取到阻塞在这些 latch 且位于 waiting 队列首位的所有其他 task，接着对应线程会调用 <code>scheduler::try_to_wake_up</code> 函数遍历唤醒这些 task 并尝试再次获取 latch 和执行，一旦能够获取成功便去 execute，否则继续阻塞等待其他线程再次唤醒即可。</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// Tries to acquire the latches specified by the `lock` for command with ID</span><br><span class="hljs-comment">/// `who`.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// This method will enqueue the command ID into the waiting queues of the</span><br><span class="hljs-comment">/// latches. A latch is considered acquired if the command ID is the first</span><br><span class="hljs-comment">/// one of elements in the queue which have the same hash value. Returns</span><br><span class="hljs-comment">/// true if all the Latches are acquired, false otherwise.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">acquire</span></span>(&amp;<span class="hljs-keyword">self</span>, lock: &amp;<span class="hljs-keyword">mut</span> Lock, who: <span class="hljs-built_in">u64</span>) -&gt; <span class="hljs-built_in">bool</span> &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> acquired_count: <span class="hljs-built_in">usize</span> = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> &amp;key_hash <span class="hljs-keyword">in</span> &amp;lock.required_hashes[lock.owned_count..] &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> latch = <span class="hljs-keyword">self</span>.lock_latch(key_hash);<br>        <span class="hljs-keyword">match</span> latch.get_first_req_by_hash(key_hash) &#123;<br>            <span class="hljs-literal">Some</span>(cid) =&gt; &#123;<br>                <span class="hljs-keyword">if</span> cid == who &#123;<br>                    acquired_count += <span class="hljs-number">1</span>;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    latch.wait_for_wake(key_hash, who);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-literal">None</span> =&gt; &#123;<br>                latch.wait_for_wake(key_hash, who);<br>                acquired_count += <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>    lock.owned_count += acquired_count;<br>    lock.acquired()<br>&#125;<br><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">wait_for_wake</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, key_hash: <span class="hljs-built_in">u64</span>, cid: <span class="hljs-built_in">u64</span>) &#123;<br>    <span class="hljs-keyword">self</span>.waiting.push_back(<span class="hljs-literal">Some</span>((key_hash, cid)));<br>&#125;<br><br><span class="hljs-comment">/// Releases all the latches held by a command.</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">release_lock</span></span>(&amp;<span class="hljs-keyword">self</span>, lock: &amp;Lock, cid: <span class="hljs-built_in">u64</span>) &#123;<br>    <span class="hljs-keyword">let</span> wakeup_list = <span class="hljs-keyword">self</span>.inner.latches.release(lock, cid);<br>    <span class="hljs-keyword">for</span> wcid <span class="hljs-keyword">in</span> wakeup_list &#123;<br>        <span class="hljs-keyword">self</span>.try_to_wake_up(wcid);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/// Releases all latches owned by the `lock` of command with ID `who`,</span><br><span class="hljs-comment">/// returns the wakeup list.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// Preconditions: the caller must ensure the command is at the front of the</span><br><span class="hljs-comment">/// latches.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">release</span></span>(&amp;<span class="hljs-keyword">self</span>, lock: &amp;Lock, who: <span class="hljs-built_in">u64</span>) -&gt; <span class="hljs-built_in">Vec</span>&lt;<span class="hljs-built_in">u64</span>&gt; &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> wakeup_list: <span class="hljs-built_in">Vec</span>&lt;<span class="hljs-built_in">u64</span>&gt; = <span class="hljs-built_in">vec!</span>[];<br>    <span class="hljs-keyword">for</span> &amp;key_hash <span class="hljs-keyword">in</span> &amp;lock.required_hashes[..lock.owned_count] &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> latch = <span class="hljs-keyword">self</span>.lock_latch(key_hash);<br>        <span class="hljs-keyword">let</span> (v, front) = latch.pop_front(key_hash).unwrap();<br>        <span class="hljs-built_in">assert_eq!</span>(front, who);<br>        <span class="hljs-built_in">assert_eq!</span>(v, key_hash);<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(wakeup) = latch.get_first_req_by_hash(key_hash) &#123;<br>            wakeup_list.push(wakeup);<br>        &#125;<br>    &#125;<br>    wakeup_list<br>&#125;<br><br><span class="hljs-comment">/// Tries to acquire all the necessary latches. If all the necessary latches</span><br><span class="hljs-comment">/// are acquired, the method initiates a get snapshot operation for further</span><br><span class="hljs-comment">/// processing.</span><br><span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">try_to_wake_up</span></span>(&amp;<span class="hljs-keyword">self</span>, cid: <span class="hljs-built_in">u64</span>) &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-keyword">self</span>.inner.acquire_lock_on_wakeup(cid) &#123;<br>        <span class="hljs-literal">Ok</span>(<span class="hljs-literal">Some</span>(task)) =&gt; &#123;<br>            fail_point!(<span class="hljs-string">"txn_scheduler_try_to_wake_up"</span>);<br>            <span class="hljs-keyword">self</span>.execute(task);<br>        &#125;<br>        <span class="hljs-literal">Ok</span>(<span class="hljs-literal">None</span>) =&gt; &#123;&#125;<br>        <span class="hljs-literal">Err</span>(err) =&gt; &#123;<br>            <span class="hljs-comment">// Spawn the finish task to the pool to avoid stack overflow</span><br>            <span class="hljs-comment">// when many queuing tasks fail successively.</span><br>            <span class="hljs-keyword">let</span> this = <span class="hljs-keyword">self</span>.clone();<br>            <span class="hljs-keyword">self</span>.inner<br>                .worker_pool<br>                .pool<br>                .spawn(<span class="hljs-keyword">async</span> <span class="hljs-keyword">move</span> &#123;<br>                    this.finish_with_err(cid, err);<br>                &#125;)<br>                .unwrap();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>实际上一旦构造出 TaskContext 并插入到 task_slots 中，只要持有 id 便可以去 task_slots 中获取到该 task 和其对应的 callback，那么任何一个线程都可以去执行该任务并返回客户端对应的执行结果。</p><p>总体来看，这样的异步执行方案相当于在 command 级别抽象出了一套类协程调度逻辑，再辅以 Rust 原生的无栈协程，减少了很多 grpc 线程之间的同步阻塞和切换。</p><p>通过本小节，希望您能够了解 Storage 模块的组织结构，并对 scheduler 的异步并发请求调度方案有一定的认知，能够在正确的位置去追踪单个请求的异步调用路径。</p><h3 id="RaftStore"><a href="#RaftStore" class="headerlink" title="RaftStore"></a>RaftStore</h3><p>RaftStore 常被认为是 TiKV 最复杂，最晦涩的模块，劝退了相当一部分开发者。</p><p>在笔者看来这主要跟要保证 multi-raft + split/merge 在各种 case 下的一致性/正确性有关，本身的语义就十分复杂，那实现也就很难简单了。尽管有太多需要注意的细节，但如果仅要了解 RaftStore 的大体框架依然是可行的。</p><p><a href="https://pingcap.com/zh/blog/tikv-source-code-reading-17" target="_blank" rel="noopener">TiKV 源码解析系列文章（十七）raftstore 概览</a> 介绍了 3.x 版本的 RaftStore，目前 RaftStore 已经有了些许的变化，本小节将简单补充笔者的理解。</p><p>Batch System 是 RaftStore 处理的基石，是一套用来并发驱动状态机的机制。</p><p>状态机的核心定义如下：<br><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// A `Fsm` is a finite state machine. It should be able to be notified for</span><br><span class="hljs-comment">/// updating internal state according to incoming messages.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">trait</span> <span class="hljs-title">Fsm</span></span> &#123;<br>    <span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Message</span></span>: <span class="hljs-built_in">Send</span>;<br><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">is_stopped</span></span>(&amp;<span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">bool</span>;<br><br>    <span class="hljs-comment">/// Set a mailbox to FSM, which should be used to send message to itself.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">set_mailbox</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, _mailbox: Cow&lt;<span class="hljs-symbol">'_</span>, BasicMailbox&lt;<span class="hljs-keyword">Self</span>&gt;&gt;)<br>    <span class="hljs-keyword">where</span><br>        <span class="hljs-keyword">Self</span>: <span class="hljs-built_in">Sized</span>,<br>    &#123;<br>    &#125;<br>    <span class="hljs-comment">/// Take the mailbox from FSM. Implementation should ensure there will be</span><br>    <span class="hljs-comment">/// no reference to mailbox after calling this method.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">take_mailbox</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) -&gt; <span class="hljs-built_in">Option</span>&lt;BasicMailbox&lt;<span class="hljs-keyword">Self</span>&gt;&gt;<br>    <span class="hljs-keyword">where</span><br>        <span class="hljs-keyword">Self</span>: <span class="hljs-built_in">Sized</span>,<br>    &#123;<br>        <span class="hljs-literal">None</span><br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">get_priority</span></span>(&amp;<span class="hljs-keyword">self</span>) -&gt; Priority &#123;<br>        Priority::Normal<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/// A unify type for FSMs so that they can be sent to channel easily.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">FsmTypes</span></span>&lt;N, C&gt; &#123;<br>    Normal(<span class="hljs-built_in">Box</span>&lt;N&gt;),<br>    Control(<span class="hljs-built_in">Box</span>&lt;C&gt;),<br>    <span class="hljs-comment">// Used as a signal that scheduler should be shutdown.</span><br>    Empty,<br>&#125;<br></code></pre></div></td></tr></table></figure></p><p>状态机通过 PollHandler 来驱动，定义如下：</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// A handler that polls all FSMs in ready.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// A general process works like the following:</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// loop &#123;</span><br><span class="hljs-comment">///     begin</span><br><span class="hljs-comment">///     if control is ready:</span><br><span class="hljs-comment">///         handle_control</span><br><span class="hljs-comment">///     foreach ready normal:</span><br><span class="hljs-comment">///         handle_normal</span><br><span class="hljs-comment">///     light_end</span><br><span class="hljs-comment">///     end</span><br><span class="hljs-comment">/// &#125;</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// A [`PollHandler`] doesn't have to be [`Sync`] because each poll thread has</span><br><span class="hljs-comment">/// its own handler.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">trait</span> <span class="hljs-title">PollHandler</span></span>&lt;N, C&gt;: <span class="hljs-built_in">Send</span> + <span class="hljs-symbol">'static</span> &#123;<br>    <span class="hljs-comment">/// This function is called at the very beginning of every round.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">begin</span></span>&lt;F&gt;(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, _batch_size: <span class="hljs-built_in">usize</span>, update_cfg: F)<br>    <span class="hljs-keyword">where</span><br>        <span class="hljs-keyword">for</span>&lt;<span class="hljs-symbol">'a</span>&gt; F: <span class="hljs-built_in">FnOnce</span>(&amp;<span class="hljs-symbol">'a</span> Config);<br><br>    <span class="hljs-comment">/// This function is called when the control FSM is ready.</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// If `Some(len)` is returned, this function will not be called again until</span><br>    <span class="hljs-comment">/// there are more than `len` pending messages in `control` FSM.</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// If `None` is returned, this function will be called again with the same</span><br>    <span class="hljs-comment">/// FSM `control` in the next round, unless it is stopped.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_control</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, control: &amp;<span class="hljs-keyword">mut</span> C) -&gt; <span class="hljs-built_in">Option</span>&lt;<span class="hljs-built_in">usize</span>&gt;;<br><br>    <span class="hljs-comment">/// This function is called when some normal FSMs are ready.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">handle_normal</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, normal: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">impl</span> DerefMut&lt;Target = N&gt;) -&gt; HandleResult;<br><br>    <span class="hljs-comment">/// This function is called after [`handle_normal`] is called for all FSMs</span><br>    <span class="hljs-comment">/// and before calling [`end`]. The function is expected to run lightweight</span><br>    <span class="hljs-comment">/// works.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">light_end</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, _batch: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">Option</span>&lt;<span class="hljs-keyword">impl</span> DerefMut&lt;Target = N&gt;&gt;]) &#123;&#125;<br><br>    <span class="hljs-comment">/// This function is called at the end of every round.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">end</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, batch: &amp;<span class="hljs-keyword">mut</span> [<span class="hljs-built_in">Option</span>&lt;<span class="hljs-keyword">impl</span> DerefMut&lt;Target = N&gt;&gt;]);<br><br>    <span class="hljs-comment">/// This function is called when batch system is going to sleep.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">pause</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123;&#125;<br><br>    <span class="hljs-comment">/// This function returns the priority of this handler.</span><br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">get_priority</span></span>(&amp;<span class="hljs-keyword">self</span>) -&gt; Priority &#123;<br>        Priority::Normal<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>大体来看，状态机分成两种，normal 和 control。对于每一个 Batch System，只有一个 control 状态机，负责管理和处理一些需要全局视野的任务。其他 normal 状态机负责处理其自身相关的任务。每个状态机都有其绑定的消息和消息队列。PollHandler 负责驱动状态机，处理自身队列中的消息。Batch System 的职责就是检测哪些状态机需要驱动，然后调用 PollHandler 去消费消息。消费消息会产生副作用，而这些副作用或要落盘，或要网络交互。PollHandler 在一个批次中可以处理多个 normal 状态机。</p><p>在 RaftStore 里，一共有两个 Batch System。分别是 RaftBatchSystem 和 ApplyBatchSystem。RaftBatchSystem 用于驱动 Raft 状态机，包括日志的分发、落盘、状态跃迁等。已经提交的日志会被发往 ApplyBatchSystem 进行处理。ApplyBatchSystem 将日志解析并应用到底层 KV 数据库中，执行回调函数。所有的写操作都遵循着这个流程。</p><p><img src="https://img1.www.pingcap.com/prod/2_3696723f56.png" srcset="/img/loading.gif" lazyload alt></p><p>具体一点来说：</p><ul><li>每个 PollHandler 对应一个线程，其在 poll 函数中会持续地检测需要驱动的状态机并进行处理，此外还可能将某些 hot region 路由给其他 PollHandler 来做一些负载均衡操作。</li><li>每个 region 对应一个 raft 组，而每个 raft 组在一个 BatchSystem 里就对应一个 normal 状态机，<ul><li>对于 RaftBatchSystem，参照 <a href="https://cn.pingcap.com/blog/tikv-source-code-reading-2" target="_blank" rel="noopener">TiKV 源码解析系列文章（二）raft-rs proposal 示例情景分析</a> 中提到的 raft-rs 接口，每个 normal 状态机在一轮 loop 中被 PollHandler 获取一次 ready，其中一般包含需要持久化的未提交日志，需要发送的消息和需要应用的已提交日志等。对于需要持久化的未提交日志，最直接的做法便是将其暂时缓存到内存中进行攒批，然后在当前 loop 结尾的 end 函数中统一同步处理，这无疑会影响每轮 loop 的效率， TiKV 的 6.x 版本已经将 loop 结尾的同步 IO 抽到了 loop 外交给了额外的线程池去做，这进一步提升了 store loop 的效率，具体可参考该 <a href="https://github.com/tikv/tikv/issues/10540" target="_blank" rel="noopener">issue</a>。对于需要发送的消息，则通过 Transport 异步发送给对应的 store。对于需要应用的已提交日志，则通过 applyRouter 带着回调函数发给 ApplyBatchSystem。</li><li>对于 ApplyBatchSystem，每个 normal 状态机在一轮 loop 中被 PollHandler 获取 RaftBatchSystem 发来的若干已经提交需要应用的日志，其需要将其攒批提交并在之后执行对应的回调函数返回客户端结果。需要注意的是，返回客户端结果之后 ApplyBatchSystem 还需要向 RaftBatchSystem 再 propose ApplyRes 的消息，从而更新 RaftBatchSystem 的某些内存状态，比如 applyIndex，该字段的更新能够推动某些阻塞在某个 ReadIndex 上的读请求继续执行。</li></ul></li></ul><p>如下便是 BatchSystem 的启动流程及 poll 函数：</p><figure class="highlight rust"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">/// A system that can poll FSMs concurrently and in batch.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// To use the system, two type of FSMs and their PollHandlers need to be</span><br><span class="hljs-comment">/// defined: Normal and Control. Normal FSM handles the general task while</span><br><span class="hljs-comment">/// Control FSM creates normal FSM instances.</span><br><span class="hljs-keyword">pub</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">BatchSystem</span></span>&lt;N: Fsm, C: Fsm&gt; &#123;<br>    name_prefix: <span class="hljs-built_in">Option</span>&lt;<span class="hljs-built_in">String</span>&gt;,<br>    router: BatchRouter&lt;N, C&gt;,<br>    receiver: channel::Receiver&lt;FsmTypes&lt;N, C&gt;&gt;,<br>    low_receiver: channel::Receiver&lt;FsmTypes&lt;N, C&gt;&gt;,<br>    pool_size: <span class="hljs-built_in">usize</span>,<br>    max_batch_size: <span class="hljs-built_in">usize</span>,<br>    workers: Arc&lt;Mutex&lt;<span class="hljs-built_in">Vec</span>&lt;JoinHandle&lt;()&gt;&gt;&gt;&gt;,<br>    joinable_workers: Arc&lt;Mutex&lt;<span class="hljs-built_in">Vec</span>&lt;ThreadId&gt;&gt;&gt;,<br>    reschedule_duration: Duration,<br>    low_priority_pool_size: <span class="hljs-built_in">usize</span>,<br>    pool_state_builder: <span class="hljs-built_in">Option</span>&lt;PoolStateBuilder&lt;N, C&gt;&gt;,<br>&#125;<br><br><span class="hljs-keyword">impl</span>&lt;N, C&gt; BatchSystem&lt;N, C&gt;<br><span class="hljs-keyword">where</span><br>    N: Fsm + <span class="hljs-built_in">Send</span> + <span class="hljs-symbol">'static</span>,<br>    C: Fsm + <span class="hljs-built_in">Send</span> + <span class="hljs-symbol">'static</span>,<br>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">start_poller</span></span>&lt;B&gt;(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, name: <span class="hljs-built_in">String</span>, priority: Priority, builder: &amp;<span class="hljs-keyword">mut</span> B)<br>    <span class="hljs-keyword">where</span><br>        B: HandlerBuilder&lt;N, C&gt;,<br>        B::Handler: <span class="hljs-built_in">Send</span> + <span class="hljs-symbol">'static</span>,<br>    &#123;<br>        <span class="hljs-keyword">let</span> handler = builder.build(priority);<br>        <span class="hljs-keyword">let</span> receiver = <span class="hljs-keyword">match</span> priority &#123;<br>            Priority::Normal =&gt; <span class="hljs-keyword">self</span>.receiver.clone(),<br>            Priority::Low =&gt; <span class="hljs-keyword">self</span>.low_receiver.clone(),<br>        &#125;;<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> poller = Poller &#123;<br>            router: <span class="hljs-keyword">self</span>.router.clone(),<br>            fsm_receiver: receiver,<br>            handler,<br>            max_batch_size: <span class="hljs-keyword">self</span>.max_batch_size,<br>            reschedule_duration: <span class="hljs-keyword">self</span>.reschedule_duration,<br>            joinable_workers: <span class="hljs-keyword">if</span> priority == Priority::Normal &#123;<br>                <span class="hljs-literal">Some</span>(Arc::clone(&amp;<span class="hljs-keyword">self</span>.joinable_workers))<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-literal">None</span><br>            &#125;,<br>        &#125;;<br>        <span class="hljs-keyword">let</span> props = tikv_util::thread_group::current_properties();<br>        <span class="hljs-keyword">let</span> t = thread::Builder::new()<br>            .name(name)<br>            .spawn_wrapper(<span class="hljs-keyword">move</span> || &#123;<br>                tikv_util::thread_group::set_properties(props);<br>                set_io_type(IoType::ForegroundWrite);<br>                poller.poll();<br>            &#125;)<br>            .unwrap();<br>        <span class="hljs-keyword">self</span>.workers.lock().unwrap().push(t);<br>    &#125;<br><br>    <span class="hljs-comment">/// Start the batch system.</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">spawn</span></span>&lt;B&gt;(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, name_prefix: <span class="hljs-built_in">String</span>, <span class="hljs-keyword">mut</span> builder: B)<br>    <span class="hljs-keyword">where</span><br>        B: HandlerBuilder&lt;N, C&gt;,<br>        B::Handler: <span class="hljs-built_in">Send</span> + <span class="hljs-symbol">'static</span>,<br>    &#123;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..<span class="hljs-keyword">self</span>.pool_size &#123;<br>            <span class="hljs-keyword">self</span>.start_poller(<br>                thd_name!(<span class="hljs-built_in">format!</span>(<span class="hljs-string">"&#123;&#125;-&#123;&#125;"</span>, name_prefix, i)),<br>                Priority::Normal,<br>                &amp;<span class="hljs-keyword">mut</span> builder,<br>            );<br>        &#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..<span class="hljs-keyword">self</span>.low_priority_pool_size &#123;<br>            <span class="hljs-keyword">self</span>.start_poller(<br>                thd_name!(<span class="hljs-built_in">format!</span>(<span class="hljs-string">"&#123;&#125;-low-&#123;&#125;"</span>, name_prefix, i)),<br>                Priority::Low,<br>                &amp;<span class="hljs-keyword">mut</span> builder,<br>            );<br>        &#125;<br>        <span class="hljs-keyword">self</span>.name_prefix = <span class="hljs-literal">Some</span>(name_prefix);<br>    &#125;<br>&#125;<br><br>    <span class="hljs-comment">/// Polls for readiness and forwards them to handler. Removes stale peers if</span><br>    <span class="hljs-comment">/// necessary.</span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-function"><span class="hljs-keyword">fn</span> <span class="hljs-title">poll</span></span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123;<br>        fail_point!(<span class="hljs-string">"poll"</span>);<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> batch = Batch::with_capacity(<span class="hljs-keyword">self</span>.max_batch_size);<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> reschedule_fsms = <span class="hljs-built_in">Vec</span>::with_capacity(<span class="hljs-keyword">self</span>.max_batch_size);<br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> to_skip_end = <span class="hljs-built_in">Vec</span>::with_capacity(<span class="hljs-keyword">self</span>.max_batch_size);<br><br>        <span class="hljs-comment">// Fetch batch after every round is finished. It's helpful to protect regions</span><br>        <span class="hljs-comment">// from becoming hungry if some regions are hot points. Since we fetch new FSM</span><br>        <span class="hljs-comment">// every time calling `poll`, we do not need to configure a large value for</span><br>        <span class="hljs-comment">// `self.max_batch_size`.</span><br>        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> run = <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">while</span> run &amp;&amp; <span class="hljs-keyword">self</span>.fetch_fsm(&amp;<span class="hljs-keyword">mut</span> batch) &#123;<br>            <span class="hljs-comment">// If there is some region wait to be deal, we must deal with it even if it has</span><br>            <span class="hljs-comment">// overhead max size of batch. It's helpful to protect regions from becoming</span><br>            <span class="hljs-comment">// hungry if some regions are hot points.</span><br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> max_batch_size = std::cmp::max(<span class="hljs-keyword">self</span>.max_batch_size, batch.normals.len());<br>            <span class="hljs-comment">// Update some online config if needed.</span><br>            &#123;<br>                <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> rust 2018 does not support capture disjoint field within a closure.</span><br>                <span class="hljs-comment">// See https://github.com/rust-lang/rust/issues/53488 for more details.</span><br>                <span class="hljs-comment">// We can remove this once we upgrade to rust 2021 or later edition.</span><br>                <span class="hljs-keyword">let</span> batch_size = &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>.max_batch_size;<br>                <span class="hljs-keyword">self</span>.handler.begin(max_batch_size, |cfg| &#123;<br>                    *batch_size = cfg.max_batch_size();<br>                &#125;);<br>            &#125;<br>            max_batch_size = std::cmp::max(<span class="hljs-keyword">self</span>.max_batch_size, batch.normals.len());<br><br>            <span class="hljs-keyword">if</span> batch.control.is_some() &#123;<br>                <span class="hljs-keyword">let</span> len = <span class="hljs-keyword">self</span>.handler.handle_control(batch.control.as_mut().unwrap());<br>                <span class="hljs-keyword">if</span> batch.control.as_ref().unwrap().is_stopped() &#123;<br>                    batch.remove_control(&amp;<span class="hljs-keyword">self</span>.router.control_box);<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(len) = len &#123;<br>                    batch.release_control(&amp;<span class="hljs-keyword">self</span>.router.control_box, len);<br>                &#125;<br>            &#125;<br><br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> hot_fsm_count = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span> (i, p) <span class="hljs-keyword">in</span> batch.normals.iter_mut().enumerate() &#123;<br>                <span class="hljs-keyword">let</span> p = p.as_mut().unwrap();<br>                <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">self</span>.handler.handle_normal(p);<br>                <span class="hljs-keyword">if</span> p.is_stopped() &#123;<br>                    p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Remove);<br>                    reschedule_fsms.push(i);<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> p.get_priority() != <span class="hljs-keyword">self</span>.handler.get_priority() &#123;<br>                    p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Schedule);<br>                    reschedule_fsms.push(i);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">if</span> p.timer.saturating_elapsed() &gt;= <span class="hljs-keyword">self</span>.reschedule_duration &#123;<br>                        hot_fsm_count += <span class="hljs-number">1</span>;<br>                        <span class="hljs-comment">// We should only reschedule a half of the hot regions, otherwise,</span><br>                        <span class="hljs-comment">// it's possible all the hot regions are fetched in a batch the</span><br>                        <span class="hljs-comment">// next time.</span><br>                        <span class="hljs-keyword">if</span> hot_fsm_count % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> &#123;<br>                            p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Schedule);<br>                            reschedule_fsms.push(i);<br>                            <span class="hljs-keyword">continue</span>;<br>                        &#125;<br>                    &#125;<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> HandleResult::StopAt &#123; progress, skip_end &#125; = res &#123;<br>                        p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Release(progress));<br>                        reschedule_fsms.push(i);<br>                        <span class="hljs-keyword">if</span> skip_end &#123;<br>                            to_skip_end.push(i);<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut</span> fsm_cnt = batch.normals.len();<br>            <span class="hljs-keyword">while</span> batch.normals.len() &lt; max_batch_size &#123;<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Ok</span>(fsm) = <span class="hljs-keyword">self</span>.fsm_receiver.try_recv() &#123;<br>                    run = batch.push(fsm);<br>                &#125;<br>                <span class="hljs-comment">// When `fsm_cnt &gt;= batch.normals.len()`:</span><br>                <span class="hljs-comment">// - No more FSMs in `fsm_receiver`.</span><br>                <span class="hljs-comment">// - We receive a control FSM. Break the loop because ControlFsm may change</span><br>                <span class="hljs-comment">//   state of the handler, we shall deal with it immediately after calling</span><br>                <span class="hljs-comment">//   `begin` of `Handler`.</span><br>                <span class="hljs-keyword">if</span> !run || fsm_cnt &gt;= batch.normals.len() &#123;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>                <span class="hljs-keyword">let</span> p = batch.normals[fsm_cnt].as_mut().unwrap();<br>                <span class="hljs-keyword">let</span> res = <span class="hljs-keyword">self</span>.handler.handle_normal(p);<br>                <span class="hljs-keyword">if</span> p.is_stopped() &#123;<br>                    p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Remove);<br>                    reschedule_fsms.push(fsm_cnt);<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> HandleResult::StopAt &#123; progress, skip_end &#125; = res &#123;<br>                    p.policy = <span class="hljs-literal">Some</span>(ReschedulePolicy::Release(progress));<br>                    reschedule_fsms.push(fsm_cnt);<br>                    <span class="hljs-keyword">if</span> skip_end &#123;<br>                        to_skip_end.push(fsm_cnt);<br>                    &#125;<br>                &#125;<br>                fsm_cnt += <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">self</span>.handler.light_end(&amp;<span class="hljs-keyword">mut</span> batch.normals);<br>            <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> &amp;to_skip_end &#123;<br>                batch.schedule(&amp;<span class="hljs-keyword">self</span>.router, *index);<br>            &#125;<br>            to_skip_end.clear();<br>            <span class="hljs-keyword">self</span>.handler.end(&amp;<span class="hljs-keyword">mut</span> batch.normals);<br><br>            <span class="hljs-comment">// Iterate larger index first, so that `swap_reclaim` won't affect other FSMs</span><br>            <span class="hljs-comment">// in the list.</span><br>            <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> reschedule_fsms.iter().rev() &#123;<br>                batch.schedule(&amp;<span class="hljs-keyword">self</span>.router, *index);<br>                batch.swap_reclaim(*index);<br>            &#125;<br>            reschedule_fsms.clear();<br>        &#125;<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-literal">Some</span>(fsm) = batch.control.take() &#123;<br>            <span class="hljs-keyword">self</span>.router.control_scheduler.schedule(fsm);<br>            info!(<span class="hljs-string">"poller will exit, release the left ControlFsm"</span>);<br>        &#125;<br>        <span class="hljs-keyword">let</span> left_fsm_cnt = batch.normals.len();<br>        <span class="hljs-keyword">if</span> left_fsm_cnt &gt; <span class="hljs-number">0</span> &#123;<br>            info!(<br>                <span class="hljs-string">"poller will exit, schedule &#123;&#125; left NormalFsms"</span>,<br>                left_fsm_cnt<br>            );<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>..left_fsm_cnt &#123;<br>                <span class="hljs-keyword">let</span> to_schedule = <span class="hljs-keyword">match</span> batch.normals[i].take() &#123;<br>                    <span class="hljs-literal">Some</span>(f) =&gt; f,<br>                    <span class="hljs-literal">None</span> =&gt; <span class="hljs-keyword">continue</span>,<br>                &#125;;<br>                <span class="hljs-keyword">self</span>.router.normal_scheduler.schedule(to_schedule.fsm);<br>            &#125;<br>        &#125;<br>        batch.clear();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>通过本小节，希望您能够了解 BatchSystem 的大体框架，并知悉 PollHandler 和 FSM 的物理含义，以便结合之后的博客去熟悉全链路读写流程。</p><h2 id="调试方案"><a href="#调试方案" class="headerlink" title="调试方案"></a>调试方案</h2><p>断点调试是一种学习源码的有效手段。当不是很熟悉 gdb 等工具时，使用一些更现代的 IDE 会大幅提升调试代码的体验。</p><p>笔者平时采用了 CLion + intellij-rust 的工具链来调试 Rust 代码。需要注意的是，在使用 CLion 调试 TiKV 源码时，需要参照 <a href="https://doc.rust-lang.org/cargo/reference/profiles.html" target="_blank" rel="noopener">Cargo book</a> 修改 TiKV cargo.toml 中 <code>[profile.test]</code> 和 <code>[profile.dev]</code> 的 <a href="https://github.com/tikv/tikv/blob/master/Cargo.toml#L327" target="_blank" rel="noopener">debug 选项</a> 来开启调试信息，否则在 Clion 里断点调试时会无法看到对应的堆栈信息。</p><p>实际上如果要做到以上读写路径的全链路追踪，最简单的方法便是从集成测试里面寻找一些 case，接着从 Service 模块开始打断点，之后执行调试即可。在这里推荐 <code>integrations/server/kv_service.rs</code> 中的测试，里面的 test 都会构造 <code>TiKVClient</code> 发送真实的 RPC 请求，且服务端也基本不包含 Mock 组件，可以完整的去追踪一条 RPC 的全链路流程。</p><p>此外由于 TiKV 的代码中有比较多的 spawn 和回调函数，刚开始可能并不能很直接的串起来流程，但相信通过上文的介绍，您已经大致了解其异步框架的实现，从而可以在正确的闭包位置打下断点，进而熟悉地追踪单条请求的全链路实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客介绍了 TiKV 的基本概念，TiKV 读写路径上的三个重要模块（KVService，Storage，RaftStore）和断点调试 TiKV 学习源码的方案</p><p>希望本博客能够帮助对 TiKV 开发感兴趣的新同学尽快了解 TiKV 的 codebase。</p><p>感谢您的阅读~</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>源码阅读</tag>
      
      <tag>TiKV</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Talent-Plan：用 Rust 实现简易 KV 引擎</title>
    <link href="/naive-kvengine-in-rust/"/>
    <url>/naive-kvengine-in-rust/</url>
    
    <content type="html"><![CDATA[<h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><ul><li><a href="https://github.com/pingcap/talent-plan/tree/master/courses/rust" target="_blank" rel="noopener">官网版本</a></li></ul><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>Rust 学习</p><ul><li><a href="https://fasterthanli.me/articles/a-half-hour-to-learn-rust" target="_blank" rel="noopener">半小时学习 Rust</a></li><li><a href="https://github.com/rust-lang/rustlings" target="_blank" rel="noopener">Rustling</a> 及 <a href="https://github.com/OneSizeFitsQuorum/rustlings/pull/1" target="_blank" rel="noopener">解答</a></li><li><a href="https://course.rs/about-book.html" target="_blank" rel="noopener">Rust 语言圣经</a> 及 <a href="https://zh.practice.rs/why-exercise.html" target="_blank" rel="noopener">习题</a></li><li><a href="https://kaisery.github.io/trpl-zh-cn/title-page.html" target="_blank" rel="noopener">Rust 官方文档</a></li><li><a href="https://zhuanlan.zhihu.com/p/558415847" target="_blank" rel="noopener">Talent Plan Percolator Lab</a></li></ul><h2 id="过关过程"><a href="#过关过程" class="headerlink" title="过关过程"></a>过关过程</h2><h3 id="Rust-Project-1-The-Rust-toolbox"><a href="#Rust-Project-1-The-Rust-toolbox" class="headerlink" title="Rust Project 1: The Rust toolbox"></a>Rust Project 1: The Rust toolbox</h3><p>本 project 过关代码可参考该 <a href="https://github.com/OneSizeFitsQuorum/PracticalNetworkedApplications/commit/1a0ca3eb1af93c33a3bb9881dec782dbd623aa49" target="_blank" rel="noopener">commit</a>。</p><p>主要参照了 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/blob/master/courses/rust/projects/project-1/README.md" target="_blank" rel="noopener">README</a> 来完成本 project，具体过程比较 trivial 不再细述。主要工作如下：</p><ul><li>搭建项目基本目录结构。</li><li>使用 <a href="https://docs.rs/clap/3.2.15/clap/" target="_blank" rel="noopener">clap</a> 来解析命令行参数，根据官方文档学习 crate 的具体使用方法。</li><li>使用 cargo.toml 中的若干参数，包括 dev-dependencies，条件编译等等。</li><li>完成基于内存 hashmap 的 KvStore 的增删改查接口。</li><li>增加包文档和函数文档并在文档中添加了文档测试</li><li>使用 cargo fmt 和 cargo clippy 来提升代码质量</li></ul><h3 id="Rust-Project-2-Log-structured-file-I-O"><a href="#Rust-Project-2-Log-structured-file-I-O" class="headerlink" title="Rust Project 2: Log-structured file I/O"></a>Rust Project 2: Log-structured file I/O</h3><p>本 project 过关代码可参考该 <a href="https://github.com/OneSizeFitsQuorum/PracticalNetworkedApplications/commit/fb097b172c46784ed7ebe24afdec0a8ab5d3d399" target="_blank" rel="noopener">commit</a>。</p><h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>在阅读 failure crate 的 <a href="https://boats.gitlab.io/failure/" target="_blank" rel="noopener">文档</a> 之后，在本 project 中采用了第二种错误处理方式——自定义错误结构。通过定义 KVStoreError 结构体并使用 failure crate 提供的能力，可以很轻易地捕捉不同的错误并列举他们的表示，调用者也可以直接通过模式匹配的方式得到错误类型。</p><p>此外，通过为 io:Error 和 serde_json:Error 添加转换到 KVStoreError 的函数，在主逻辑中可以轻松的使用 ? 来向上传递错误，从而避免对 Result 类型的暴力 unwrap。</p><p>此外，还定义了 Result<T> 类型别名来统一本项目中所有的 Result 返回类型。</T></p><p><img src="/naive-kvengine-in-rust/boxcnvQkj4GJmiTwJeV21SmMeFf.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="包结构"><a href="#包结构" class="headerlink" title="包结构"></a>包结构</h4><p>对于包含一个 lib 包和一个 bin 包的 crate ，在 lib 包中，需要引用所有新增文件的文件名当做其模块名将其引入，此外还需要使用 pub use 语法来将 bin 包会用到的结构公开导出。</p><p>在 lib 包的任何文件里，都可以通过 crate:: 的方式来引入本 lib 库被公开导出的结构。</p><p>在 bin 包中，需要通过实际 crate 名：: 的方式来引入同名 lib 库被公开导出的结构。</p><p><img src="/naive-kvengine-in-rust/boxcnYwXTYAHx39aKM0Pljd8R7b.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnnTJ4rUCXtxN59nGmDPclRc.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnwOPKgrmNT5kp3zgO5UB2Tc.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn1GHZz1EW2O6yQvws5Xz0Ah.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="结果捕捉"><a href="#结果捕捉" class="headerlink" title="结果捕捉"></a>结果捕捉</h4><p><img src="/naive-kvengine-in-rust/boxcn4BhJAA4AnwlfT6ksZkY7Ye.png" srcset="/img/loading.gif" lazyload alt></p><p>结果捕捉中的正常/异常处理需要满足以上题意的要求，因而在 main 函数中原样实现了以上需求如下。</p><p><img src="/naive-kvengine-in-rust/boxcnFEf4FsRUzUJXg3v9CORCQc.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h4><p>KvStore 结构体中各个变量含义如下：</p><ul><li>Index ：参照 bitcask 的模型，key 为 kv pair 的 key，value 并不存储对应的 value，而是存储该 value 在第 file_number 个文件的 offset 处，长度为 length。</li><li>current_readers：对于所有已经存在的文件，KvStore 都缓存了一个 BufReader 来便于 seek 到对应的 offset 去 read。实际上也可以没有该结构体每次需要 reader 时新建即可，但复用 reader 可以一定程度上减少资源的损耗。</li><li>current_writer：当前正在写入的 file，其每次写入只需要 append 即可，不需要 seek。新建一个 BufWriterWithPosition 结构体的原因是能够快速的获取当前写入的 offset，而不需要在通过 seek(SeekFrom::Current(0))（可能是系统调用） 的方式去获取。</li><li>current_file_number：当前最大的 file_number，每次 compaction 之后会新增 1。每个数据文件都会附带一个 file_number，file_number 越大的文件越新，该 version 能够保证恢复时的正确性。</li><li>dir_path：当前文件目录路径。</li><li>useless_size：当前无用的数据总和。当改值大于某一个阈值时，会触发一次 compaction。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnY6aDLMIS6gKAnE8vWIz1Gh.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnQyOZ7qGBDfLOSbKLQdpKXg.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnRZrLuatQsEySdLCweP9hJf.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h4><p>使用 serde_json 将 set 命令序列化，接着再写入到 current_writer 中，然后在 index map 中维护该 key 的索引。注意如果某 key 之前已在 KvStore 中存在，则 insert 函数会返回该 key 的旧 value，此时需要维护 useless_size。最后判断如果 useless_size 超过某一个阈值，则进行一次 compact。</p><p>需要注意许多返回 Result<T, error> 的函数都可以通过 ? 而直接向上传递异常，这得益于 Rust 错误处理的良好抽象。</T,></p><p><img src="/naive-kvengine-in-rust/boxcnvogcxYCj6ePDFug2C3BYUg.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h4><p>首先在 index 中获取该 key 的索引，如果不存在则说明该 key 不存在直接返回即可，否则根据索引中的 file_number 在 current_readers 中拿到对应的 reader，seek 到对应的 offset 并读取长度为 length 的数据。如果存在则返回 value，否则说明遇到了异常，返回错误即可。</p><p><img src="/naive-kvengine-in-rust/boxcnjPcxYncr6MzPFaF5vITIFf.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="删除流程"><a href="#删除流程" class="headerlink" title="删除流程"></a>删除流程</h4><p>首先在 index 中获取该 key 的索引，如果不存在则说明该 key 不存在返回 ErrNotFound 错误即可，否则移除该索引，接着将 rm 命令序列化并写入到 current_writer 中以保证该 key 能够被确定性删除。注意对于能够找到对应 key 的 rm 命令，useless_size 不仅需要增加 rm 命令本身的长度，还需要增加之前 set 命令的长度，因为此时他们俩都已经可以被一起回收。 最后判断如果 useless_size 超过某一个阈值，则进行一次 compact。</p><p><img src="/naive-kvengine-in-rust/boxcnxthxhEe0zV8eIkzz9VYGOf.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="重启流程"><a href="#重启流程" class="headerlink" title="重启流程"></a>重启流程</h4><p>重启时首先初始化若干重要结构，最重要的是调用 recover 函数，该函数将遍历当前所有的文件，不仅将索引维护到 index 结构中，还会将 reader 维护到 current_readers 结构中，最后返回（当前最大的文件版本，当前所有文件的 useless_size)，接着利用 current_file_number 构建当前最大文件的 writer，需要注意由于 bitcask 模型是 append_only 的机制，所以在构建 writer 时需要使用 OpenOptions 来使得 append 属性为 true，这样重启后直接 append 即可。最后根据 use_less 判断是否需要 compact，最后返回即可。</p><p><img src="/naive-kvengine-in-rust/boxcnBf5TfEwrTv7qGI7BqvI1Lh.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 Recover 函数，其需要读取数据目录中的所有文件，按照 file_number 从小到大的顺序去按序 apply 从而保证重启的正确性。</p><p>对于排序，不能直接对文件名排序，因为这样的排序是按照字母编码而不是按照 file_number 大小。因此需要先将所有的 file_number 解析出来再对数字进行排序，之后再利用这些数字索引文件名即可。需要注意这里利用了许多文件操作的链式调用，需要查很多文档。</p><p>在获取到排序好的 versions 之后，可以按序读取文件并将其维护到 index 和 current_readers 中去，注意在该过程中也要注意维护 useless_size。此外得益于 serde_json 的 from_reader().into_iter() 接口，可以按照迭代器的方式去读取 command，而不用关注何时到了末尾，应该读多少字节才可以解析出一个 command，这极大的简化了读取流程。</p><p><img src="/naive-kvengine-in-rust/boxcnLi3nwF781srG69oyMI22Dh.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnBDm1Ma5cBgjhEakKRxtvMe.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="合并流程"><a href="#合并流程" class="headerlink" title="合并流程"></a>合并流程</h4><p>当前的合并流程采用了暴力的全部合并策略，同时将合并放在了客户端可感知延迟的执行流程中。</p><p>当 useless_size 大于某个阈值时，会触发一次合并，此时会增加 file_number 并将 index 中所有的数据都写入到当前新建的文件中，同时更新内存中的索引。接着再删除老文件和对应的 reader，最后再新建一个文件承载之后的写入即可。</p><p>需要注意按照这个流程即使在合并的写文件过程中出现了重启也不会出现正确性问题。如果新文件的所有数据尚未 flush 成功，老文件并不会被删除，那么只要重启时会按照 file_number 从小到大的顺序进行重放，数据便不会丢失。</p><p><img src="/naive-kvengine-in-rust/boxcnwANdnQiduaMqWuTfuqYqtf.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnfOG27BeMg3VNRx3DnIOySb.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="Rust-Project-3-Synchronous-client-server-networking"><a href="#Rust-Project-3-Synchronous-client-server-networking" class="headerlink" title="Rust Project 3: Synchronous client-server networking"></a>Rust Project 3: Synchronous client-server networking</h3><p>本 project 过关代码可参考该 <a href="https://github.com/OneSizeFitsQuorum/PracticalNetworkedApplications/commit/4bf43135e3f662bd7f3a40078d2e648f436ce632" target="_blank" rel="noopener">commit</a>。</p><h4 id="命令行解析"><a href="#命令行解析" class="headerlink" title="命令行解析"></a>命令行解析</h4><p>在本 project 中，命令行分为了客户端 kvs-client 和服务端 kvs-server 两处，因此需要分别进行解析。</p><p>对于 kvs-client，基本继承了 project2 的命令行解析工具，仅仅增加了 addr 的解析。此外也按照题意将正常输出打印在了 stdout 中，将错误输出打印在了 stderr 中并以非 0 值结束进程</p><p><img src="/naive-kvengine-in-rust/boxcnlWsXGHwpQAAaeTPofjL0Kd.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn6NSpWGbC9UEkuyXIACdTJf.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 kvs-server，则是按照题意重新写了参数解析器，并对于 engine 增加了只能 2 选 1 的约束。同时还利用 judge_engine 函数实现了引擎选择的判断：对于第一次启动，按照用户参数来启动对应的引擎，如未指定则使用 kvs；对于之后的启动，必须按照之前的引擎启动，若与用户参数冲突则报错。在参数无问题之后打出对应的关键配置既可。</p><p><img src="/naive-kvengine-in-rust/boxcnI8W6PH9TwZcCP0DC53yUub.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn0ExuHszDnabB7fosTNAXXq.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnzfeeo29RWnUZNdMlRtSNKg.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnyJQWFUM6irMEkN22WYrW7c.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="日志打印"><a href="#日志打印" class="headerlink" title="日志打印"></a>日志打印</h4><p>在本 project 中对日志采用了集成轻量的 env_logger，参照 <a href="https://docs.rs/env_logger/0.9.0/env_logger/" target="_blank" rel="noopener">文档</a> 仅仅需要在进程启动时指定日志的最低级别即可。</p><p><img src="/naive-kvengine-in-rust/boxcncl0pVAsp6LqYau0QRjXAbc.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="命令传输"><a href="#命令传输" class="headerlink" title="命令传输"></a>命令传输</h4><p>本 project 直接使用了 tcp 级别的网络接口来传输命令，因而会有黏包的问题需要处理。</p><p>一般的解决方案是在流上发送每段数据前先写入长度，再写入真实的数据；这样在流上读数据时便可以先读长度，再读对应长度的数据后解除阻塞返回了。</p><p>这样的思路可以自己手写，也可以使用 serde 现成的 reader/writer 接口去实现。因而在客户端构建了一个 Client 结构体对 socket 进行了简单的包装。对于 request，使用了一个 BufWriter 的装饰器配以每次写完数据后的 flush 来降低系统调用的开销啊，其在内部已经能够做到先写入长度再写入数据。对于 response，则是参照重启恢复时的逻辑使用 Deserializer 接口构建 reader，并指定对应的反序列化类型以达到先读长度再读数据的问题。这样便可以利用 serde 帮助解决黏包问题。</p><p><img src="/naive-kvengine-in-rust/boxcnGwjWKxNs7ZmeiWebu1lIoc.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnEArkStGv1C1Us4ew1SguPf.png" srcset="/img/loading.gif" lazyload alt></p><p>对于服务端，获取 request 和发送 response 的流程和客户端类似。</p><p><img src="/naive-kvengine-in-rust/boxcnUw2Q2c0Bvoe3GjIFMHSE05.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="可扩展存储引擎"><a href="#可扩展存储引擎" class="headerlink" title="可扩展存储引擎"></a>可扩展存储引擎</h4><p>为了扩展存储引擎的多种实现，抽象出来了统一的 trait 接口 KvsEngine 以对上暴露 trait 的抽象而隐藏具体的实现细节。这样 kvs-server 在启动时便可以以 trait 的方式去访问 engine，而不需要在意其内部的实现细节。</p><p><img src="/naive-kvengine-in-rust/boxcnPj0lx11Jj3YB6h1REJY7Zf.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn5rZYcmvMfYnXcat5LSeCos.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnG99bQVGuok6gTqhr05Kmkn.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 KvStore，将其 set/get/remove 这三个方法抽象到了 KvsEngine 的实现中。</p><p><img src="/naive-kvengine-in-rust/boxcnzQkpPos1qxbygU4KvMx7Xc.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 Sled，同样实现了 KvsEngine 的三个方法。需要注意其默认接口的语义和格式与 KvsEngine 不一致，因而需要增加对应的转换。</p><p>此外在 set 时注释掉对应的 flush 操作是由于增加上之后性能过于慢，无法在之后的 bench 阶段跑出结果。</p><p><img src="/naive-kvengine-in-rust/boxcniO3GQy0JnxunBBQ3rH7ewg.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h4><p>参照 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/blob/master/courses/rust/projects/project-3/README.md" target="_blank" rel="noopener">Project3 文档</a> 中的介绍创建了 benches/benches 文件并参照 criterion 的 <a href="https://bheisler.github.io/criterion.rs/book/getting_started.html" target="_blank" rel="noopener">用户手册</a> 开始构建性能测试。</p><p><img src="/naive-kvengine-in-rust/boxcnkIOzLCHIFKMU89CnoFKRMc.png" srcset="/img/loading.gif" lazyload alt></p><p>对于性能测试中的三个问题：</p><ul><li>如何精准测量想要测量的时间，而不包括初始化和清理的时间：参照 <a href="https://bheisler.github.io/criterion.rs/book/user_guide/timing_loops.html" target="_blank" rel="noopener">criterion 计时迭代的文档</a> 选择了 iter_batched 接口来精准测量读写的时间，初始化的清理的时间并不会被包括在内。</li><li>尽管使用了 rand，如何使得每次迭代都确定性：这里通过在迭代之前利用 rand 的 <a href="https://rust-random.github.io/book/guide-seq.html" target="_blank" rel="noopener">choose_multiple</a> 函数创建好对应的写入数据，使得每次迭代的操作数都具有相同的集合。</li><li>在读 benchmark 中，如何保证选到的读集合是写集合的子集：这里采用了同样的方法，读集合是在写集合的集成上去随机选择，从而保证了读取必然能够读到。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnH9edzFxF6Ey7CpeEELfj3d.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnjxp5q574LIf0hidMFs4E7d.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnq23CIUQa25i4rf4mFEbk5b.png" srcset="/img/loading.gif" lazyload alt></p><p>最终性能对比如下：尽管已经去掉了 sled 每次写入时的 flush 操作来减少其随机 IO，在单线程客户端的情况下，sled 引擎的写延时大概是自写 bitcask 引擎写延时的 20 倍；sled 引擎的读延时大概是自写 bitcask 引擎读延时的 800 倍。</p><p><img src="/naive-kvengine-in-rust/boxcno48X01i1c9r5i1aeN1XUQh.png" srcset="/img/loading.gif" lazyload alt></p><p>个人猜测产生如此悬殊对比的原因有可能是：</p><ul><li>Sled 专为多线程无锁设计，在单线程下无法体现其性能优势。</li><li>Sled 本质上是一种树状结构，其相比 hash 结构能够提供高效的范围查询，也能够在海量数据场景与磁盘结合起来提供稳定的读延时，因而在小数据量的单点查询场景相比 hash 结构并不占优势。</li><li>当前自写 bitcask 模型还没有引入并发处理的开销，而 sled 是并发安全的，如此对比并不公平。</li></ul><p>本来想用一些 profile 工具测量一下 sled 的火焰图查找一下原因，由于本人的电脑芯片是 M1Pro，许多 profile 工具类如 perf 安装还不是很方便。在参照 <a href="https://github.com/tikv/pprof-rs/blob/master/examples/criterion.rs" target="_blank" rel="noopener"> pprof-rs 的文档</a> 为 criterion 配置之后依然无法打出火焰图，猜测可能跟环境有关系，便没有进一步再研究了，之后有机会在 Linux 下再进行 profile 吧。</p><h3 id="Rust-Project-4-Concurrency-and-parallelism"><a href="#Rust-Project-4-Concurrency-and-parallelism" class="headerlink" title="Rust Project 4: Concurrency and parallelism"></a>Rust Project 4: Concurrency and parallelism</h3><p>本 project 过关代码可参考该 <a href="https://github.com/OneSizeFitsQuorum/PracticalNetworkedApplications/commit/3d31896e832cef31e78380794f768375fc1bfc70" target="_blank" rel="noopener">commit</a>。</p><h4 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h4><p>为了多线程需要抽象出线程池的概念，ThreadPool trait 定义如下：spawn 函数中的闭包 F 不仅需要满足 FnOnce() 的 bound 来满足近执行一次的语义，还要实现 Send + ‘static 的 bound 来实现线程安全的发送接收和足够长的生命周期。</p><p><img src="/naive-kvengine-in-rust/boxcnZcbACyBVBV9JlUYqicx0we.png" srcset="/img/loading.gif" lazyload alt></p><p>对于最简单的 NaiveThreadPool，仅仅需要在 spawn 的时候创建一个线程让其执行即可。</p><p><img src="/naive-kvengine-in-rust/boxcnkG00kSYp5ZcIaGm4TmiKpe.png" srcset="/img/loading.gif" lazyload alt></p><p>对于共享队列的 ThreadPool，参照 RustBook 中的 <a href="https://kaisery.github.io/trpl-zh-cn/ch20-02-multithreaded.html" target="_blank" rel="noopener">举例</a> 即可实现。大体思路是用 channel 做通信，让多个子线程竞争 job 去执行即可。需要注意以下三点：</p><ul><li>std 库自带的 channel 是 MPSC 类型，因而可以支持并发写但不支持并发读。因而要想实现多个子 thread 对 channel 的监听便需要用 Arc<Mutex<receiver>&gt; 来保证不存在并发读。此外也可以使用 crossbeam 的 <a href="https://github.com/crossbeam-rs/crossbeam/tree/master/crossbeam-channel" target="_blank" rel="noopener">mpsc channel</a> 来支持并发读，那样便直接 clone 即可。</Mutex<receiver></li><li>为了优雅停机，对于 Job 又包装了一层枚举和 Terminate 类型来支持子 thread 的优雅退出，此外还需要利用 Box 将闭包 F 放在堆上来支持线程安全的传递闭包。</li><li>由于单元测试中传入的闭包可能会 panic 但不想看到线程池中的线程减少，一种方案是检测到线程 panic 退出之后新增新的线程，另一种方式则是捕获可能得 panic。例如在 Java 中可以使用 try catch 捕捉一个 throwable 的错误，在 go 中可以 defer recover 一个 panic。在 rust 中类似的语法是 <a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html" target="_blank" rel="noopener">catch_unwind</a>，因而在执行真正的 job 闭包时，会使用 panic::catch_unwind(AssertUnwindSafe(job)) 的方式来确保该线程不会由于执行闭包而 panic。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnb0wlmKE1MrtOLIjPnjaiBd.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnkPconSZtYcnSV1O8K4loPk.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn1WUh1RyixFp1UHgsRv44TV.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 RayonThreadPool，直接参考官网的样例初始化对应的 pool 并直接 spawn 给其即可。</p><p><img src="/naive-kvengine-in-rust/boxcnsmyPz8LfrnLhML6AksCPDc.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="多线程服务端"><a href="#多线程服务端" class="headerlink" title="多线程服务端"></a>多线程服务端</h4><p>在 KvServer 初始化时使用了一个线程池来管理不同 tcp 连接的读写，这样便可以使得并发的请求能够在多核 CPU 的服务端并行执行而不是并发执行。</p><p><img src="/naive-kvengine-in-rust/boxcnnVupdcBFwenEaIuUvFhWDh.png" srcset="/img/loading.gif" lazyload alt></p><p>注意在 KvServer 中还维护了一个 is_stop 的原子变量，该变量的作用是能够便于当前线程结束阻塞等待进而退出。之所以阻塞的原因是由于 tcplistener 的 incoming() 函数是阻塞的，因而一旦进入 serve 函数当前线程就阻塞了。在之后的性能测试中可能一个线程内想在启动 server 后开始迭代测试并最后关闭 server 并进行下一轮测试：此时如果是同步的写法就无法执行 serve 之后的函数，如果新建一个线程则无法在迭代测试之后通知该线程结束，因而加入了该原子变量之后不仅可以异步启动 server 从而在当前线程进行性能测试，又能够在当前线程的测试结束后以新建一个空 client 的方式关闭 server 以便下一轮测试不会再出现 address already in use 的错误。</p><p><img src="/naive-kvengine-in-rust/boxcn0lodECLFH3AjTT7CGOFGLg.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="KvsEngine-线程安全"><a href="#KvsEngine-线程安全" class="headerlink" title="KvsEngine  线程安全"></a>KvsEngine  线程安全</h4><p>KvsEngine trait 需要满足 Clone + Send + ‘static 的 bound，同时三个对应的接口也可以去掉 &amp;mut，因为变量的所有权和可变性已经转移到了智能指针中。</p><p><img src="/naive-kvengine-in-rust/boxcnJFwgaF5IXUqkq7iPFqorWd.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="SledKvsEngine-线程安全"><a href="#SledKvsEngine-线程安全" class="headerlink" title="SledKvsEngine 线程安全"></a>SledKvsEngine 线程安全</h4><p>Sled 引擎本身支持并发读写，因而直接对结构体 derive(Clone) 即可，其 set/get/remove 函数仅需挪去 self 的 &amp;mut 即可。</p><p><img src="/naive-kvengine-in-rust/boxcnzGfVRmcZ2kjZyKatOZ9uHb.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnPZjYAEANb7Z9O28Zm5rfIg.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnW993QBlpNeVJ1vocEYpCwe.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="KvStore-线程安全"><a href="#KvStore-线程安全" class="headerlink" title="KvStore 线程安全"></a>KvStore 线程安全</h4><p>KvStore 的线程安全则需要对之前的结构体做大量的改造，改造之后的 KvStore 不仅支持读写请求互相不阻塞，甚至对同一 FileReader 的读请求也可以不在应用层阻塞。</p><ul><li>对于 index 结构，将其转换为了并发安全的 DashMap 结构，同时又增加了 Arc 指针以便于在不同线程间共享。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnaTmdxQINxNh6bgoVnbVpIh.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>对于 writer 结构，由于对同一文件的 append 操作从语义上来说便不支持并行，因而便通过 Arc<Mutex<Writer>&gt; 的方式将所有的线程串行起来</Mutex<Writer></li></ul><p><img src="/naive-kvengine-in-rust/boxcn35QJnz7gVjIWmD7xrNrTCh.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>对于 readers 结构，我参照了部分 project4 样例的源码设计进行了无锁实现。注意其内部的 readers 在 clone 时并不是拷贝指针，而是初始化一个全新的 map，因而当多线程读同一个文件时，会创建多个 reader，这些 reader 可以在应用层对同一个文件执行并发的 IO 读请求。使用 RefCell 包装的原因是由于接口并未提供可变引用，如果还想保留对 map 的更改权限就需要用到 RefCell 了。</li><li>最容易想到的一种读请求并发控制方案是在上层做一定的串行以使得每个文件最多同时只有一个读请求在执行，从而减少磁盘的随机 IO。但实际上这样的设计并不一定有效果，一方面由于在文件系统中一个 file 的所有 data block 不一定完全在连续的 block 上，因而仅仅限制对一个文件不能并发读而不限制对多个文件不能并发读不一定能够起到减少随机 IO 的效果，另一方面 linux VFS 下的 IO 调度层本来就已经会对 IO 请求通过电梯算法等方式来做一些乱序处理来减少随机 IO，如果完全在上层做了串行反而会丢失部分可优化吞吐的空间。因而如果系统还没到完全掌握磁盘快中数据的分布来减少随机 IO 的地步，可以先尽可能的将读请求并行起来让底层去串行，而不是在上层就做好串行。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnlZ4coU7mWqKybLfYC7pqgp.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="写流程-1"><a href="#写流程-1" class="headerlink" title="写流程"></a>写流程</h4><p>由于 append 的写请求语义上就不能并行，因而当前 KvsEngine 的 set 请求被全部串行了起来</p><p><img src="/naive-kvengine-in-rust/boxcnrM7s7ntdUZwS41euVNO2af.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnFBgZG4DdIytqlfeqrlmqxe.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="删除流程-1"><a href="#删除流程-1" class="headerlink" title="删除流程"></a>删除流程</h4><p>由于删除也需要顺序 append，因而其语义与 set 类似不能并行，因而当前 KvsEngine 的 remove 请求也被全部串行了起来</p><p><img src="/naive-kvengine-in-rust/boxcnDij7HnjT3xTO0tBYJBmyEg.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="读流程-1"><a href="#读流程-1" class="headerlink" title="读流程"></a>读流程</h4><p>读流程语义理论上可以并行执行，因而首先在可并发读的 DashMap 中获取到索引，接着在当前线程内读取对应的 file_number 的 reader，如果当前线程不存在该 reader 则创建出对应的 reader 读取即可（使用了 entry API 来避免两次 hash）。</p><p><img src="/naive-kvengine-in-rust/boxcnPQEGztT4pID88lJEVIpTKJ.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnRs4vfkVcwiEJoQLIJpHM7o.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcn9YBWH6fWTEqZroFFEmjfQd.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="合并流程-1"><a href="#合并流程-1" class="headerlink" title="合并流程"></a>合并流程</h4><p>在实现无锁读之后，reader 的清理便不再能够串行起来了，因而需要一个多线程共享的原子变量来记录最新 compaction 之后的 file_number，小于这个 file_number 的文件和对应的 reader 便都可以删除了。</p><p>compact 流程会始终持有 writer 的写锁，因而此时并不存在并发安全问题，其在结束后会尝试删除掉过时的文件。不过该删除并不会影响其他读线程的 reader 句柄继续读去文件，这与 linux 文件系统的实现原理有关，直到任何线程都不存在指向该文件对应 inode 的句柄时便可以安全的释放该文件了。</p><p><img src="/naive-kvengine-in-rust/boxcnj3SztibcQ3dVtk80AgHB5r.png" srcset="/img/loading.gif" lazyload alt></p><p><img src="/naive-kvengine-in-rust/boxcnkFizeIlIHOkdtLdjiJXa1b.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 reader，在 compaction 中其执行的索引尽管可能文件已经被删除了，但由于其持有句柄因而始终能够读到数据，在 compaction 之后其执行的索引一定是更新的文件，因而老的 reader 便不会再被用到，如果这些老 reader 一直不被释放，则可能导致合并过后的老文件始终无法在文件系统被释放，最终导致磁盘变满。因此在每次查询时都可以判断一下该原子变量并尝试删除本线程的老 reader，这样便可以既实现 lock-less 的 reader 又满足 compaction 消息的无锁感知和对应的资源清理了。</p><p><img src="/naive-kvengine-in-rust/boxcnbIWT6ofbomscJjhYDsI3og.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="性能测试-1"><a href="#性能测试-1" class="headerlink" title="性能测试"></a>性能测试</h4><p>按照题意写出对应的六个 benchmark 即可，主要做了以下工作：</p><ul><li>使用 Once 接口来确保在多个函数中 logger 仅被初始化一次，从而避免报错。</li></ul><p><img src="/naive-kvengine-in-rust/boxcn2a3QFIu6KvawbPR6I8lb0d.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>使用了 <a href="https://bheisler.github.io/criterion.rs/book/user_guide/benchmarking_with_inputs.html" target="_blank" rel="noopener">bench_with_input</a> 接口来支持不同线程数的对比</li></ul><p><img src="/naive-kvengine-in-rust/boxcncFWYwfER6WT9yFEYNoIIud.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>使用了之前提到的方式来异步启动 server 并在一轮迭代结束后回收 server。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnjhiY2nLL2YcXE6hcSQvbqg.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>使用了 waitGroup 来实现客户端线程和迭代线程的同步。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnUGMyrZgPdodAwns1WyUrwc.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>减少 sample_size 来加快性能测试时间。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnWKzKDZwn4IZ1VuXbeuicbg.png" srcset="/img/loading.gif" lazyload alt></p><p>最终的测试结果如下：</p><ul><li>write_queue_kvstore：随着线程数增大，延时先降再升，但变化幅度不大，尽管 read/write socket 可以并行起来了，但 set 还是必须得串行起来，与实现基本相符。</li></ul><p><img src="/naive-kvengine-in-rust/boxcnrpuZM9Ienhb4A3R8PGHdAd.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>read_queued_kvstore：随着线程数增大，延时先大幅度降低再大幅度升高，大幅度降低符合预期，因为不同的读请求现在可以串行起来，大幅度升高则不太符合预期，观察到了客户端建立连接 Timeout 的现象，不确定是否与本地的 Mac M1 Pro 环境有关。</li></ul><p><img src="/naive-kvengine-in-rust/boxcn4HmL8lEVkATOr4kedonK3f.png" srcset="/img/loading.gif" lazyload alt></p><p>其他测试：</p><ul><li>write_rayon_kvstore</li></ul><p><img src="/naive-kvengine-in-rust/boxcnqWEQYmfb87Ku1fwAHwutEg.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>read_rayon_kvstore</li></ul><p><img src="/naive-kvengine-in-rust/boxcn31tkUHW2shoqZ4XO6Mx3dR.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>write_rayon_sledkvengine</li></ul><p><img src="/naive-kvengine-in-rust/boxcnAgA1VT5aM02gLqyi9YHJ6d.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>read_rayon_sledkvengine</li></ul><p><img src="/naive-kvengine-in-rust/boxcnoPA82ks3t9N0DQJDlpDcIf.png" srcset="/img/loading.gif" lazyload alt></p><p>测试总结：</p><ul><li>总体来看，不同的存储引擎，不同的线程池策略，随着服务端线程池的线程数增大，延时都能够在某点得到最小值，这说明并行能够在部分场景起到效果。</li><li>在 MacOS M1 Pro 的环境上测试性能不太稳定，还容易出现 timeout 的情况，因而便没有进行更详细分析，感觉要想真的对比出性能的差异，还是需要在 Linux 环境下配上稳定的 CPU，磁盘，网络的可观测性工具结合不同引擎和不同线程池的内部 metric 来分析原因。害，底层软件就是这么难测试。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过本 Rust Lab，总共写了大约 2000+ 行的 Rust 代码。从 Cargo 包管理到 Rust 的所有权机制，然后到错误管理和若干标准库三方库的使用，再到线程池和并发引擎的设计以及异步 Runtime 的学习，虽然在性能测试和对比部分做的并不完善，但这些内容已经涵盖了开发大型 Rust 项目的方方面面。</p><p>下一步计划开始从 TiKV 的小 issue 入手，进一步深入学习 Rust。</p>]]></content>
    
    
    
    <tags>
      
      <tag>存储引擎</tag>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Talent-Plan：用 Rust 实现 Percolator 算法</title>
    <link href="/percolator-in-rust/"/>
    <url>/percolator-in-rust/</url>
    
    <content type="html"><![CDATA[<h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><ul><li><a href="https://github.com/pingcap/talent-plan/tree/master/courses/dss/percolator" target="_blank" rel="noopener">官网版本</a></li></ul><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>Rust 学习</p><ul><li><a href="https://fasterthanli.me/articles/a-half-hour-to-learn-rust" target="_blank" rel="noopener">半小时学习 Rust</a></li><li><a href="https://github.com/rust-lang/rustlings" target="_blank" rel="noopener">Rustling</a> 及 <a href="https://github.com/OneSizeFitsQuorum/rustlings/pull/1" target="_blank" rel="noopener">解答</a></li><li><a href="https://course.rs/about-book.html" target="_blank" rel="noopener">Rust 语言圣经</a> 及 <a href="https://zh.practice.rs/why-exercise.html" target="_blank" rel="noopener">习题</a></li><li><a href="https://kaisery.github.io/trpl-zh-cn/title-page.html" target="_blank" rel="noopener">Rust 官方文档</a></li></ul><p>Percolator 学习</p><ul><li><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://github.com/OneSizeFitsQuorum/tinykv/blob/test/solution/lab4.md" target="_blank" rel="noopener">TinyKV lab4 文档</a></li></ul><h2 id="过关思路"><a href="#过关思路" class="headerlink" title="过关思路"></a>过关思路</h2><p>在基本环境搭建好之后，观察发现 lab 只有 13 个测试，测试全部 AC 即可通过项目。实际上一个生产级别的 Percolator 实现这些测试是远远不够的，需要考虑和测试的 case 很多。</p><p>由于本 lab 的主要目标是帮助学习 Rust，因此本次过关思路便是通过 TDD 的方式通关，将主要精力放在通过测试以及对应 Rust 语法的学习和练习上，对于实现的 Percolator 算法满足论文要求和当前的测试 case 即可，不再去新增更多的 test case 和并发情况。</p><p><img src="/percolator-in-rust/0.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="过关过程"><a href="#过关过程" class="headerlink" title="过关过程"></a>过关过程</h2><h3 id="TSO-测试"><a href="#TSO-测试" class="headerlink" title="TSO 测试"></a>TSO 测试</h3><ul><li>test_get_timestamp_under_unreliable_network</li></ul><p>该测试期望在不稳定网络下 client 的 get_timestamp 接口在超时重试时可以满足 backoff 幂增重试属性。<br><img src="/percolator-in-rust/1.png" srcset="/img/loading.gif" lazyload alt></p><p>因此一方面在 TSO Server 端的 get_timestamp 接口处提供一个空实现，另一方面在 Client 中维护对应初始化时传入的 rpc client 字段并在 get_timestamp 函数中增加幂增 sleep 逻辑即可。<br><img src="/percolator-in-rust/2.png" srcset="/img/loading.gif" lazyload alt></p><p>有关 async 和 await 的原理需要进一步理解学习，但仅就完成本 lab 而言，可以查看 labrpc example 中的使用样例来模仿使用，即使用 await 来驱动 async 的代码块执行，使用 block_on 达到同步执行的效果。<br><img src="/percolator-in-rust/3.png" srcset="/img/loading.gif" lazyload alt></p><p>通过本测试的新增代码可查看 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/commit/2deab4fec9c2c6a925963dd65cd690507cd7f565" target="_blank" rel="noopener">commit</a></p><h3 id="TXN-正常测试"><a href="#TXN-正常测试" class="headerlink" title="TXN 正常测试"></a>TXN 正常测试</h3><ul><li>test_predicate_many_preceders_read_predicates</li><li>test_predicate_many_preceders_write_predicates</li><li>test_lost_update</li><li>test_read_skew_read_only</li><li>test_read_skew_predicate_dependencies</li><li>test_read_skew_write_predicate</li><li>test_write_skew</li><li>test_anti_dependency_cycles</li></ul><p>以上测试要求在网络正常的情况下能够正确实现 Percolator 的事务提交，即可按照论文中的伪码实现即可。</p><h4 id="client"><a href="#client" class="headerlink" title="client"></a>client</h4><p>对于 Client 的 new 函数，保存两个 rpc client 并初始化 start_ts 和 mem_buffer。注意，为了在客户端进行去重，mem_buffer 使用了 hashmap 而不是 Vec。<br><img src="/percolator-in-rust/4.png" srcset="/img/loading.gif" lazyload alt></p><p>对于 Client 的 get_timestamp 函数，参照上一小节实现发 RPC 和对应的重试以及错误处理逻辑即可。</p><p>对于 Client 的 begin 函数，使用 get_timestamp 函数更新本地的 start_ts 即可，start_ts 将作为快照读取的依据。</p><p>对于 Client 的 set 函数，直接缓存到 mem_buffer 中即可。</p><p>对于 Client 的 commit 函数，开始 Percolator 的提交流程，即先 prewrite 再 commit。注意不论是 prewrite 还是 commit 都是先对 primary 进行处理再对 secondary 处理。</p><p><img src="/percolator-in-rust/5.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="proto"><a href="#proto" class="headerlink" title="proto"></a>proto</h4><p>参照论文写出了对应的 proto 文件如下，以下将分别分析四种 RPC 请求：<br><figure class="highlight plain"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs proto">message TimestampRequest &#123;&#125;<br><br>message TimestampResponse &#123;<br>    uint64 timestamp &#x3D; 1;<br>&#125;<br><br>message GetRequest &#123;<br>    bytes key &#x3D; 1;<br>    uint64 start_ts &#x3D; 2;<br>&#125;<br><br>message GetResponse &#123;<br>    bytes value &#x3D; 1;<br>&#125;<br><br>message PrewriteRequest &#123;<br>    uint64 start_ts &#x3D; 1;<br>    bytes primary &#x3D; 2;<br>    bytes key &#x3D; 3;<br>    bytes value &#x3D; 4;<br>&#125;<br><br>message PrewriteResponse &#123;<br>    bool success &#x3D; 1;<br>&#125;<br><br>message CommitRequest &#123;<br>    bool is_primary &#x3D; 1;<br>    uint64 start_ts &#x3D; 2;<br>    uint64 commit_ts &#x3D; 3;<br>    bytes key &#x3D; 4;<br>&#125;<br><br>message CommitResponse &#123;<br>    bool success &#x3D; 1;<br>&#125;<br></code></pre></div></td></tr></table></figure></p><h4 id="get-timestamp"><a href="#get-timestamp" class="headerlink" title="get_timestamp"></a>get_timestamp</h4><p>对于 TSO 请求，此时需要使用一个全局唯一 ID 的递增生成器而不能硬编码成 0 了。最暴力的方法便是采用 wall clock time 来生成，然而在高并发情况下 wall clock time 可能产生重复的 ID，因此一般需要 HLC 结合物理时间戳和逻辑时间戳的方式来保证全局唯一。出于时间原因，我直接采用了逻辑递增 ID 的方式来生成全局唯一的递增 ID。为了性能考虑，我采用了 Arc<AtmoicU64> 而不是 Arc<Mutex<u64>&gt; 来生成 id，这样实现的理论性能会更高，同时由于此处仅仅需要生成 ID 没有其他逻辑，因此 Ordering 采用 Relaxed 即可。<br><img src="/percolator-in-rust/6.png" srcset="/img/loading.gif" lazyload alt></Mutex<u64></AtmoicU64></p><h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p>对于 Get 请求，需要携带 key 和对应的 start_ts 来针对某一全局快照读取。因此客户端构建好 request 后向服务端发送即可，注意此时依然实现了超时重试的逻辑。<br><img src="/percolator-in-rust/7.png" srcset="/img/loading.gif" lazyload alt></p><p>在服务端的 RPC handler 里，首先使用 lock 进入临界区，接着判断 lock 列中是否存在与本事务冲突的其他事务，如果存在则 backoff 等待并在稍后重试。接着查找 write 列中该 key 最接近当前事务 start_ts 的 commit_ts，如果不存在则返回空字符串，否则获取到其 start_ts 将其从 data 列读出来即可。<br><img src="/percolator-in-rust/8.png" srcset="/img/loading.gif" lazyload alt></p><p>在 KVTable 的 read 函数中，使用 BTreeMap 的 range 接口和 last 接口来获取某个区间的最大值，如果不存在则返回 None。<br><img src="/percolator-in-rust/9.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="prewrite"><a href="#prewrite" class="headerlink" title="prewrite"></a>prewrite</h4><p>对于 PreWrite 请求，需要携带 start_ts，primary 和对应的 KV 对来进行写入。客户端添加了对应的重试和错误处理逻辑，并将参数发送给服务端。<br><img src="/percolator-in-rust/10.png" srcset="/img/loading.gif" lazyload alt></p><p>在服务端，首先使用 lock 进入临界区，接着判断 lock 列和 Write 列中是否存在与本事务冲突的其他事务，如果存在则返回错误，此时只能事务执行失败让应用层重试。如果没有冲突的事务，则可以向 data 列写入暂时不可见的数据，接着向 lock 列写入锁来保证不会出现 lost update。<br><img src="/percolator-in-rust/11.png" srcset="/img/loading.gif" lazyload alt></p><p>在 KVTable 的 write 函数中，使用 BTreeMap 的 insert 接口来新增对应的 entry。<br><img src="/percolator-in-rust/12.png" srcset="/img/loading.gif" lazyload alt></p><p>需要注意的是，该 Lab 中并未引入分片的概念，因此可以认为所有的数据均在一个分片，因此理论上可以直接使用 1PC 的方式将请求直接在服务端进行 PreWrite &amp; Commit 处理。本人也进行了 1PC 的实现，在实现完后发现存在一个测试并不希望按照 1PC 去处理，因而便采用了效率最低但和论文伪码以及测试能够对应的方式，每个 key 都会发一次 rpc 且 prewrite 和 commit 会发两轮 rpc。</p><h4 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h4><p>对于 Commit 请求，需要携带 start_ts, commit_ts，是否为 primary 以及对应要 commit 的 key。客户端添加了对应的重试和错误处理逻辑，并将参数发送给服务端。<br><img src="/percolator-in-rust/13.png" srcset="/img/loading.gif" lazyload alt></p><p>在服务端，首先使用 lock 进入临界区，接着判断 lock 列是否存在自己的锁，如果不存在则说明发生了不符合预期的错误（比如此次 RPC 延期到达，或者本事务已经被其他事务 abort 且清理），此时只能返回失败让应用层处理。如果自己的锁存在，则可以向 write 列写入 ((key, commit_ts), start_ts) 以让 data 列的数据可见，接着移除掉 lock 列写入的锁即可。<br><img src="/percolator-in-rust/14.png" srcset="/img/loading.gif" lazyload alt></p><p>在 KVTable 的 erase 函数中，使用 BTreeMap 的 remove 接口来移除对应的 entry。<br><img src="/percolator-in-rust/15.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h4><p>以上逻辑通过了事务正常提交时的测试，然而网络异常或者协调者异常时的测试还未完全 AC，因此还需要进一步处理。<br><img src="/percolator-in-rust/16.png" srcset="/img/loading.gif" lazyload alt></p><p>通过本测试的新增代码可查看 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/commit/5ca761e06f7eefe5da901ca2e37c7c3fb7c2a3b7" target="_blank" rel="noopener">commit</a></p><h3 id="TXN-异常测试"><a href="#TXN-异常测试" class="headerlink" title="TXN 异常测试"></a>TXN 异常测试</h3><ul><li>test_commit_primary_drop_secondary_requests</li><li>test_commit_primary_success</li><li>test_commit_primary_success_without_response</li><li>test_commit_primary_fail</li></ul><p>异常测试会模拟 commit 请求的 req/resp 被丢弃的场景，但是 primary 的 commit 会始终被满足，因而 secondary 的请求有可能会被丢弃。</p><p>在客户端侧，首先需要针对 test_commit_primary_fail 和 test_commit_primary_success_without_response 返回的错误进行特判处理，同样是发 rpc 出错，但他们一个要求 client 返回 Err(Error::Other(“resphook”.to_owned()))，另一个要求返回 Ok(False)。尽管并不统一，但可以通过修改特判 Err 类型的方式来通过测试<br><img src="/percolator-in-rust/17.png" srcset="/img/loading.gif" lazyload alt></p><p>在服务端侧，异常测试主要实现的函数便是 back_off_maybe_clean_up_lock，即当遇到其他事务遗留下来的 prewrite 结果时要如何处理。</p><p>对于 percolator 这种事务模型，primary key 的提交与否便是整个事务提交与否的标志。任何事务在读某一 key 时，如果遇到遗留的 Lock 列锁，在 sleep 超过 TTL 时间后，可以接着获取该冲突 key1 在 lock 列  key 中的 start_ts 和 value 中存的 primary 值。然后再去 Write 列中寻找 (primarykey，0) 和 (primarykey， u64::MAX) 范围内是否有指向 start_ts 的记录。如果存在，则说明该事务已经提交且能够获取到 commit_ts，此时对该 key1 做 commit 处理即可，即清理 Lock 列并在 Write 列添加对应的记录。如果不存在，则说明该事务尚未提交，且其他任何 rpc 再执行的时候都能够确定性的判断出该事务并未提交（即便是乱序到达的 primary  commit rpc，其也会检测 lock 记录是否存在，只有存在时才能 commit），此时只需要将当前 key1 的遗留 lock 清理即可。尽管也可以顺便检测清理其他的遗留 key，但让其他的遗留 key 在需要清理时再进行清理也不影响 safety，因而只用清理 key1 即可。在 key1 清理完之后，当前事务便可以正常读取 key 的值了。</p><p>代码如下，需要注意在进入 back_off_maybe_clean_up_lock 函数前需要 drop 掉锁，back_off_maybe_clean_up_lock 函数在 sleep 完之后需要先拿到锁再进行操作。<br><img src="/percolator-in-rust/18.png" srcset="/img/loading.gif" lazyload alt></p><p>contains_in_write_column 函数遍历 write 列寻找 (primarykey，0) 和 (primarykey， u64::MAX) 范围内是否有指向 start_ts 的记录，如果存在则返回 commit_ts，否则返回 None。<br><img src="/percolator-in-rust/19.png" srcset="/img/loading.gif" lazyload alt></p><p>此外 kvtable 中的 erase 函数的参数之前是 commit_ts，但由于在 lock 列中记录的是 start_ts，不论是正常 commit 还是 rollback 均需要按照 (key, start_ts) 去清理而不是 (key, commit_ts)，因而感觉这里应该是论文中的笔误被照抄过来了，在此处从 commit_ts 改为了 start_ts。<br><img src="/percolator-in-rust/20.png" srcset="/img/loading.gif" lazyload alt></p><p>通过本测试的新增代码可查看 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/commit/8a62c5bc6096408433bfb0e0b6e04d9040b4082a" target="_blank" rel="noopener">commit</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最终所有测试通过如下，本人过关代码可参考该 <a href="https://github.com/OneSizeFitsQuorum/talent-plan/pull/1" target="_blank" rel="noopener">PR</a>。<br><img src="/percolator-in-rust/21.png" srcset="/img/loading.gif" lazyload alt></p><p>通过本 lab，对 Rust 编程的若干关键工具和重要知识点有了一定的实践，包括但不限于 cargo 管理，模式匹配，流程控制，错误处理，所有权与借用，迭代器，宏编程等等。希望未来能够深入理解 rust 的异步编程，成为一名有经验的 Rustacean。</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式事务概述和对应代码框架介绍</title>
    <link href="/talent-plan-transaction-talk/"/>
    <url>/talent-plan-transaction-talk/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>分享一下前两天在 <a href="https://tidb.net/talent-plan" target="_blank" rel="noopener">Talent Plan Community</a> 做的有关分布式事务和 Distributed-Txn 代码框架的介绍。</p><p>这次分享除了对 2021 VLDB summer school 中讲授的若干重要主题进行了概述，还着重介绍了事件排序这一很本质的问题，此外也参考了不少优质资料，现在 share 出来希望能对这块知识感兴趣的同学有帮助。由于本人水平有限，如有原理错误欢迎与我沟通~</p><p>注：以下仅为图片，可以在 <a href="https://pingcap.feishu.cn/drive/folder/fldcn9zPuLSTqoL2JDQOT5jbpQd" target="_blank" rel="noopener">此处</a> 在线浏览 PPT 原件和录屏。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p><img src="/talent-plan-transaction-talk/1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/2.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/3.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/4.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/5.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/6.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/7.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/8.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/9.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/10.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/11.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/12.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/13.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/14.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/15.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/16.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/17.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/18.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/19.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/20.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/21.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/22.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/23.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/24.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/25.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/26.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/27.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/28.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/29.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/30.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/31.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-transaction-talk/32.png" srcset="/img/loading.gif" lazyload alt></p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Raft 算法和对应代码框架介绍</title>
    <link href="/talent-plan-raft-talk/"/>
    <url>/talent-plan-raft-talk/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>分享一下前不久在 <a href="https://tidb.net/talent-plan" target="_blank" rel="noopener">Talent Plan Community</a> 做的有关 Raft 算法和 Etcd/TinyKV 代码框架的介绍。</p><p>这次分享对 Raft 算法和对应实现做了较为系统的调研整理，不仅对若干经典问题做了介绍，也提供了不少优质参考资料，现在 share 出来希望能对这块知识感兴趣的同学有帮助。</p><p>注：以下仅为图片，可以在 <a href="https://vevotse3pn.feishu.cn/file/boxcn6tQX2I5QxyLM4ZGGVu2wmd" target="_blank" rel="noopener">此处</a> 在线浏览 PPT 原件。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p><img src="/talent-plan-raft-talk/1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/2.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/3.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/4.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/5.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/6.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/7.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/8.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/9.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/10.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/11.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/12.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/13.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/14.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/15.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/16.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/17.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/18.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/19.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/20.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/21.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/22.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/23.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/24.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/25.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/26.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/27.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/28.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/29.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/30.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/31.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/32.png" srcset="/img/loading.gif" lazyload alt><br><img src="/talent-plan-raft-talk/33.png" srcset="/img/loading.gif" lazyload alt></p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021 年终总结：记我在清华 Apache IoTDB 组的成长</title>
    <link href="/2021-annual-summary/"/>
    <url>/2021-annual-summary/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2021 年即将结束，这一年忙忙碌碌收获许多，也认识到了定期总结定期反省的重要性。今年回家后意识到自己应该养成写年终总结的习惯了，于是断断续续用近一周的时间写了第一次年终总结，算给自己的一整年一个交代。希望我的经历和感悟能给大家一些启发。</p><p>首先进行一个简单的自我介绍，我叫谭新宇，清华本硕，现在清华大学软件学院 Apache IoTDB 组就读研二，师从王建民/黄向东老师，我对分布式系统，时序数据库和共识算法较感兴趣。</p><p>接着简单介绍一下我们组的工作：Apache IoTDB（物联网数据库）是一体化收集、存储、管理与分析物联网时序数据的软件系统。 Apache IoTDB 采用轻量式架构，具有高性能和丰富的功能，并与 Apache Hadoop、Spark 和 Flink 等进行了深度集成，可以满足工业物联网领域的海量数据存储、高速数据读取和复杂数据分析需求。截止 2021 年底，Apache IoTDB 是国内高校唯一在 Apache TLP 中的开源软件，目前已经被建设成了百余贡献者的开源社区。</p><h2 id="本科经历"><a href="#本科经历" class="headerlink" title="本科经历"></a>本科经历</h2><p>既然是第一次年终总结，在此简单提提自己的本科经历。</p><p>2016 年，高考完填清华志愿的我并不知道自己的专业兴趣是什么，也并不知道不同的专业有什么区别，于是随便报了个机械大类便入学了。</p><p>在大一下的时候，一方面是成绩尚可（前 10%），另一方面是大一下接触编程课的印象还不错。对游戏一直很感兴趣的我便萌生了转专业的想法，最终也顺利的平转到了对编程萌新相对友好的软件学院。</p><p>在大二刚转过来的时候，我感受到的课程压力是非常大的，当然主要原因还是自己的编程基础太差。因为大学之前从未接触过编程，而且大一只学了一门针对机械学院同学开的比较水的编程课，所以大二学数据结构操作系统的时候非常吃力。幸运的是，软件学院的大佬同学们（教主，杰神，方舟，冯老板，伟哥等等）和辅导员们（岳导，李导）帮助了我很多，再结合自己的努力，我的成绩也慢慢能够跟上来了。</p><p>在大三的时候，得益于学院这个大平台和自己的努力，我分别在旷视和微软进行了短期实习。在旷视，我主要在 Data 组打杂，也是在这个时候开始了解分布式系统领域，学习了 Google 的三篇马车（GFS/MapReduce/BigTable）和 Facebook 的小文件冷热存储解决方案（HayStack/F4）并逐渐对这个领域产生了浓厚的兴趣。此外，我在旷视的 mentor 庄大师（外号纯纯）也给我留下了非常深刻的印象，现在他已经是成功人士了（手动狗头）。在微软，我们跟着邹欣老师（现在已经跳槽到 CSDN 当副总裁了）组队完成了一个 NLP 领域的 CodeSearch 项目，主要功能是实现一个 VSCode 插件，能够输入自然语言输出对应的代码，这个工作还拿到微软内部 Hackathon 比赛的奖。不过我的任务主要是爬虫数据清理之类的工作，一方面是自己对 AI 不是很感兴趣，另一方面也是自己炼丹的能力不足。这段经历到现在留给我的印象就是微软内部和谐友好的氛围了，是真的很 WLB 啊。</p><p>到了大四做保研还是工作的决定时，有很厉害的学长劝我早点到工业界，说很多研究生的工作都是在虚度年华，贵清也不例外。我的父母则是坚持要求我接着读书。在平衡各方面利弊后，我最终决定继续读个硕士，给自己一些缓冲的时间，并希望能够找到一个不虚度年华的实验室。</p><p>最开始我找到了李振华老师的实验室，主要原因是振华老师在上本科课程《网络系统》时实在是太过于风趣幽默，吸引了一大批小学弟。在振华组里最开始我是希望能够做一段有意义的科研的，然而呆了半年后我逐渐感觉到，我所感兴趣的分布式系统方面振华老师做的工作不多，我自己也很难独立的搞出一份科研工作出来。此外，振华老师喜欢的学生特质是英文写作能力强，基础扎实，对计算机网络/操作系统感兴趣，而当时的我与这三个特质都不太搭边，因此我的离开便不是很意外了。不过 u1s1，振华老师写论文的功底真的非常强，MobiCom，NSDI 年年发，21 年他们组还中了软院第一篇 SIGCOMM，可谓是风光无限了。尽管会比较 push，但好歹 push 的结果对大家都好，满足上述三个特征的同学也可以去跟振华老师联系。</p><p>当时，我和同在振华组里的苏总相约好了一起润，我们几乎打听了学院的所有实验室，在过滤掉不感兴趣的搞前后端和 AI 的实验室后，我们最后面临了两个选择，一个是散养的实验室，去了之后可以在企业自由的实习三年。一个是学院里在做的时序数据库 Apache IoTDB（当时还是孵化器项目），尽管去了之后会比较忙，但由于主力是学生，相比在外实习可能能得到更多的锻炼，而且硕士期间也能够拥有三年的数据库内核开发经验，对找工作比较友好。最终经过深思熟虑，我们相约一起润去了 Apache IoTDB 实验室。</p><p>进组后，我当时给自己的目标便是利用研究生三年时间提升自己的理论知识水平和工程能力。因而我一进去就开始了解开源，学习数据库知识并加入了分布式模块进行实践。做了不到一年，2020 年底我便被社区接纳为了 committer，这里也很感谢组里分布式模块的实力大哥江天学长的举荐。</p><p>如果让我在 2020 年底反思读研是否值得，我可能还很难给出明确的答案。但如果让我现在反思读研是否值得的话，我的答案一定是值得。这与我进实验室后的经历有关，我不确定当时直接工作的话在企业是否也能得到这样的成长，但至少 2021 年在实验室的成长已经让我觉得读研不虚此行了。其实仅仅深度参与一个开源基础软件从雏形不断发展壮大再到可能的商业化，感受项目管理，产品功能，人员心态，宣传运营，社区交流等方面的进化就已经是非常难得的一段经历了，更不要谈在这期间借助这个平台我们自己的成长了。</p><p>当然，读研到底是不是正收益。家庭情况，实验室情况，个人兴趣，时代发展，专业方向，人脉关系这些都是影响很大的因素，不可一概而论。</p><h2 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h2><p>讲完了之前的经历，在这里谈谈 2021 年的经历。如果要给 2021 年的自己一个关键字的话，我觉得应该是<strong>成长</strong>。</p><p>卷了一整个本科的我在研究生选课时遵循了兴趣导向的原则。即对于自己不感兴趣的课水水即可，对于自己感兴趣的课付出大量精力。前半年，我了解到了贵系陈康老师的《分布式导论》课程，这门课基本 Follow 了 MIT 6.824 的课纲，大作业也是完成 6.824 的 lab。尽管听起来就很硬核，但我毅然决然的选了它。在上这门课的时候，我一方面同步听了线下陈康老师和线上 MIT Robert Morris 老师的课程，另一方面花费了大量的精力去完成大作业，尽管大作业不要求完成 challenge 的内容，但我还是完成了 lab1-4 和 challenge 1-2 的全部内容，最终我如愿以偿的拿到了 A+ 的成绩，这门课也成为了我在贵清收获最大的课。现在想想，这一门课上下来，我阅读了近 20 篇经典论文，学习了很多分布式经典理论，包括各种一致性级别，CAP，BASE，FLP，共识算法，偏序/全序关系，若干系统架构等等，基本重铸了分布式系统的知识体系。此外，我也将我的大作业文档在 Github 上进行了开源，短短半年已经收获近 300 个 star，新增 160+ follower。而且我在知乎上也给自己的文档打了广告，半年收获了 13 万+ 阅读，500+ 赞，1200+ 收藏，成为了”如何的才能更好地学习 MIT6.824 分布式系统课程？”排名第三的答案（第一是 PingCAP 的黄东旭老师）。通过这些关注，我在这半年里也认识了很多志同道合的朋友，这是一生的财富。</p><p>7 月，刷完 6.824 收获很大的我又开始关注另一门课 CMU 15-445，想要就此机会认真学习一下数据库理论。用时一个多月，我利用晚上和周末的时间学习完了 15-445 的线上课程并被 Andy 老师的个人魅力深深吸引。无论是上课时的 DJ drop table，还是 Andy 老师对数据库知识的热情都让我印象深刻。通过这门课程，我基本了解了如何实现一个支持 ACID 的单机关系型数据库。略感遗憾的是，其大作业 bustub 的 codebase 是 C++，我一方面对 C++ 没有技术积累，另一方面也对自己的代码有一定的洁癖，如果我不足够了解 C++ 的话，我也不想写出一堆很丑陋的 lab 代码出来。主要是基于这个原因，我放弃了刷 bustub，换为 MIT 6.830 数据库课程的 lab （codebase 是 Java）刷了刷，但后来刷到 lab2 便由于时间原因被搁置了，之后有机会的话希望能重捡起来。</p><p>8 月，经过一年多的开发，我们终于迎来了 Apache IoTDB 分布式版本的第一个线上用户，针对于 20TB 每天的入库流量，我们用 3 节点的分布式 IoTDB 集群替代了 20 节点的 HBase 集群， 经过初步统计，预约未来 5 年能为企业节省上百万的硬件成本。尽管在上线前的内测期间我们遇到了不少问题，但我们顶住了压力并都进行了修复，最终也顺利上线。通过这次经历，我不仅进一步认可了自己在做的工作，也理解了能为用户创造实际价值才是项目存亡的关键。</p><p>8 月底，对 TiDB 架构一直感兴趣的我发现 PingCAP 提供了免费的 PCTA （TiDB 系统管理基础能力认证）考试机会，于是看了看文档考了一个 PCTA 证书玩玩。</p><p>在暑假，我参加了中科院组织的开源之夏活动，题目为 《Apache IoTDB 分布式混沌测试框架》。这份工作基于阿里的 ChaosBlade 搭建了一个混沌测试平台并对 Apache IoTDB 进行了若干种异常 case 的混沌测试。通过测试，我们发现了 Apache IoTDB 当前分布式版本在异常环境下存在的一些问题，有一些容易解决的问题已经得到了修复，然而也有一些较复杂的问题到今天依然存在，这也多多少少间接引起了我们的一次大规模重构，勉强算是一件有意义的工作吧。令人略感遗憾的是，尽管该混沌测试框架在部署好之后可以用 Dashboard 的方式方便地注入特定的异常，然而该框架依然是基于物理节点来实现的，很难做到自动化。如果没有测试人员去维护并定期手动测试，如果没有开发人员愿意抽出时间来完全解决其中发现的问题，如果整个团队没有足够重视异常场景下系统的对外表现并愿意为之付出大量的精力，该框架就很难形成正向反馈，最终只能被遗忘在历史的角落里。作为一点反省，我现在觉得混沌测试还是应该尽可能的通过持续集成的方式自动化起来（参照 ChaosMesh），这样释放人力的方式是大家都喜爱的，也只有这样，混沌测试才能对项目产生持续的正向收益。</p><p>9 月，打算硕士开题的我阅读了 Raft 相关的近 20 篇论文，感觉近几年与 Raft 相关的论文主要还是在区块链，新硬件和一些特定场景的优化上，没有太多本质的变化。</p><p>10 月，抱着学习的心态，我和家贝一唱报名参加了第一届九坤并行程序优化大赛，这个比赛主要考验选手最大化压榨 CPU 和 IO 性能的能力。由于赛题是 C/C++ 的 codebase，然而我们基本都对 C/C++ 不太熟悉，于是我们起名叫做了”只会 JAVA 队”。作为三个在体系结构几乎一窍不通的小白，在一个多月断断续续的不到 10 次线下沟通中，我们逐渐对体系结构入了门，在 192 个队伍脱颖而出，并在决赛取得了第 4 名的成绩（离苹果周边只差一步）。个人认为，数据库做到极致就是硬件性能的一种体现。因此，一个优秀的数据库工程师应该对体系结构具有一定的了解，这样才有可能进一步压榨硬件性能，从而达到更好的数据库性能。一直以来，我希望分布式数据库能够成为自己的一个标签。通过这次比赛，我意识到高性能计算也是一个很有趣且硬核的方向，其不仅能够给企业迅速带来真金白银的收益（节约成本），而且也是很多领域做到极致的一种出路。</p><p>11 月，PingCAP 举办了第一届 Talent Plan KV 学习营。我和汉乙组队参与了这次比赛，由于我们俩之前都刷过 MIT 6.824，已经对教学级别的 raft 有一定的了解，所以参加此次比赛的目的就是去感受一下生产级别分布式 KV 的代码实现，学习实践一下 lsm, etcd, raftstore 和 percolator 的理论知识和 codebase。u1s1，刷 lab 的过程十分曲折，我们俩所在的实验室到年底的时候都非常忙，前几周基本每周都只能抽出顶多一两天的时间来写代码，而理解 lab2b/lab3b raftstore 的难度是非常大的，我们用了一周多的时间才勉强看懂 raftstore 的代码。这使得到还剩两周时间的时候，我们才刷到 lab2c。最后两周我们利用中午午休时间和晚上睡觉时间疯狂加班，在 lab 上花了更多的时间，最后才堪堪刷完。出人意料的是，我们得了第二名的好成绩。事后反省一下，在 safety 上我们遇到的问题都解决了；在 liveness 上我们没投入太多精力；在文档上，我们简单介绍了代码实现，但将重点放在了我们对相关知识的理解和思考上；在性能上，我们重点做了最容易做的 batching 优化，其本质上是使用 raft 的优化而不是 raft 自身的优化，但对性能的提升却异常关键，比如 tidb 对于一个事务打包的一堆写请求，到 tikv 的 region 之后，这些写请求同步成一条还是多条 raftlog 对于性能的影响是巨大的。</p><p>年底，我和祥威思屹其骏受到实验室的支持，前去参加了海口的 2021 VLDB summer school，今年的 topic 是分布式事务。于向遥，吴英骏和魏星达老师清晰地介绍了分布式事务的方方面面，李飞飞和黄东旭老师则是分享了很多工业界的思考。虽然 KeyNote 请了 Andy 过来我也很喜欢 Andy 老师，但 u1s1 topic 和分布式事务不搭边，感觉基本是 Andy 老师在狂荡不羁的给 ottertune 打广告哈哈哈。这次 VLDB 第一次采用了理论 + 实践 + 随机组队的方式，我们除了每天早上要去感受学术界的熏陶外，下午还会去学习 PingCAP 工程师有关实践 lab 的 talk。我们的 lab 要实现 tinykv + tinysql 中有关分布式事务的所有部分。由于我之前已经了解过 tinykv 的 codebase，所以我的 lab 完成的很顺利，我也尽我所能在下午的实践课程中帮助了很多不了解 codebase 的其他组同学，这也使得我最终拿到了积极参与奖的荣誉。此外我们组由于做了 3 份独立的作业而且最后汇报的表现也还不错，最终成为了排名第一的组，我也幸运的拿到了优秀学员的荣誉并领了一堆 PingCAP 周边。当然对于我来说收获最大的还是跟大佬们的交流。我有幸代表学员跟周傲英老师简单分享了这次 VLDB summer school 的学习方式。我也在吴英骏老师课后跟其请教了应该怎么看待 serializable 和 linearizable，实际上前者是在说事务之间的隔离性，并不需要具备满足时序的偏序关系，而后者是在说单个对象读写操作间的可见性，需要严格满足时序的偏序关系。如果将事务看成单个对象来理解，事务之间又有隔离性又能够满足时序的偏序关系，则就可以被称为 strict serializable（也被 Google Spanner 称为 external consistency）。黄东旭老师在 KeyNote 上很直白的分享了很多工业界分布式事务的真实挑战，比如超大事务（100GB+），Online DDL （有 Google F1 Online DDL 可能还不够）等，在课下交流时，东旭老师则觉得将复制和共识解耦很可能是一件有意义的工作。我们是不是一直以来用错了共识算法？即共识只应该是共识索引而不是共识数据，比如对于 100GB 的数据，是不是在架构上将其写到一个共享存储/内存池上，然后将轻量的索引共识即可。此外我还跟 PingCAP 的童牧老哥请教了不少问题，主要问题集中在 SEDA 模型和 TPC 模型的优劣上。TiKV 利用 rust 在应用态做了非公平业务感知的 CPU scheduler，使得大数据的聚合查询和小数据量的单点查询在高并发时后者的延时依然稳定，感觉是非常有意义的工作。除了技术方面的交流外，王岩广老师介绍的 Talent Plan 社区也让我印象深刻。就我所看到的情况而言，PingCAP 在国产数据库人才培养方面付出了大量的努力并且成果斐然，在这里真诚感谢一下 PingCAP 社区。</p><p>除了参加一些活动学习一些课程，这一年我在 Apache IoTDB 社区 Review 了近 140 个 PR，提交并被合并了 47 个 PR，但大多都是一些维护性重构性的工作。说来也惭愧，进组一年了直到今年后半年我才开始认真研究时序数据库并逐渐意识到了它的挑战。最后一个季度，我和思屹调研了若干个国产时序数据库的分布式架构并进行了多次分享，从中发现了许多优点和大家依然没有解决的痛点。这些优点和痛点的解决方案我们已经进行了大量的讨论和分析，这期间东哥，乔老师，田原学长，金锐学长，江天学长，荣钊学弟，洪胤学弟等也都结合一些论文和自己的思考提出了不少很有特点的想法。这些工作目前正在被逐步吸收进 Apache IoTDB 的分布式版本里面去。尽管短期内还没有成效，但我对 2022 年充满信心。</p><p>后半年，我们实验室引入了在管理方面很有经验的刘海老师，对我们实验室的管理模式进行了一系列改造，包括但不限于分组管理和汇报，利用 sprint 管理进度，利用 confluence 管理文档，目标驱动等等。整个实验室的管理模式发生了翻天覆地的变化，我也有幸成为了一个 3 人小组的小组长，负责分布式模块的维护和推进工作。实际上我们实验室由于一直在搞开源基础软件，所以学生的工程能力一般都还不错。今年引入成熟的管理模式之后，每个人都感受到了管理的力量，也能够在毕业之前提前学习到一些有关管理的知识。长远来看，这对于学生的成长是非常有帮助的。在企业里，调动积极性还可以通过期权，职级等手段来实现。在学校里，调动积极性就只能靠个人魅力和让大家都得到成长的能力了。在我个人看来，这是更富有挑战的。</p><p>之前我觉得在实验室里追求个人的发展和完成组里的工作一定程度上是冲突的，我也就此事跟刘海老师沟通过。渐渐的，我意识到这两者并不一定冲突，它反而促进了我对于高效率的追求。今年我参加的课外比赛和线上学习的课程基本都是利用晚上和周末的时间完成的，并没有影响实验室的工作，在上午和下午的工作时间我依然会专心的进行实验室的工作。由于时间紧张，我会更加专注于手头上的工作，减少摸鱼时间，并不断反思总结如何更高效的工作和交流。从结果来看，思路的转变使我在相同的时间内得到了更多的成长。当然，代价就是牺牲了一些休息时间。</p><p>今年我写了大约 25 篇技术博客，开始阶段性地记录自己的学习过程，字数合计在十万以上。我觉得分享的本质是让大家变得更好，所以我会尽可能的写一些技术总结或者思想感悟，希望读者看了后有所收获。通过博客，我也认识了不少新朋友，希望自己之后能继续坚持下去。</p><p>今年我抽了一些休息时间断断续续看了一些比较感兴趣的电视剧《朱元璋》，《走向共和》和《天道》，也阅读了《邓小平时代》，《原则》和《人生的智慧》等书籍。尽管感悟不少，但它们的主题都比较深沉，我也常常会陷入悲观历史主义中去。我特别感谢我的女朋友小杨同学能够纠正我一些过于悲观的思想，能够让我始终燃着对生活的热爱。如果自己能多抽出一些时间陪陪她就好了。</p><p>当然，以上都是有好结果的经历，今年我也有很多失败的经历，包括但不限于没刷完 6.830 lab，没好好参加 OceanBase 数据库比赛，没去成字节跳动暑期夏令营，没有坚持刷 leetcode，没有完全解决对 IoTDB 进行混沌测试后发现的问题等等。</p><p>除了自己的成长外，这一年 Apache IoTDB 也在我们团队的努力下成长了很多，不论从功能还是性能上都有了很大的提升。当然最重要的还是社区的良性成长：从 2020 年的 396 人增长到 1532 人，国内社群用户数量较 2020 年增长超 287 % ！目前已经有 162 位贡献者为 IoTDB 主仓库贡献了代码，从 2020 年的 94 增长到 162，相比 2020 年初增长了近 70 人！目前已经有多家公司深度参与到 IoTDB 的开发中，如东方国信、阿里、云智慧、360、用友、华为、中冶赛迪等等。学生群体方面，去年一年新增了来自清华、北大、北航、西北工业大学、复旦大学、南京大学、厦门大学、威斯康星大学、新加坡国立大学等国内外高校学生的身影，更有同学选择 IoTDB 作为他们的毕业设计方向。在 IoTDB，我们不仅在个人能力上得到了锻炼，也通过社区认识了很多很厉害很友善的新朋友。</p><h2 id="一些感悟"><a href="#一些感悟" class="headerlink" title="一些感悟"></a>一些感悟</h2><p>谈完了这么多经历，也想谈谈自己的感悟，这些感悟不一定适用于每个人，但都是我个人在今年得到成长的诀窍，一年前的我要是能明白这些道理也许就能少踩很多坑了。</p><h3 id="从要我干什么到我能干什么"><a href="#从要我干什么到我能干什么" class="headerlink" title="从要我干什么到我能干什么"></a>从要我干什么到我能干什么</h3><p>今年感觉自己认知转变最大的一点就是从”要我干什么”过渡到了”我能干什么”。认知的变化彻底改变了我思考问题的方式。</p><p>我不再荒废太多时间在娱乐上，而是思考自己当前能做什么有意义的事情。我不再将一些工作视为是锅，而是将其视为成长的机会。我不再低头闷声学习，而是开始热衷于交流，反思，请教和提问。我不再认为自己当前仅仅专注技术就够了，而是开始学习一些有关管理，表达，领导力的技巧。</p><p>读研三年，仅仅拿个学位在我看来还是有些虚度年华的。在未来我希望自己能够继续跳出自己的舒适圈，继续折腾和挑战自己。</p><h3 id="人与人最大的区别是认知"><a href="#人与人最大的区别是认知" class="headerlink" title="人与人最大的区别是认知"></a>人与人最大的区别是认知</h3><p>这个感悟也是今年体会特别深的一点。人与人最大的区别不是出身，不是社会地位，而是认知。同样的一件事，认知不同的人会有不同的看法，有的人视之为机会，有的人视之为灾祸，最后当然会有不同的结果。</p><p>今年有幸跟很多大佬都请教过，他们对这个世界和行业的认知都让我印象深刻。我的大导师清华大学软件学院院长王建民教授就常会来我们组跟我们讲一些做研究做工程的方法论。在这样的熏陶下，我们组同学们对行业的认知也在不断的提高。</p><p>就我个人的想法而言，多跟大佬们请教，怀着开放的心态去学习，把批评当做进步的机会就是提升自己认知的绝好方式。</p><h3 id="找准自己的兴趣点并持之以恒的专注"><a href="#找准自己的兴趣点并持之以恒的专注" class="headerlink" title="找准自己的兴趣点并持之以恒的专注"></a>找准自己的兴趣点并持之以恒的专注</h3><p>今年的 VLDB summer school 有一个数据库人才培养论坛，交流的大牛有北大的崔斌老师，人大的陈红老师，浙大的陈刚老师，华东师大的钱卫宁老师，阿里的李飞飞老师和 PingCAP 的黄东旭老师，期间有这样一个问题”作为新一代的数据库人，现在应该怎么做才有可能在未来成为一个在数据库界有影响力的人？”。各位老师都分享了自己的看法，包括但不限于努力，专注，思考，交流等等，但所有老师均认为保持长期专注是很重要的一个特性：只有长期的专注才有可能做到顶尖，这一点上没有捷径。</p><p>这个回答也引起了我强烈的共鸣，不论是在学术界还是在工业界，很重要的一点就是找准自己的兴趣点。一定要找到一个自己感兴趣的方向，通俗点来说，就是找到那种自己在休息时间也愿意去学习去钻研的兴趣点。这样，我们不仅在工作学习时更有热情，而且自己的价值也会随着长期地专注而得到不断增长。</p><h3 id="拒绝无效内卷"><a href="#拒绝无效内卷" class="headerlink" title="拒绝无效内卷"></a>拒绝无效内卷</h3><p>尽管长期地专注很重要，但无效内卷是不可取的。从长远来看，无效内卷会影响我们的工作热情并破坏团队氛围，最终一定是得不偿失的。不同人对”无效内卷”的评判标准不同，但我觉得每个人都应该有意识的去反思自己到底是不是在无效内卷。如果是，那一定要想到缓解甚至拒绝它的方法，包括但不限于和 leader one-one，润等。世界这么大，要相信自己一定能够找到立足之地，没必要恶心自己。</p><p>这两天有一个比较火的新闻是腾讯企业微信的应届生怒怼领导恶意内卷。说实话看新闻看得我热血沸腾，我也很佩服这位老哥，要是我自己可能就默默润了，然而他却敢于发声，这是非常难能可贵的。祝愿他未来一切顺利。</p><h3 id="脑袋决定屁股，屁股驱动行为"><a href="#脑袋决定屁股，屁股驱动行为" class="headerlink" title="脑袋决定屁股，屁股驱动行为"></a>脑袋决定屁股，屁股驱动行为</h3><p>在其位谋其职，任何组织都有光明的一面和黑暗的一面。屁股在哪就要努力让它变得更好，而不是见到黑暗面后就只知道诋毁和抱怨。从长远来看，后者最终只会损坏自己的名誉浪费自己的时间，得不到什么好处。</p><p>当然，如果经过自己的努力依然无法改变任何东西，那就用脑袋挑选一个更符合自己价值观的位置去坐吧。</p><h3 id="营造团队氛围，每个人都有责任"><a href="#营造团队氛围，每个人都有责任" class="headerlink" title="营造团队氛围，每个人都有责任"></a>营造团队氛围，每个人都有责任</h3><p>今年阅读了桥水基金创始人瑞·达利欧的《原则》这本书，我被其中描述的创意择优像家一样的工作氛围所深深吸引，幻想着自己未来能到这样的公司工作。</p><p>然而，我和很多读者一样都进入了相同的思维误区，那就是等着别人来营造这种氛围而我们坐享其成。既然每个人都喜欢这样的氛围，那么为什么不能在自己力所能及的范围内行动呢？</p><p>在我们实验室的三人分布式小组里，我作为小组长和两位学弟就努力在组内营造了这种氛围。大家有不错的学习资料就相互分享，有棘手的脏活就平分来干，功能按照兴趣去推动，bug 按照难易尽量平均分配，有人周中有事的话其他人可以暂时帮忙顶住工程压力，而他在忙完之后往往周末也会主动加班赶上落下的进度。在这期间，我也与学弟们建立了良好的私人关系，这样的氛围让我觉得开心，也让我进一步确信每个人都可以去营造团队氛围。</p><p>尽管营造团队氛围每个人都有责任，但我还是觉得考虑自己职业规划时一定要优先考虑关注员工成长的公司，否则推进这种氛围可能会非常难，这会进而影响自己的热情和产出。我个人是非常不认同企业付高工资就可以将工程师当做工具人来使用的企业文化的，员工和项目只有共同成长才有可能建立一个长期高效持续创新的团队，也只有这样的团队才值得大家齐心协力为之奋斗。</p><h3 id="真诚坦率"><a href="#真诚坦率" class="headerlink" title="真诚坦率"></a>真诚坦率</h3><p>《原则》这本书里谈到了真诚坦率是很难得的高价值品质，它带给我们的收益往往比我们想象的还要大。</p><p>当我们能够真诚坦率的公开我们的工作内容和进度时，一方面会使我们更容易获得上级和同事的理解信任，另一方面也会促使我们减少摸鱼时间，更加重视自己的单位时间产出并努力提高自己的工作效率，而后者在我看来是更关键的。人都会存在惰性，这样的机制可以帮助自己克服惰性，追求效率至上。</p><h3 id="不要妄想别人帮自己指出最优解，路都是自己走出来的"><a href="#不要妄想别人帮自己指出最优解，路都是自己走出来的" class="headerlink" title="不要妄想别人帮自己指出最优解，路都是自己走出来的"></a>不要妄想别人帮自己指出最优解，路都是自己走出来的</h3><p>我在振华老师组的时候曾经请教他让他为我指一条发展最快的捷径。振华老师当时说他也不确定我走哪条路是最快的捷径，只能结合我自己的状态一步步走着看。</p><p>当时的我还不能够理解，现在的我逐渐明白了：对于大部分人来说，路都是要自己一步步走出来的，不要妄想有个大佬能直接给自己指出全局最优的捷径。保持开放的心态，一直学习一直反思，多向大佬们请教，能走出一条局部最优解的路就已经很不错了。</p><h3 id="养成定期反思的好习惯"><a href="#养成定期反思的好习惯" class="headerlink" title="养成定期反思的好习惯"></a>养成定期反思的好习惯</h3><p>犯错误不可怕，不反思错误的原因并进行针对性的分析和改进就很可怕了。</p><p>随着见识的增长，我逐渐意识到定期反思总结对于个人的发展至关重要。因此我们小组除了每周同步两次工作进度以外，每周每月还会做反思总结并在组间进行分享和互相评价，这些总结内容包括但不限于工作总结，个人发展，自我反思和想法建议等。每月抽一个小时反思下存在的问题，不论是自身的还是团队的，一经分享讨论下个月就可能已经进行了改进，这形成了一个正反馈效应，对大家都是有益无害的。</p><p>通过这些分享，我们每个人都在逐渐的进步，这些进步包括但不限于代码设计，时间管理，汇报技巧，工作方式，做事思维等等。就跟当年高考刷题一样，悲观的人认为题量是无尽的，怎么刷也刷不完；乐观的人认为题量是有尽的，刷一道少一道。我是乐观的人，我坚信这些定期反思加上我们的长期专注一定会迎来收获。</p><h3 id="了解技术细节最好的时机有两个，一个是过去，一个是现在"><a href="#了解技术细节最好的时机有两个，一个是过去，一个是现在" class="headerlink" title="了解技术细节最好的时机有两个，一个是过去，一个是现在"></a>了解技术细节最好的时机有两个，一个是过去，一个是现在</h3><p>在写代码的时候我们常会碰到一些技术细节（比如 git 命令，比如不同 IO 的区别），有些人认为这些细节无关紧要将其置之不理，而有些人非常重视这些细节并将其很快学懂。我觉得面对这些细节问题的态度是决定技术水平是否会停滞不前的重要因素。</p><p>了解技术细节最好的时机有两个，一个是过去，一个是现在。当遇到技术细节时，可以简单评估一下学习成本。如果很低（小于 1 小时），则可以在当天尽量将其搞明白。如果比较高，则可以将其放在预计学习的列表里面，定期抽出一些整块的时间集中学习。</p><p>诚然，在刚开始编程的时候就这样会比较累，因为什么都不会。但只要能够长期坚持学习，遇到不懂技术细节的概率会越来越低，自己的水平也会越来越高，形成的正反馈效应也会强化这一过程。</p><h3 id="不要给自己设限"><a href="#不要给自己设限" class="headerlink" title="不要给自己设限"></a>不要给自己设限</h3><p>在大型基础软件里，往往不同的人会负责不同的模块。如果模块解耦做的比较好的话，可能不同模块的同学不会有太多交流。比如在刚进组的时候我就只关注了分布式模块的内容，有关单机任何模块的功能和 bug 修复我基本都不会关注，这也使得我进组都一年了还不太了解时序数据库是什么。现在回想当时的自己还是太傻了。</p><p>之前振华组里的明亮学长在做秋招分享时介绍到，他认为互联网跳槽之所以容易涨薪涨职级，就是因为跳槽人往往对其所在组工作具有比较深刻的认知，这些认知可能是几十人的团队踩了数年的坑才提炼出来的经验，而只要在这个团队待几个月说不定就能够学懂大半了，这些经验可以为下家公司创造很大的价值。</p><p>基于这样的思路，我们就不应该给自己设限。在自己力所能及的范围内去关注一下其他模块的工作往往不需要很多时间，但对于自己的职业发展一定是有益无害的。这里我就非常佩服和我在一个组的苏总，他就是典型的不给自己设限的人，他一人为 IoTDB 带来了 UDF, Trigger, Select into, Continuous query, 算数表达式等高级特性，写入，查询，生态工具这些模块他都碰过。尽管他现在非常忙，但我们这一届的同学毕业后对 IoTDB 了解最深的人很可能就是他，那他的价值就会非常高了。</p><h3 id="多给自己一些正向反馈"><a href="#多给自己一些正向反馈" class="headerlink" title="多给自己一些正向反馈"></a>多给自己一些正向反馈</h3><p>这个感悟其实涉及到了一些心理学的技巧。在学习计算机的过程中，往往会遇到很多棘手的问题，而这些问题很可能会影响学习热情。很多小白在刚入门的时候遇到一个棘手的问题就被劝退了。因此我们需要定期给自己一些正向反馈，这些反馈包括但不限于做一个完整的 project/feature，解决一个别人解决不了的 bug，参加各种比赛获奖，做 talk，发论文等等。通过这种外在的对自己的认可，我们也就能继续保持着学习热情。这一点黄东旭老师在 VLDB summer school 的 panel 上也有提到。</p><h3 id="不能只有输入没有输出"><a href="#不能只有输入没有输出" class="headerlink" title="不能只有输入没有输出"></a>不能只有输入没有输出</h3><p>在工作学习中，不能只有输入没有输出。我对输入的理解是指花费的时间成本，对输出的理解则是明确的他人可以看到的工作量。</p><p>为什么要强调这一点？因为我刚到实验室就是这样的状态，后面才慢慢意识到并进行了改变。比如对于一个调研的工作，往往会花费很多时间，调研完后自己可能感觉学习到了很多东西，但也没有明确的输出（包括但不限于分享，阅读笔记，解决实际问题等等）让别人看到，过一段时间可能自己又忘了。这不仅会导致别人丧失对自己的信任，也会导致自己忽视自己的单位时间产出，形成过一天混一天的惰性思维。它们都会使得自己丧失进一步成长的机会。因此，定期适当地输出是非常重要的。</p><h3 id="敢于不卑不亢地分享自己的想法"><a href="#敢于不卑不亢地分享自己的想法" class="headerlink" title="敢于不卑不亢地分享自己的想法"></a>敢于不卑不亢地分享自己的想法</h3><p>之前振华老师跟我们分享过他在明尼苏达留学时的一个有趣现象。在每周全院的科研 idea 分享会上，尽管上台分享的印度人很多，但大多数都很 naive，相反上台分享的中国人很少，但大多都很厉害，这侧面反映了我们中国人可能受儒家思想的影响，大都不好意思去分享自己还不成熟的工作。不同的人对这种现象有不同的看法，但在振华老师看来，早分享可能早避坑，不畏惧批评反而会有更大的前景。在 VLDB summer school 上黄东旭老师也告诫我们不要畏惧权威，要敢于分享自己的想法。</p><p>对于技术问题，我们要敢于不卑不亢，就事论事的分享自己的想法。如果我们的想法是正确的，这样能够不断竖立自己的个人影响力。如果我们的想法是错误的，这样也能够早点遭致批评来纠正自己的错误想法。无论如何对自己都是有益无害的。</p><h3 id="养成闭环的做事习惯"><a href="#养成闭环的做事习惯" class="headerlink" title="养成闭环的做事习惯"></a>养成闭环的做事习惯</h3><p>养成闭环的做事习惯非常重要，这有利于自己在同事中建立信任，塑造自己靠谱的形象。</p><p>一个新功能的开发工作，从接受，需求，调研，设计，实现，测试，review，合并到最终汇报要形成一个闭环。我在刚开始参与社区的时候对这样繁琐的流程非常困惑，感觉没有什么意义。随着维护项目经验的积累，我逐步意识到了这些都是过来人的智慧。</p><p>乔老师常给我们介绍说做事要做到”事事有回应 件件有着落 凡事有交代”，务实的说，很难对所有的事情都做到这种程度，但我们可以怀抱着这样的期望尽力做到这样，至少也得把重要且紧急的事情做到这个地步。养成这样的习惯对于自己的职业发展绝对是有益无害的。</p><h3 id="开源铸就了数据库最好的时代"><a href="#开源铸就了数据库最好的时代" class="headerlink" title="开源铸就了数据库最好的时代"></a>开源铸就了数据库最好的时代</h3><p>不确定是不是幸存者偏差，感觉数据库近几年在国内越来越火了。但就算是幸存者偏差，开源基础软件在国内越来越火已经是毋庸置疑的事实了。不论是资本还是企业，都更青睐开源的基础软件。</p><p>作为学生，这也是我们迅速成长的最好时代。我们完全可以参与开源社区，迅速提升自己的能力并认识一批志同道合的朋友，我就是开源的典型受益者，不论是 Talent Plan 社区还是 Apache IoTDB 社区都让我受益良多。</p><p>此外，站在巨人的肩膀上非常重要。我们如今身处开源的时代，很多资料都是公开的，一定要避免闭门造车。多了解其他系统，多交流，多调研，这对于个人和项目的发展都是有益无害的。</p><h3 id="稳定性可维护性大于性能"><a href="#稳定性可维护性大于性能" class="headerlink" title="稳定性可维护性大于性能"></a>稳定性可维护性大于性能</h3><p>当修 bug 次数多了之后，我逐渐意识到软件工程的重要性，并开始思考项目不稳定的根因。</p><p>OceanBase 的杨传辉老师提过一个观点：每个系统设计时都需要考虑架构、稳定性和性能，这三者之间的关系是什么？一个经典的规律是“把稳定的系统做高效，远比把高效的系统做稳定更容易”。最难的是从 0 到 1 把系统做稳定。有了稳定的系统，接下来逐步优化性能往往会比较顺利，直到遇到系统架构的性能天花板。因此，系统架构设计之前，首先要考虑清楚系统的目标和性能天花板，接着基于正确的架构把系统做稳定，最后优化性能。</p><p>我个人非常认同这个观点，大型基础软件的性能和稳定性可维护性往往存在一个不那么明显的 trade-off。在开源软件里，要实现新功能或者重构，一定要优先关注可维护性和稳定性。实现一个性能最优但模块耦合不好维护的功能对项目的伤害是非常大的，甚至可以被称为技术债，这会大大影响开发者的热情并辜负客户的信任。先实现一个 naive 但好维护几乎没有 bug 的版本，逐步的去优化性能，对于开发者和客户来说都是一个正向反馈的过程，这对于社区的发展也是很有帮助的。这里我就非常喜欢 TiDB 社区的方式，模块解耦做的比较干净，从 3.0 到 4.0 再到 5.0。每个版本都有巨大的性能提升，社区也越来越好，这就是一个明显的正反馈过程。</p><p>至于如何进一步提升系统的稳定性，在 VLDB summer school 的 panel 上我请教了黄东旭老师，他分享了 PingCAP 现在已经有几百台测试服务器日夜不息的进行测试，同时每年 PingCAP 为了稳定性付出的成本（包括硬件成本，人力成本等）已经达到了总支出的 30%~40%，而这依然还没有让他满意。由此可见，稳定的产品一定是大量的测试打磨出来的，没有太多捷径可走。当然，作为写代码的工程师，多反思总结，不断提升自己的技术水平，也能够对项目的稳定性做出自己的贡献。</p><h3 id="创新往往来自假设的改变"><a href="#创新往往来自假设的改变" class="headerlink" title="创新往往来自假设的改变"></a>创新往往来自假设的改变</h3><p>在今年的 VLDB summer school 上，有一个观点始终被提及：”创新往往来自假设的改变”。这个世界本来并不存在什么假设，假设是人类描述自然规律时的前置条件，而这个前置条件并不一定绝对正确，也不一定一成不变。不论是做学术还是做产品，可以时常想想假设在部分场景是否已经发生了变化，这其中可能蕴含着巨大的创新。</p><h2 id="来年展望"><a href="#来年展望" class="headerlink" title="来年展望"></a>来年展望</h2><p>洋洋洒洒写了这么一大堆流水账，也是借着写总结的机会再反思下自己，给未来的自己一个警醒。</p><p>新的一年，希望自己能努力干好以下 6 件事情吧：</p><ul><li>和实验室同学们一起打造出一个稳定高效的分布式 IoTDB，在毕业之前不留遗憾。</li><li>和实验室同学们一起营造团队的技术氛围，希望能够将我们组塑造成高校做开源的标杆实验室，吸引一大批对分布式系统感兴趣的优秀同学过来，一起干有意义有挑战的事情。</li><li>实习和秋招的时候多找一些团队聊聊，最终选择一个能得到成长的增量赛道。</li><li>认真学习一下数据库引擎，真的动手实践一下 LLVM，JIT，CodeGen，向量化等技术，也许是学习一下 tinysql 3.0 版本或者 risinglight。</li><li>规律作息，多锻炼多运动，减减肥，让自己拥有健康的身体。</li><li>多抽一些时间陪陪我的小杨同学，祝愿她申请一切顺利。</li></ul><p>最后，在除夕这天，预祝大家新年万事如意。愿每个人在新的一年都学有所得，学有所获，学有所长。</p>]]></content>
    
    
    
    <tags>
      
      <tag>IoTDB</tag>
      
      <tag>年终总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021 Talent Plan KV 学习营结营总结</title>
    <link href="/tinykv/"/>
    <url>/tinykv/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>2021 年 11 月 ~ 2022 年 1 月 ，<strong>PingCAP </strong>举办了第一届 <strong>Talent Plan KV 学习营</strong>，相关介绍可参考 <a href="https://m.creatby.com/v2/manage/book/oa4occ/?from=singlemessage" target="_blank" rel="noopener">推送</a>。</p><p>在本次比赛中，由于我们小组的两位成员之前都刷过 MIT 6.824，已经对教学级别的 raft 有一定的了解，所以参加此次比赛的目的就是去感受一下生产级别分布式 KV 的代码实现，学习实践一下 lsm, etcd, raftstore 和 percolator 的理论知识和 codebase。</p><p>u1s1，刷 lab 的过程十分曲折，我们俩所在的实验室到年底的时候都非常忙，前几周基本每周都只能抽出顶多一两天的时间来写代码，而理解 lab2b/lab3b raftstore 的难度是非常大的，我们用了一周多的时间才勉强看懂 raftstore 的代码。这使得到还剩两周时间的时候，我们才刷到 lab2c。最后两周我们利用中午午休时间和晚上睡觉时间疯狂加班，在 lab 上花了更多的时间，最后才堪堪刷完。</p><p>在刷 lab 的过程中，由于时间有限，我们始终秉持着<code>学习优先，成绩第二</code>的原则。即以 <strong>了解 codebase，学习知识，做最容易做且最有用的优化</strong> 为主，并没有去卷很多功能点。在处理 bug 的态度上，对于 safety 的问题比如错误读写的 bug 等，我们对这类问题进行了重点关注和解决；对于 liveness 的问题比如 request timeout 等，我们则是在有限的时间内尽力做了优化，但并没有投入太多精力，因为这种工作没有上限，tikv 的 raftstore 也一定在持续做这些工作，时间不够的情况下去卷这些就没有太大意义了。</p><p><img src="/tinykv/grade.png" srcset="/img/loading.gif" lazyload alt></p><p>出人意料的是，我们得了第二名的好成绩，具体可参考 <a href="https://asktug.com/t/topic/393068" target="_blank" rel="noopener">官宣</a>。事后反省一下，在 safety 上我们遇到的问题都解决了；在 liveness 上我们没投入太多精力；在文档上，我们简单介绍了代码实现，但将重点放在了我们对相关知识的理解和思考上；在性能上，我们重点做了最容易做的 batching 优化，其本质上是使用 raft 的优化而不是 raft 自身的优化，但对性能的提升却异常关键，比如 tidb 对于一个事务打包的一堆写请求，到 tikv 的 region 之后，这些写请求同步成一条还是多条 raftlog 对于性能的影响是巨大的。</p><p>从结果来看，我们的策略是正确的，我们在很有限的时间内拿到了很高的收益。</p><p>最后，出于对课程的保护，也出于跟大家分享一些刷 lab 的经验，让大家少踩坑，在此处我仅将文档公开，希望能为大家提供一些思路，欢迎一起交流。</p><h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><h2 id="lab1"><a href="#lab1" class="headerlink" title="lab1"></a>lab1</h2><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><h4 id="Part-1-Implement-a-standalone-storage-engine"><a href="#Part-1-Implement-a-standalone-storage-engine" class="headerlink" title="Part 1 : Implement a standalone storage engine"></a>Part 1 : Implement a standalone storage engine</h4><p>本部分是对底层 badger api 的包装，主要涉及修改的代码文件是 standalone_storage.go, 需要实现 Storage 接口的 Write 和 Reader 方法，来实现对底层 badger 数据库的读写。</p><h5 id="1-Write-部分实现思路"><a href="#1-Write-部分实现思路" class="headerlink" title="1.Write 部分实现思路"></a>1.Write 部分实现思路</h5><p>Write 部分涉及到 Put 和 Delete 两种操作。</p><p>因为 write_batch.go 中已经实现了对 badger 中 entry 的 put 和 delete 操作，我们只需要判断 batch 中的每一个 Modify 的操作类型，然后直接调用 write_batch.go 中相对应的方法即可。</p><h5 id="2-Reader-部分实现思路"><a href="#2-Reader-部分实现思路" class="headerlink" title="2.Reader 部分实现思路"></a>2.Reader 部分实现思路</h5><p>Reader 部分会涉及到 point read 和 scan read 两种不同读方式。</p><p>因为提示到应该使用 badger.Txn 来实现 Reader 函数，所以我们声明了一个 badgerReader 结构体来实现 StorageReader 接口，badgerReader 结构体内部包含对 badger.Txn 的引用。</p><p>针对 point read，<br>我们直接调用 util.go 中的 GetCF 等函数，对 cf 中指定 key 进行读取。</p><p>针对 scan read，<br>直接调用 cf_iterator.go 中的 NewCFIterator 函数，返回一个迭代器，供 part2 中调用。</p><h4 id="Part-2-Implement-raw-key-value-service-handlers"><a href="#Part-2-Implement-raw-key-value-service-handlers" class="headerlink" title="Part 2 : Implement raw key/value service handlers"></a>Part 2 : Implement raw key/value service handlers</h4><p>本部分需要实现 RawGet/ RawScan/ RawPut/ RawDelete 四个 handlers，主要涉及修改的代码文件是 raw_api.go</p><p>针对 RawGet，<br>我们调用 storage 的 Reader 函数返回一个 Reader，然后调用其 GetCF 函数进行点读取即可，读取之后需要判断对应 key 是否存在。</p><p>针对 RawScan，<br>同样地调用 storage 的 Reader 函数返回一个 Reader，然后调用其 IterCF 函数返回一个迭代器，然后使用迭代器读取即可。</p><p>针对 RawPut 和 RawDelete，<br>声明对应的 Modify 后，调用 storage.Write 函数即可。</p><h3 id="相关知识学习"><a href="#相关知识学习" class="headerlink" title="相关知识学习"></a>相关知识学习</h3><p>LSM 是一个伴随 NoSQL 运动一起流行的存储引擎，相比 B+ 树以牺牲读性能的代价在写入性能上获得了较大的提升。</p><p>近年来，工业界和学术界均对 LSM 树进行了一定的研究，具体可以阅读 VLDB2018 有关 LSM 的综述：<a href="https://arxiv.org/pdf/1812.07527.pdf" target="_blank" rel="noopener">LSM-based Storage Techniques: A Survey</a>, 也可直接阅读针对该论文我认为还不错的一篇 <a href="https://blog.shunzi.tech/post/vldbj-2018lsm-based-storage-techniques-a-survey/" target="_blank" rel="noopener">中文概要总结</a>。</p><p>介绍完了 LSM 综述，可以简单聊聊 badger，这是一个纯 go 实现的 LSM 存储引擎，参照了 FAST2016 有关 KV 分离 LSM 的设计： <a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf" target="_blank" rel="noopener">WiscKey</a> 。有关其项目的动机和一些 benchmark 结果可以参照其创始人的 <a href="https://dgraph.io/blog/post/badger/" target="_blank" rel="noopener">博客</a>。</p><p>对于 Wisckey 这篇论文，除了阅读论文以外，也可以参考此 <a href="https://www.scienjus.com/wisckey/" target="_blank" rel="noopener">阅读笔记</a> 和此 <a href="https://www.skyzh.dev/posts/articles/2021-08-07-lsm-kv-separation-overview/" target="_blank" rel="noopener">总结博客</a>。这两篇资料较为系统地介绍了现在学术界和工业界对于 KV 分离 LSM 的一些设计和实现。</p><p>实际上对于目前的 NewSQL 数据库，其底层大多数都是一个分布式 KV 存储系统。对于 OLTP 业务，其往往采用行存的方式，即 key 对应的 value 便是一个 tuple。在这样的架构下，value 往往很大，因而采用 KV 分离的设计往往能够减少大量的写放大，从而提升性能。</p><p>之前和腾讯云的一个大佬聊过，他有说 TiKV 的社区版和商业版存储引擎性能差异很大。目前想一下，KV 分离可能便是 RocksDB 和 Titan 的最大区别吧。</p><h2 id="lab2"><a href="#lab2" class="headerlink" title="lab2"></a>lab2</h2><h3 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h3><h4 id="lab2a"><a href="#lab2a" class="headerlink" title="lab2a"></a>lab2a</h4><h5 id="Leader-election"><a href="#Leader-election" class="headerlink" title="Leader election"></a>Leader election</h5><p>本部分是对 raft 模块 leader 选举功能的实现，主要涉及修改的代码文件是 raft.go、log.go</p><p>raft 模块 leader 选举流程如下：</p><p><img src="/tinykv/leader%20election.jpg" srcset="/img/loading.gif" lazyload alt></p><p>第一步，我们首先实现对 raft 的初始化。</p><p>实现 log.go 中的 newLog 方法，调用 storage 的 InitialState 等方法对 RaftLog 进行初始化，读取持久化在 storage 中 term、commit、vote 和 entries，为后面的 lab 做准备。完成 RaftLog 的初始化后，再填充 Raft 中的相应字段，即完成 Raft 对象的初始化。</p><p>第二步，我们实现 Raft 对象的 tick() 函数</p><p>上层应用会调用 tick() 函数，作为逻辑时钟控制 Raft 模块的选举功能和心跳功能。因此我们实现 tick() 函数，当 Raft 状态是 Follower 时，检查自上次接收心跳之后，间隔时间是否超过了 election timeout，如果超过了，将发送 MessageType_MsgHup；当 Raft 状态时 Leader 时，检查自上次发送心跳之后，间隔时间是否超过了 heartbeat timeout，如果超过了，将发送 MessageType_MsgBeat。</p><p>第三步，我们实现 raft.Raft.becomeXXX 等基本函数</p><p>实现了 becomeFollower(),becomeCandidate(),becomeLeader() 等 stub 函数，对不同状态下的属性进行赋值。</p><p>第四步，我们实现 Step() 函数对不同 Message 的处理</p><p>主要涉及到的 Message 有</p><ul><li><p>MessageType_MsgHup</p></li><li><p>MessageType_MsgRequestVote</p></li><li><p>MessageType_MsgRequestVoteResponse</p></li></ul><p>接下来分情况实现：</p><p>（1）MessageType_Msgup</p><p>当 Raft 状态为 Follower 和 Candidate 时，会先调用 becomeCandidate() 方法，将自己的状态转变为 Candidate，然后向所有 peer 发送 MessageType_MsgRequestVote 消息，请求他们的投票</p><p>（2）MessageType_MsgRequestVote</p><p>当 Raft 接收到此消息时，会在以下情况拒绝投票：</p><ul><li><p>当 Candidate 的 term 小于当前 raft 的 term 时拒绝投票</p></li><li><p>如果当前 raft 的 term 与 candidate 的 term 相等，但是它之前已经投票给其他 Candidate 时，会拒绝投票</p></li><li><p>如果当前 raft 发现 candidate 的日志不如自己的日志更 up-to-date 时，也会拒绝投票</p></li></ul><p>（3）MessageType_MsgRequestVoteResponse</p><p>Candidate 接收到此消息时，就会根据消息的 reject 属性来确定自己的得票，当自己的得票数大于一半以上，就会调用 becomeLeader() 函数，将状态转变为 Leader；当拒绝票数也大于一半以上时，就会转回到 Follower 状态。</p><h5 id="Log-replication"><a href="#Log-replication" class="headerlink" title="Log replication"></a>Log replication</h5><p>本部分是对 raft 模块日志复制功能的实现，主要涉及修改的代码文件是 raft.go、log.go</p><p>日志复制的流程如下：</p><p><img src="/tinykv/log%20replication.jpg" srcset="/img/loading.gif" lazyload alt="Log Replication"></p><p>本部分主要实现不同状态的 raft 对以下 Message 的处理：</p><ul><li>MessageType_MsgBeat</li><li>MessageType_MsgHeartbeat</li><li>MessageType_MsgHeartbeatResponse</li><li>MessageType_MsgPropose</li><li>MessageType_MsgAppend</li><li>MessageType_MsgAppendResponse</li></ul><p>接下来分情况实现：</p><p>（1）MessageType_MsgBeat</p><p>当上层应用调用 tick() 函数时，Leader 需要检查是否到了该发送心跳的时候，如果到了，那么就发送 MessageType_MsgHeartbeat。</p><p>leader 会将自己的 commit 值赋给在 MsgHeartbeat 消息中响应值，以让 Follower 能够及时 commit 安全的 entries</p><p>（2）MessageType_MsgHeartbeat</p><p>当 Follower 接收到心跳时，会更新自己的 electionTimeout，并会将自己的 lastIndex 与 leader 的 commit 值比较，让自己能够及时 commit entry。</p><p>（3）MessageType_MsgHeartbeatResponse</p><p>当 Leader 接收到心跳回复时，会比较对应 Follower 的 Pr.Match, 如果发现 Follower 滞后，就会向其发送缺少的 entries</p><p> (4)MessageType_MsgPropose</p><p>当 Leader 要添加 data 到自己的 log entries 中时，会发送一个 local message—MsgPropose 来让自己向所有 follower 同步 log entries，发送 MessageType_MsgAppend</p><p>（5）MessageType_MsgAppend</p><p>当 Follower 接收到此消息时，会在以下情况拒绝 append：</p><ul><li>当 Leader 的 term 小于当前 raft 的 term 时拒绝 append</li><li>当 Follower 在对应 Index 处不含 entry，说明 Follower 滞后比较严重</li><li>当 Follower 在对应 Index 处含有 entry，但是 term 不相等，说明产生了冲突</li></ul><p>其他情况，Follower 会接收新的 entries，并更新自己的相关属性。</p><p>（6）MessageType_MsgAppendResponse</p><p>当 Leader 发现 Follower 拒绝 append 后，会更新 raft.Prs 中对应 Follower 的进度信息，并根据新的进度，重新发送 entries。</p><h5 id="Implement-the-raw-node-interface"><a href="#Implement-the-raw-node-interface" class="headerlink" title="Implement the raw node interface"></a>Implement the raw node interface</h5><p>本部分主要实现 raw node 的接口，涉及修改的代码文件为 rawnode.go</p><p>RawNode 对象中的属性除了 Raft 对象，还增加了 prevSoftState 和 preHardState 两个属性，用于在 HasReady() 函数中判断 node 是否 pending</p><p>此外还实现了 Advance() 函数，主要是对 Raft 内部属性进行更新。</p><h4 id="lab2b"><a href="#lab2b" class="headerlink" title="lab2b"></a>lab2b</h4><h5 id="Implement-peer-storage"><a href="#Implement-peer-storage" class="headerlink" title="Implement peer storage"></a>Implement peer storage</h5><p>本部分主要实现 peer_storage.go 中 SaveReadyState() 方法和 Append() 方法，涉及修改的代码文件为 peer_storage.go</p><p>peer storage 除了管理持久化 raft log 外，也会管理持久化其他元数据（RaftLocalState、RaftApplyState 和 RegionLocalState），因此我们需要实现 SaveReadyState() 方法，将 raft.Ready 中修改过的状态和数据保存到 badger 中。</p><p>首先我们通过实现 Append() 方法，保存需要持久化的 raft log。遍历 Ready 中 Entries，调用 SetMeta() 方法将他们保存到 raftWB，并删除可能未提交的 raft log，最后更新 raftState。</p><p>在处理完 raft log 后，我们还需要保存 Ready 中的 hardState，并在最后调用 WriteToDB() 方法保证之前的修改落盘。</p><h5 id="Implement-raft-ready-process"><a href="#Implement-raft-ready-process" class="headerlink" title="Implement raft ready process"></a>Implement raft ready process</h5><p>本部分主要实现 peer_storage_handler.go 中的 proposeRaftCommand() 和 HandleRaftReady() 方法，涉及修改的代码文件为 peer_storage_handler.go</p><p>proposeRaftCommand() 方法使得系统有能力将接收到的 client 请求通过 raft 模块进行同步，以实现分布式环境下的一致性。在本方法中，我们直接调用 raft 模块的 Propose 方法，将 client 请求进行同步，并为该请求初始化对应的 proposal，以便该请求 committed 后将结果返回给 client</p><p>当 msg 被 raft 模块处理后，会导致 raft 模块的一些状态变化，这时候需要 HandleRaftReady() 方法进行一些操作来处理这些变化：</p><ol><li>需要调用 peer_storage.go() 中的 SaveReadyState() 方法，将 log entries 和一些元数据变化进行持久化。</li><li>需要调用 peer_storage_handler 中的 send() 方法，将一些需要发送的消息，发送给同一个 region 中的 peer</li><li>我们需要处理一些 committed entries，将他们应用到状态机中，并把结果通过 callback 反馈给 client</li><li>在上述处理完后，需要调用 advance() 方法，将 raft 模块整体推进到下一个状态</li></ol><h4 id="lab2c"><a href="#lab2c" class="headerlink" title="lab2c"></a>lab2c</h4><p>因为 raft entries 不可能一直无限增长下去，所以本部分我们需要实现 snapshot 功能，清理之前的 raft entries。</p><p>整个 lab2c 的执行流程如下：</p><ol><li>gc log 的流程：</li></ol><p><img src="/tinykv/gc%20raftLog.png" srcset="/img/loading.gif" lazyload alt="gc raftLog"></p><ol><li>发送和应用 snapshot 的流程：</li></ol><p><img src="/tinykv/send%20and%20apply%20Snapshot.png" srcset="/img/loading.gif" lazyload alt="send and apply snapshot"></p><h5 id="Implement-in-raft"><a href="#Implement-in-raft" class="headerlink" title="Implement in raft"></a>Implement in raft</h5><p>当 leader 发现 follower 落后太多时，会主动向 follower 发送 snapshot，对其进行同步。在 Raft 模块内部，需要增加对 MessageType_MsgSnapshot 消息的处理，主要对以下两点进行处理：</p><ol><li>当 leader 需要向 follower 同步日志时，如果同步的日志已经被 compact 了，那么直接发送 snapshot 给 follower 进行同步，否则发送 MessageType_MsgAppend 消息，向 follower 添加 entries。通过调用 peer storage 的 Snapshot() 方法，我们可以得到已经制作完成的 snapshot</li><li>实现 handleSnapshot() 方法，当 follower 接收到 MessageType_MsgSnapshot 时，需要进行相应处理。</li></ol><p>在第二步中，follower 需要判断 leader 发送的 snapshot 是否会与自己的 entries 产生冲突，如果发送的 snapshot 是目前现有 entries 的子集，说明 snapshot 是 stale 的，那么要返回目前 follower 的进度，更新 leader 中相应的 Match 和 Next，以便再下一次发送正确的日志；如果没有发生冲突，那么 follower 就根据 snapshot 中的信息进行相应的更新，更新自身的 committed 等 index，如果 confstate 也产生变化，有新的 node 加入或者已有的 node 被移除，需要更新本节点的 confState，为 lab3 做准备。</p><h5 id="Implement-in-raftstore"><a href="#Implement-in-raftstore" class="headerlink" title="Implement in raftstore"></a>Implement in raftstore</h5><p>在本部分中，当日志增长超过 RaftLogGcCountLimit 的限制时，会要求本节点整理和删除已经应用到状态机的旧日志。节点会接收到类似于 Get/Put/Delete/Snap 命令的 CompactLogRequest，因此我们需要在 lab2b 的基础上，当包含 CompactLogRequest 的 entry 提交后，增加 processAdminRequest() 方法来对这类 adminRequest 的处理。</p><p>在 processAdminRequest() 方法中，我们需要更新 RaftApplyState 中 RaftTruncatedState 中的相关元数据，记录最新截断的最后一个日志的 index 和 term，然后调用 ScheduleCompactLog() 方法，异步让 RaftLog-gc worker 能够进行旧日志删除的工作。</p><p>另外，因为 raft 模块在处理 snapshot 相关的 msg 时，也会对一些状态进行修改，所以在 peer_storage.go 方法中，我们需要在 SaveReadyState() 方法中，调用 ApplySnapshot() 方法中，对相应的元数据进行保存。</p><p>在 ApplySnapshot() 方法中，如果当前节点已经处理过的 entries 只是 snapshot 的一个子集，那么需要对 raftLocalState 中的 commit、lastIndex 以及 raftApplyState 中的 appliedIndex 等元数据进行更新，并调用 ClearData() 和 ClearMetaData() 方法，对现有的 stale 元数据以及日志进行清空整理。同时，也对 regionLocalState 进行相应更新。最后，我们需要通过 regionSched 这个 channel，将 snapshot 应用于对应的状态机</p><h3 id="相关知识学习-1"><a href="#相关知识学习-1" class="headerlink" title="相关知识学习"></a>相关知识学习</h3><h4 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h4><p>Raft 是 2015 年以来最受人瞩目的共识算法，有关其前世今生可以参考我们总结的 <a href="https://tanxinyu.work/raft/">博客</a>，此处不再赘述。</p><p>etcd 是一个生产级别的 Raft 实现，我们在实现 lab2a 的时候大量参考了 etcd 的代码。这个过程不仅帮助我们进一步了解了 etcd 的 codebase，也让我们进一步意识到一个工程级别的 raft 实现需要考虑多少 corner case。整个学习过程收获还是很大的，这里贴一些 etcd 的优质博客以供学习。</p><ul><li><a href="https://www.codedump.info/post/20180922-etcd-raft/" target="_blank" rel="noopener">etcd Raft 库解析</a></li><li><a href="https://www.codedump.info/post/20181125-etcd-server/" target="_blank" rel="noopener">Etcd 存储的实现</a></li><li><a href="https://www.codedump.info/post/20210515-raft" target="_blank" rel="noopener">Etcd Raft 库的工程化实现</a></li><li><a href="https://www.codedump.info/post/20210628-etcd-wal/" target="_blank" rel="noopener">Etcd Raft 库的日志存储</a></li></ul><h4 id="KVRaft"><a href="#KVRaft" class="headerlink" title="KVRaft"></a>KVRaft</h4><p>在 Raft 层完成后，下一步需要做的便是基于 Raft 层搭建一个高可用的 KV 层。这里依然参考了 etcd KV 层驱动 Raft 层的方式。<br>即总体的思路如下所示：<br><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Go"><span class="hljs-keyword">for</span> &#123;<br>  <span class="hljs-keyword">select</span> &#123;<br>  <span class="hljs-keyword">case</span> &lt;-s.Ticker:<br>    Node.Tick()<br>  <span class="hljs-keyword">default</span>:<br>    <span class="hljs-keyword">if</span> Node.HasReady() &#123;<br>      rd := Node.Ready()<br>      saveToStorage(rd.State, rd.Entries, rd.Snapshot)<br>      send(rd.Messages)<br>      <span class="hljs-keyword">for</span> _, entry := <span class="hljs-keyword">range</span> rd.CommittedEntries &#123;<br>        process(entry)<br>      &#125;<br>      s.Node.Advance(rd)<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure></p><p>做过 tinykv 的同学应该都能够感觉到 lab2b 的难度与之前有一个大 gap，我认为主要原因是需要看的代码实现是太多了。</p><p>如今回首，建议分三个步骤来做，这样效率可能会高一些：</p><ul><li>了解读写流程的详细步骤。对于 client 的请求，其处理和回复均在 raft_server.go 中进行了处理，然而其在服务端内部的生命周期如何，这里需要知根知底。（注意在遇到 channel 打断同步的执行流程时不能瞎猜，一定要明确找到 channel 的接收端和发送端继续把生命周期理下去）</li><li>仔细阅读 raft_server.go, router.go, raftstore.go, raft_worker.go, peer_storage.go, peer_msg_handle.go 等文件的代码。这会对了解整个系统的 codebase 十分有帮助。</li><li>仔细阅读 tinykv 的 lab2 文档，了解编码，存储等细节后便可以动手实现了。</li></ul><p>在实现 lab2b 中，由于时间有限，我们重点关注了 batching 的优化和 apply 时的 safety，以下进行简单的介绍：</p><ul><li><p>batching 优化：客户端发来的一条 command 可能包含多个读写请求，服务端可以将其打包成一条或多条 raft 日志。显然，打包成一条 Raft 日志的性能会更高，因为这样能够节省大量 IO 资源的消耗。当然这也需要在 apply 时对所有的 request 均做相应的业务和容错处理。</p></li><li><p>apply 时的 safety：要想实现基于 Raft 的 KV 服务，一大难点便是如何保证 applyIndex 和状态机数据的原子性。比如在 6.824 的框架中，Raft 层对于上层状态机的假设是易失的，即重启后状态机为空，那么 applyIndex 便可以不被持久化记录，因为一旦发生重启 Raft 实例可以从 0 开始重新 apply 日志，对于状态机来说这个过程保证不会重复。然而这样的实现虽然保证了 safety，但却不是一个生产可用的实现。对于 tinykv，其状态机为非易失的 LSM 引擎，一旦要记录 applyIndex 就可能出现与状态机数据不一致的原子性问题，即重启后可能会存在日志被重复 apply 到状态机的现象。为了解决这一问题，我们将每个 Index 下 entry 的应用和对应 applyIndex 的更新放到了一个事务中来保证他们之间的原子性，巧妙地解决了该过程的 safety 问题。</p></li></ul><h4 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h4><p>tinykv 的 Snapshot 几乎是一个纯异步的方案，在架构上有很多讲究，这里可以仔细阅读文档和一位社区同学分享的 <a href="https://asktug.com/t/topic/273859" target="_blank" rel="noopener">Snapshot 流程</a> 后再开始编码。</p><p>一旦了解了以下两个流程，代码便可以自然而然地写出来了。</p><ul><li>log gc 流程</li><li>snapshot 的异步生成，异步分批发送，异步分批接收和异步应用。</li></ul><h2 id="lab3"><a href="#lab3" class="headerlink" title="lab3"></a>lab3</h2><h3 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h3><h4 id="lab3a"><a href="#lab3a" class="headerlink" title="lab3a"></a>lab3a</h4><p>本部分主要涉及 Raft 算法 leader transfer 和 conf change 功能的两个工作，主要涉及修改的代码文件是 raft.go</p><p>对于 leader transfer，注意以下几点即可：</p><ul><li>leader 在 transfer 时需要阻写。</li><li>当 leader 发现 transferee 的 matchIndex 与本地的 lastIndex 相等时直接发送 timeout 请求让其快速选举即可，否则继续发送日志让其快速同步。</li><li>当 follower 收到 leader transfer 请求时，直接发起选举即可</li></ul><p>对于 conf change，注意以下几点即可：</p><ul><li>只对还在共识组配置中的 raftnode 进行 tick。</li><li>新当选的 leader 需要保证之前任期的所有 log 都被 apply 后才能进行新的 conf change 变更，这有关 raft 单步配置变更的 safety，可以参照 <a href="https://groups.google.com/g/raft-dev/c/t4xj6dJTP6E/m/d2D9LrWRza8J" target="_blank" rel="noopener">邮件</a> 和相关 <a href="https://zhuanlan.zhihu.com/p/342319702" target="_blank" rel="noopener">博客</a>。</li><li>只有当前共识组的最新配置变更日志被 apply 后才可以接收新的配置变更日志。</li><li>增删节点时需要维护 PeerTracker。</li></ul><h4 id="lab3b"><a href="#lab3b" class="headerlink" title="lab3b"></a>lab3b</h4><p>本部分主要是在 3a 的基础上，在 raft store 层面实现对 TransferLeader、ChangePeer 和 Split 三种 AdminRequest 的处理，涉及修改的文件主要是 peer_msg_handler.go 和 peer.go</p><p>对于 TransferLeader，比较简单：</p><p>TransferLeader request 因为不需要复制到 follower 节点，所以在 peer_msg_handler.go 的 pproposeRaftCommand() 方法中直接调用 raw_node.go 中的 TransferLeader() 方法即可</p><p>对于 ConfChange，分 addNode 和 removeNode 两种行为处理。</p><p>当 addNode 的命令 commit 之后，不需要我们手动调用 createPeer() 或者 maybeCreatePeer() 来显式创建 peer。我们只需要对 d.ctx 中的 storeMeta 进行修改即可，新 peer 会通过心跳机制进行创建。</p><p>当 removeNode 的命令 commit 之后，与 addNode 命令不同的是，我们需要显式调用 destroyPeer() 函数来停止相应的 raft 模块。这时需要注意的一个点时，当 Region 中只剩下两个节点，要从这两个节点中移除一个时，如果有一个节点挂了，会使整个集群不可用，特别是要移除的节点是 leader 本身。</p><p>在测试中会遇到这样的问题：当 Region 中只剩下节点 A（leader）和 节点 B（follower），当 removeNode A 的命令被 commit 之后，leader 就进行自我销毁，如果这个时候进入了 unreliable 的状态，那么 leader 就有可能无法在 destory 之前通过 heartbeat 去更新 follower 的 commitIndex。这样使得 follower B 不知道 leader A 已经被移除，就算发起选举也无法收到节点 A 的 vote，最终无法成功，导致 request timeout。</p><p>对于 split, 需要注意：</p><ol><li>因为 Region 会进行分裂，所以需要对 lab2b 进行修改，当接收到 delete/put/get/snap 等命令时，需要检查他们的 key 是否还在该 region 中，因为在 raftCmd 同步过程中，可能会发生 region 的 split，也需要检查 RegionEpoch 是否匹配。</li><li>在比较 splitKey 和当前 region 的 endKey 时，需要使用 engine_util.ExceedEndKey()，因为 key range 逻辑上是一个环。</li><li>split 时也需要对 d.ctx 中的 storeMeta 中 region 相关信息进行更新。</li><li>需要显式调用 createPeer() 来创建新 Region 中的 peer。</li><li>在 3b 的最后一个测试中，我们遇到以下问题：<ol><li>达成共识需要的时间有时候比较长，这就会导致新 region 中无法产生 leade 与 Scheduler 进行心跳交互，来更新 Scheduler 中的 regions，产生 find no region 的错误。这一部分可能需要 pre-vote 来进行根本性地解决，但时间不够，希望以后有时间解决这个遗憾。</li><li>会有一定概率遇到“多数据”的问题，经排查发现 snap response 中会包含当前 peer 的 region 引用返回，但是这时可能会产生的一个问题时，当返回时 region 是正常的，但当 client 端要根据这个 region 来读的时候，刚好有一个 split 命令改变了 region 的 startKey 或者 endKey，最后导致 client 端多读。该问题有同学在群中反馈应该测试中对 region 进行复制。</li><li>会有一定概率遇到“少数据”的问题，这是因为当 peer 未初始化时，apply snapshot 时不能删除之前的元数据和数据。</li></ol></li></ol><h4 id="lab3c"><a href="#lab3c" class="headerlink" title="lab3c"></a>lab3c</h4><p>本部分主要涉及对收集到的心跳信息进行选择性维护和对 balance-region 策略的具体实现两个工作，主要涉及修改的代码文件是 cluster.go 和 balance_region.go</p><p>对于维护心跳信息，按照以下流程执行即可：</p><ul><li>判断是否存在 epoch，若不存在则返回 err</li><li>判断是否存在对应 region，如存在则判断 epoch 是否陈旧，如陈旧则返回 err；若不存在则选择重叠的 regions，接着判断 epoch 是否陈旧。</li><li>否则维护 region 并更新 store 的 status 即可。</li></ul><p>对于 balance-region 策略的实现，按照以下步骤执行即可：</p><ul><li>获取健康的 store 列表：<ul><li>store 必须状态是 up 且最近心跳的间隔小于集群判断宕机的时间阈值。</li><li>如果列表长度小于等于 1 则不可调度，返回空即可。</li><li>按照 regionSize 对 store 大小排序。</li></ul></li><li>寻找可调度的 store：<ul><li>按照大小在所有 store 上从大到小依次寻找可以调度的 region，优先级依次是 pending，follower，leader。</li><li>如果能够获取到 region 且 region 的 peer 个数等于集群的副本数，则说明该 region 可能可以在该 store 上被调度走。</li></ul></li><li>寻找被调度的 store：<ul><li>按照大小在所有 store 上从小到达依次寻找不存在该 region 的 store。</li><li>找到后判断迁移是否有价值，即两个 store 的大小差值是否大于 region 的两倍大小，这样迁移之后其大小关系依然不会发生改变。</li></ul></li><li>如果两个 store 都能够寻找到，则在新 store 上申请一个该 region 的 peer，创建对应的 MovePeerOperator 即可。</li></ul><h3 id="相关知识学习-2"><a href="#相关知识学习-2" class="headerlink" title="相关知识学习"></a>相关知识学习</h3><h4 id="Multi-Raft"><a href="#Multi-Raft" class="headerlink" title="Multi-Raft"></a>Multi-Raft</h4><p>Multi-Raft 是分布式 KV 可以 scale out 的基石。TiKV 对每个 region 的 conf change 和 transfer leader 功能能够将 region 动态的在所有 store 上进行负载均衡，对 region 的 split 和 merge 则是能够解决单 region 热点并无用工作损耗资源的问题。不得不说，后两者尽管道理上理解起来很简单，但工程实现上有太多细节要考虑了（据说贵司写了好几年才稳定），分析可能的异常情况实在是太痛苦了，为贵司能够啃下这块硬骨头点赞。</p><p>最近看到有一个基于 TiKV 的 hackathon <a href="https://github.com/TPC-TiKV/rfc" target="_blank" rel="noopener">议题</a>，其本质是想通过更改线程模型来优化 TiKV 的写入性能、性能稳定性和自适应能力。这里可以简单提提一些想法，其实就我们在时序数据库方向的一些经验来说，每个 TSM（TimeSeries Merge Tree）大概能够用满一个核的 CPU 资源。只要我们将 TSM 引擎额个数与 CPU 核数绑定，写入性能基本是能够随着核数增加而线性提升的。那么对于 KV 场景，是否开启 CPU 个数的 LSM 引擎能够更好的利用 CPU 资源呢？即对于 raftstore，是否启动 CPU 个数的 Rocksdb 实例能够更好的利用资源呢？感觉这里也可以做做测试尝试一下。</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>负载均衡是分布式系统中的一大难题，不同系统均有不同的策略实现，不同的策略可能在不同的 workload 中更有效。</p><p>相比 pd 的实现，我们在 lab3c 实现的策略实际上很 trivial，因此我们简单学习了 pd 调度 region 的 <a href="https://asktug.com/t/topic/242808" target="_blank" rel="noopener">策略</a>。尽管这些策略道理上理解起来都比较简单，但如何将所有统计信息准确的量化成一个动态模型却是一件很难尽善尽美的事，这中间的很多指标也只能是经验值，没有严谨的依据。</p><p>有关负载均衡我们对学术界的相关工作还不够了解，之后有时间会进行一些关注。</p><h2 id="lab4"><a href="#lab4" class="headerlink" title="lab4"></a>lab4</h2><h3 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h3><p>本 Lab 整体相对简单，在基本了解 MVCC, 2PC 和 Percolator 后便可动手了，面向测试用例编程即可。</p><h4 id="lab4a"><a href="#lab4a" class="headerlink" title="lab4a"></a>lab4a</h4><p>本部分是对 mvcc 模块的实现，主要涉及修改的代码文件是 transaction.go。需要利用对 CFLock, CFDefault 和 CFWrite 三个 CF 的一些操作来实现 mvcc。</p><p>针对 Lock 相关的函数：</p><ul><li>PutLock：将 PUT <key, lock.tobytes()> 添加到 Modify 即可。</key,></li><li>DeleteLock：将 Delete <key> 添加到 Modify 即可。</key></li><li>GetLock：在 CFLock 中查找即可。</li></ul><p>针对 Value 相关的函数：</p><ul><li>PutValue：将 PUT <EncodeKey(key, txn.startts), value> 添加到 Modify 即可。</EncodeKey(key,></li><li>DeleteValue：将 Delete <EncodeKey(key, txn.startts)> 添加到 Modify 即可。</EncodeKey(key,></li><li>GetValue：首先从 CFWrite 中寻找在当前快照之前已经提交的版本。如果未找到则返回空，如果找到则正对不同的 Kind 有不同的行为：<ul><li>Put：根据 value 中的 StartTS 去 CFDefault 寻找即可。</li><li>Delete：返回空即可。</li><li>Rollback：继续寻找之前的版本。</li></ul></li></ul><p>针对 Write 相关的函数：</p><ul><li>PutWrite：将 PUT <EncodeKey(key, committs), write.tobytes()> 添加到 Modify 即可。</EncodeKey(key,></li><li>CurrentWrite：从 CFWrite 当中寻找当前 key 对应且值的 StartTS 与当前事务 StartTS 相同的行。</li><li>MostRecentWrite：从 CFWrite 当中寻找当前 key 对应且值的 StartTS 最大的行。</li></ul><h4 id="lab4b"><a href="#lab4b" class="headerlink" title="lab4b"></a>lab4b</h4><p>本部分是对 Percolator 算法 KVPreWrite, KVCommit 和 KVGet 三个方法的实现，主要涉及修改的代码文件是 server.go, query.go 和 nonquery.go。</p><ul><li>KVPreWrite：针对每个 key，首先检验是否存在写写冲突，再检查是否存在行锁，如存在则需要根据所属事务是否一致来决定是否返回 KeyError，最后将 key 添加到 CFDefault 和 CFLock 即可。</li><li>KVCommit：针对每个 key，首先检查是否存在行锁，如不存在则已经 commit 或 rollback，如存在则需要根据 CFWrite 中的当前事务状态来判断是否返回 KeyError，最后将 key 添加到 CFWrite 中并在 CFLock 中删除即可。</li><li>KVGet：首先检查行锁，如为当前事务所锁，则返回 Error，否则调用 mvcc 模块的 GetValue 获得快照读即可。</li></ul><h4 id="lab4c"><a href="#lab4c" class="headerlink" title="lab4c"></a>lab4c</h4><p>本部分是对 Percolator 算法 KvCheckTxnStatus, KvBatchRollback, KvResolveLock 和 KvScan 四个方法的实现，主要涉及修改的代码文件是 server.go, query.go 和 nonquery.go。</p><ul><li>KvCheckTxnStatus：检查 PrimaryLock 的行锁，如果存在且被当前事务锁定，则根据 ttl 时间判断是否过期从而做出相应的动作；否则锁很已被 rollback 或者 commit，从 CFWrite 中获取相关信息即可。</li><li>KvBatchRollback：针对每个 key，首先检查是否存在行锁，如果存在则删除 key 在 CFLock 和 CFValue 中的数并且在 CFWrite 中写入一条 rollback 即可。如果不存在或者不归当前事务锁定，则从 CFWrite 中获取当前事务的提交信息，如果不存在则向 CFWrite 写入一条 rollback，如果存在则根据是否为 rollback 判断是否返回错误。</li><li>KvResolveLock：针对每个 key，根据请求中的参数决定来 commit 或者 rollback 即可。</li><li>KvScan：利用 Scanner 扫描到没有 key 或达到 limit 阈值即可。针对 scanner，需要注意不能读有锁的 key，不能读未来的版本，不能读已删除或者已 rollback 的 key。</li></ul><h4 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h4><p>为了使得 server.go 逻辑代码清晰，在分别完成三个 lab 后对代码进行了进一步整理，针对读写请求分别抽象出来了接口，这样可以使得逻辑更为清晰。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Go"><span class="hljs-keyword">type</span> BaseCommand <span class="hljs-keyword">interface</span> &#123;<br>Context() *kvrpcpb.Context<br>StartTs() <span class="hljs-keyword">uint64</span><br>&#125;<br><br><span class="hljs-keyword">type</span> Base <span class="hljs-keyword">struct</span> &#123;<br>context *kvrpcpb.Context<br>startTs <span class="hljs-keyword">uint64</span><br>&#125;<br><br><span class="hljs-keyword">type</span> QueryCommand <span class="hljs-keyword">interface</span> &#123;<br>BaseCommand<br>Read(txn *mvcc.MvccTxn) (<span class="hljs-keyword">interface</span>&#123;&#125;, error)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExecuteQuery</span><span class="hljs-params">(cmd QueryCommand, storage storage.Storage)</span> <span class="hljs-params">(<span class="hljs-keyword">interface</span>&#123;&#125;, error)</span></span> &#123;<br>ctx := cmd.Context()<br>reader, err := storage.Reader(ctx)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> &amp;kvrpcpb.ScanResponse&#123;RegionError: util.RaftstoreErrToPbError(err)&#125;, <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">defer</span> reader.Close()<br><span class="hljs-keyword">return</span> cmd.Read(mvcc.NewMvccTxn(reader, cmd.StartTs()))<br>&#125;<br><br><span class="hljs-keyword">type</span> NonQueryCommand <span class="hljs-keyword">interface</span> &#123;<br>BaseCommand<br>IsEmpty() <span class="hljs-keyword">bool</span><br>GetEmptyResponse() <span class="hljs-keyword">interface</span>&#123;&#125;<br>WriteKeys(txn *mvcc.MvccTxn) ([][]<span class="hljs-keyword">byte</span>, error)<br>Write(txn *mvcc.MvccTxn) (<span class="hljs-keyword">interface</span>&#123;&#125;, error)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExecuteNonQuery</span><span class="hljs-params">(cmd NonQueryCommand, storage storage.Storage, latches *latches.Latches)</span> <span class="hljs-params">(<span class="hljs-keyword">interface</span>&#123;&#125;, error)</span></span> &#123;<br><span class="hljs-keyword">if</span> cmd.IsEmpty() &#123;<br><span class="hljs-keyword">return</span> cmd.GetEmptyResponse(), <span class="hljs-literal">nil</span><br>&#125;<br><br>ctx := cmd.Context()<br>reader, err := storage.Reader(ctx)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> &amp;kvrpcpb.ScanResponse&#123;RegionError: util.RaftstoreErrToPbError(err)&#125;, <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">defer</span> reader.Close()<br>txn := mvcc.NewMvccTxn(reader, cmd.StartTs())<br><br>keys, err := cmd.WriteKeys(txn)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><br>latches.WaitForLatches(keys)<br><span class="hljs-keyword">defer</span> latches.ReleaseLatches(keys)<br><br>response, err := cmd.Write(txn)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><br>err = storage.Write(ctx, txn.Writes())<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><br>latches.Validation(txn, keys)<br><br><span class="hljs-keyword">return</span> response, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="相关知识学习-3"><a href="#相关知识学习-3" class="headerlink" title="相关知识学习"></a>相关知识学习</h3><p>有关分布式事务，我们之前有过简单的 <a href="https://tanxinyu.work/distributed-transactions/">学习</a>，对 2PL, 2PC 均有简单的了解，因此此次在实现 Percolator 时只需要关注 2PC 与 MVCC 的结合即可，这里重点参考了以下博客：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/77846678" target="_blank" rel="noopener">TiKV 源码解析系列文章（十二）分布式事务</a></li><li><a href="https://pingcap.com/zh/blog/tidb-transaction-model" target="_blank" rel="noopener">TiKV 事务模型概览，Google Spanner 开源实现</a></li><li><a href="http://mysql.taobao.org/monthly/2018/11/02/" target="_blank" rel="noopener">Google Percolator 分布式事务实现原理解读</a></li><li><a href="https://pingcap.com/zh/blog/async-commit-principle" target="_blank" rel="noopener">Async Commit 原理介绍</a></li></ul><p>实现完后，我们进一步被 Google 的聪明所折服，Percolator 基于单行事务实现了多行事务，基于 MVCC 实现了 SI 隔离级别。尽管其事务恢复流程相对复杂，但其本质上是在 CAP 定理中通过牺牲恢复时的 A 来优化了协调者正常写入时的 A，即协调者单点在 SQL 层不用高可用来保证最终执行 commit 或者 abort。因为一旦协调者节点挂掉，该事务在超过 TTL （TTL 的超时也是由 TSO 的时间戳来判断，对于各个 TiKV 节点来说均为逻辑时钟，这样的设计也避免了 Wall Clock 的同步难题）后会被其他事务 rollback，总体上来看 Percolator 比较优雅的解决了 2PC 的 safety 问题。</p><p>当然，分布式事务可以深究的地方还很多，并且很多思想都与 Lamport 那篇最著名的论文 <a href="https://tanxinyu.work/time-clock-order-in-distributed-system-thesis/"><code>Time, Clocks, and the Ordering of Events in a Distributed System</code></a> 有关。除了 TiDB 外，Spanner，YugaByte，CockroachDB 等 NewSQL 数据库均有自己的大杀器，比如 TrueTime，HLC 等等。总之这块儿挺有意思的，虽然在这儿告一段落，但希望以后有机会能深入做一些相关工作。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>实现一个稳定的分布式系统实在是太有挑战太有意思啦。</p><p>感谢 PingCAP 社区提供如此优秀的课程！</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>分布式存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一届九坤并行程序优化大赛总结</title>
    <link href="/jiu-kun-parallel-program-optimization-contest/"/>
    <url>/jiu-kun-parallel-program-optimization-contest/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>2021 年 9 月，量化头部公司<strong>九坤</strong>举办了其第一届<strong>并行程序优化大赛</strong>，相关介绍可参考 <a href="https://mp.weixin.qq.com/s/iaurj-1191SahJZ9uSk7RA" target="_blank" rel="noopener">推送</a>。赛题如下：</p><p><img src="/jiu-kun-parallel-program-optimization-contest/title.png" srcset="/img/loading.gif" lazyload alt></p><p>赛题是 C/C++ 的 codebase，然而我与一起组队的两位同学基本都对 C/C++ 不太熟悉，于是我们起名叫做了”只会 JAVA 队”。作为三个在体系结构几乎一窍不通的小白，在一个多月断断续续的不到 10 次线下沟通中，我们逐渐对体系结构入了门，在 192 个队伍脱颖而出，并在决赛取得了第 4 名的成绩（PS：离苹果周边只差一步真的好可惜），具体可以参考 <a href="https://mp.weixin.qq.com/s/Ct3XwD6zR_qNpvqLbQPs4Q" target="_blank" rel="noopener">总结推送</a>。</p><p><img src="/jiu-kun-parallel-program-optimization-contest/result.jpeg" srcset="/img/loading.gif" lazyload alt></p><p>这里简单做一总结，贴一些当前的资料和想法，以备之后回忆和反思。</p><h2 id="赛题"><a href="#赛题" class="headerlink" title="赛题"></a>赛题</h2><h3 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h3><p>在深度学习中，卷积操作在神经网络中扮演了重要的作用。2015 年，Andrew Lavin 等人提出了快速计算卷积的算法 Winograd，通过降低计算复杂度，相比直接卷积的算法提升 4 倍效率，成为了深度学习中非常重要的一个算法。本次比赛的第一题就是优化 Winograd 算法。各参赛队的通过优化比赛方给出的 Winograd 算法代码，缩短其运行时间，提升该算法时间的每秒浮点计算次数（FLOPS）。</p><h3 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h3><p>金融数据是真正的“大数据”。每天市场上的交易会产生海量的数据，这些数据对于预测未来市场走势只非常重要。因此负责高速储存、读取这些数据的 IO 系统成为了行业内重要的一环。目前金融数据中常用 HDF5 文件系统库进行大规模的数据存储。本次比赛第二题要求各参赛队探索 HDF5 文件系统，通过一个跑分程序 h5bench 来完成 IO 系统的性能研究和调优。</p><h2 id="代码-amp-文档"><a href="#代码-amp-文档" class="headerlink" title="代码 &amp; 文档"></a>代码 &amp; 文档</h2><p>从赛题可以看到，此两题能够检验选手最大化压榨 CPU 和 IO 性能的能力。</p><p>有关赛题的代码和文档均已开源，可移步 <a href="https://github.com/Sunny-Island/winograd-onlyJava" target="_blank" rel="noopener">此处</a> 查看。欢迎交流~</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>就 CPU 题目而言，我们此次尝试了以下优化和工具：</p><ul><li>算法优化：winograd4x3-3D</li><li>指令级并行：循环展开，分支预测</li><li>数据级并行：AVX128，256，512</li><li>线程级并行：OPENMP</li><li>编译器：尝试 gcc 不同版本，对比 llvm</li><li>内存排布：36*STRIDE</li><li>冒险尝试：merge_array</li><li>Profiling：perf</li></ul><p>其实这里有好多思想都已经在数据库领域存在了。比如向量化引擎，比如 codegen 的 llvm 优化，比如对 cache 友好的 push 查询引擎等等。</p><p>个人认为，数据库做到极致便是对硬件性能的一种体现。因此，一个优秀的数据库工程师应该对体系结构具有一定的了解，这样才有可能进一步压榨硬件性能，从而达到更好的数据库性能。</p><p>一直以来，我希望分布式数据库能够成为自己的一个标签。通过这次比赛，我意识到高性能计算也是一个很有趣且硬核的方向，其不仅能够给企业迅速带来真金白银的收益（节约成本），而且也是很多领域做到极致的一种出路。</p><p>希望未来还能有契机去进一步深挖此方向吧。</p>]]></content>
    
    
    
    <tags>
      
      <tag>高性能计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021 中科院开源之夏总结</title>
    <link href="/2021-summer-of-code/"/>
    <url>/2021-summer-of-code/</url>
    
    <content type="html"><![CDATA[<p>2021 年暑假，我参与了中科院组织的开源之夏活动，题目为 《Apache IoTDB 分布式混沌测试框架》。</p><p>有关该项目的详细信息可以查看该 <a href="https://gitlab.summer-ospp.ac.cn/summer2021/210070607" target="_blank" rel="noopener">文档</a>。</p><p>从结果来看，这份工作发现了 Apache IoTDB 当前分布式版本存在的很多问题，有一些容易解决的问题已经得到了修复，然而也有一些较复杂的问题到今天依然存在，这也多多少少间接引起了我们的一次大规模重构，勉强算是一件有意义的工作吧。</p><p>令人略感遗憾的是，尽管该混沌测试框架在部署好之后可以用 Dashboard 的方式方便地注入特定的异常，然而正如项目文档中所说的，该框架依然是基于物理节点来实现的，很难做到自动化。</p><p><strong>如果没有测试人员去维护并定期手动测试，如果没有开发人员愿意抽出时间来完全解决其中发现的问题，如果整个团队没有足够重视异常场景下系统的对外表现并愿意为之付出大量的精力，该框架就很难形成正向反馈，最终只能被遗忘在历史的角落里。</strong></p><p>作为一点反省，我现在觉得混沌测试还是应该尽可能的通过持续集成的方式自动化起来（参照 ChaosMesh），这样释放人力的方式是大家都喜爱的，也只有这样，混沌测试才能对项目产生持续的正向收益。</p><p>随意写点儿感想，仅做记录。</p>]]></content>
    
    
    
    <tags>
      
      <tag>测试</tag>
      
      <tag>IoTDB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>15-445 数据库课程学习总结</title>
    <link href="/15-445/"/>
    <url>/15-445/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>众所周知，CMU 15-445/721 是数据库的入门神课，类似于 MIT 6.824 之于分布式系统一样。由于前半年学习了 MIT 6.824 课程后感觉个人收获很大，因此在今年暑假，我抽时间学习完了 CMU 15-445 的网课，现做一概要总结。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>15-445 可以当做数据库的入门课程，授课老师是著名网红教授 <a href="http://www.cs.cmu.edu/~pavlo/" target="_blank" rel="noopener">Andy Pavlo</a>，以下是他的 Google Scholar 主页，还是非常厉害的。<br><img src="/15-445/pavlo.png" srcset="/img/loading.gif" lazyload alt></p><p>本课程的组织方式采用了自底向上的方式，分别介绍了文件管理，缓冲池管理，索引管理，执行管理，查询优化，并发控制和容错恢复等内容，基本讲述了如何从 0 实现一个单机关系型数据库。由于时间有限，没来得及做课程笔记。因此在参考资料部分列出了课程所有的 PPT 资料以及一些从网上找到的优质课程笔记，以备日后温习之用。</p><p><img src="/15-445/outline.png" srcset="/img/loading.gif" lazyload alt></p><p>当然，由于课程内容涉及的范围很广，所以每个章节都只是进行了相对简单的介绍。要想了解更多细节，建议结合大黑砖《数据库系统概念》来学习。2021 年 6 月，最新第七版的中文译版已经发行，赶紧买一本镇脑吧！</p><p><img src="/15-445/database.jpeg" srcset="/img/loading.gif" lazyload alt></p><p>对于其作业 <a href="https://github.com/cmu-db/bustub" target="_blank" rel="noopener">bustub</a>，由于其需要基于 C++17 实现，而本人在目前没有太多的 C++ 知识储备，所以就暂时搁置了，毕竟想学的是数据库而不是 C++。不过我也注意到，MIT 6.830 数据库课程的作业 <a href="https://github.com/MIT-DB-Class/simple-db-hw-2021" target="_blank" rel="noopener">simple-db</a> 是基于 Java 的，且其 6 个 lab 的内容基本覆盖了 CMU 15-445 lab 的内容，所以刷一刷 MIT 6.830 的 lab 也挺有意义的，希望自己后半年能抽出些时间吧。</p><p>此外，简单看了一下 15-721 的 <a href="https://15721.courses.cs.cmu.edu/spring2020/schedule.html" target="_blank" rel="noopener">课程主页</a>，感觉其更多的是在讲 research 方向的工作，基本是在讲各个方向的 sota，那么这门课可以等到工作之后再说吧，目前来看优先级不是很高。</p><p><img src="/15-445/15-721.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://15445.courses.cs.cmu.edu/fall2019/schedule.html" target="_blank" rel="noopener">官网资料</a></li><li><a href="https://www.bilibili.com/video/BV1rN411f7Ef" target="_blank" rel="noopener">网课视频</a></li><li><a href="https://zhenghe.gitbook.io/open-courses/cmu-15-445-645-database-systems/relational-data-model" target="_blank" rel="noopener">课程笔记 1</a></li><li><a href="https://www.jianshu.com/nb/36265841" target="_blank" rel="noopener">课程笔记 2</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>数据库</tag>
      
      <tag>网红课</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Awesome 学习资料分享</title>
    <link href="/awesome-blog/"/>
    <url>/awesome-blog/</url>
    
    <content type="html"><![CDATA[<p>计划长期维护一个自己学习过且觉得不错的资料列表，希望自己不断更新：</p><ul><li><a href="https://github.com/fuzhengwei/itstack-demo-design" target="_blank" rel="noopener">重学 Java 设计模式</a></li><li><a href="https://icyfenix.cn/introduction/about-the-fenix-project.html" target="_blank" rel="noopener">什么是“凤凰架构”</a></li><li><a href="https://www.kancloud.cn/kancloud/a-programmer-prepares/78160" target="_blank" rel="noopener">程序员的自我修养</a></li><li><a href="https://draveness.me/" target="_blank" rel="noopener">为什么系列</a></li><li><a href="https://github.com/Vonng/ddia" target="_blank" rel="noopener">DDIA</a></li><li><a href="https://netsecurity.51cto.com/art/202005/616765.htm" target="_blank" rel="noopener">线上故障排查全套路</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>开源</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>6.824 分布式系统课程学习总结</title>
    <link href="/6-824/"/>
    <url>/6-824/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab"><a href="#Lab" class="headerlink" title="Lab"></a>Lab</h2><p>2021 年 6 月 30 日，本人总算刷完了 6.824 的 lab 并整理完了文档，发篇博客庆祝一下！！！</p><p>目前能够稳定通过 6.824 lab 所有的测试，并尽可能的提升了代码可读性。</p><p>不保证绝对的 bug-free，但每个 lab 均测试 500 次以上，无一 fail。</p><p>为了遵守课程代码开放协议，只开源了文档，具体可参考 <a href="https://github.com/OneSizeFitsQuorum/MIT6.824-2021" target="_blank" rel="noopener">repo</a>。</p><p>配合 <a href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn" target="_blank" rel="noopener">raft 博士论文翻译</a> 和 <a href="https://tanxinyu.work/raft/">raft 算法介绍</a> 阅读效果更佳。</p><p>如有收获，希望点个 star 以表支持。十分感谢！</p><h2 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h2><p>基本上每篇论文都结合课程内容做了对应的论文阅读笔记。链接如下：</p><ul><li><a href="https://tanxinyu.work/mapreduce-thesis/">MapReduce</a></li><li><a href="https://tanxinyu.work/gfs-thesis/">GFS</a></li><li><a href="https://tanxinyu.work/vm-ft-thesis/">VM-FT</a></li><li><a href="https://tanxinyu.work/raft/">Raft</a></li><li><a href="https://tanxinyu.work/zookeeper-thesis/">Zookeeper</a></li><li><a href="https://tanxinyu.work/chain-replication-thesis/">Chain-Replication</a></li><li><a href="https://tanxinyu.work/aurora-thesis/">Aurora</a></li><li><a href="https://tanxinyu.work/frangipani-thesis/">Frangipani</a></li><li><a href="https://tanxinyu.work/spanner-thesis/">Spanner</a></li><li><a href="https://tanxinyu.work/farm-thesis/">Farm</a></li><li><a href="https://tanxinyu.work/spark-thesis/">Spark</a></li><li><a href="https://tanxinyu.work/scaling-memcached-thesis/">Memcached-in-Facebook</a></li><li><a href="https://tanxinyu.work/cops-thesis/">COPS</a></li><li><a href="https://tanxinyu.work/bitcoin/">BitCoin</a></li></ul><p>由于时间有限，以上博客中参考了大量其他优质博客，本人在此对于这些博客的作者表示真诚的感谢。</p>]]></content>
    
    
    
    <tags>
      
      <tag>网红课</tag>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>分布式存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>COPS 论文阅读</title>
    <link href="/cops-thesis/"/>
    <url>/cops-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>考虑这么一个问题：对于大型网站的异地复制，公司存在多个数据中心，每个数据中心拥有全量数据，读均为本地读。那么写应该怎么实现？一致性应该如何取舍？</p><p>对于以上背景，Spanner 和 Facebook/Memcached 已经给出了他们自己的解决方案：</p><ul><li>Spanner： <ul><li>线性一致性。</li><li>通过 Paxos 和 2PC 实现分布式写事务。</li><li>写入需要等待 quorum 的数据中心返回 ack，性能较低。</li><li>读取从本地数据中心读，可能需要等待，性能较高。</li></ul></li><li>Facebook/Memcached：<ul><li>最终一致性。</li><li>写入需要主数据中心返回 ack，性能一般。</li><li>读取从本地数据中心的缓存中读，性能极快。</li></ul></li></ul><p>基于以上背景，本论文在性能和一致性之间找出了一个 trade-off，给出了一种中间状态的一致性：因果一致性，其相比线性一致性更弱但相比最终一致性更强。因此，其性能也会处于中间的状态。</p><p>有关因果一致性的定义，建议先阅读此 <a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261809&amp;idx=1&amp;sn=cff64fe049a8a04ae719b34e7bf57dd1&amp;chksm=84479128b330183e55e911bacd611c22541f734a8df0c22a7bbe73323baedf6e506a12e8d2ac&amp;scene=178&amp;cur_album_id=1550842358601187329#rd" target="_blank" rel="noopener">博客</a>。</p><p>以下简单介绍其实现。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>COPS（订单保留服务器集群）是一种地理复制的键值存储系统，可保证因果一致性。它包含两个软件组件：客户端库和键值存储。</p><p>涉及的每个数据中心都有一个本地 COPS 集群，该集群维护其整个数据集的副本。COPS 客户端是使用客户端库与键值存储交互的应用程序。客户端仅与在同一数据中心运行的本地 COPS 集群交互。</p><p>COPS 跨集群中的节点对存储的数据进行分片，每个键属于每个集群中的一个主节点。此主节点接收键的写入。写入完成后，本地集群中的主节点将其复制到其他集群中的主节点。</p><p>每个键也有版本，代表该键的不同值。COPS 保证一旦副本返回了密钥的版本，副本将只返回该版本或后续请求中的因果更新版本。</p><h3 id="定义因果关系"><a href="#定义因果关系" class="headerlink" title="定义因果关系"></a>定义因果关系</h3><p>更正式地，该论文提到了作者用来定义操作之间潜在因果关系的三个规则，表示为-&gt;：</p><ul><li>执行线程：如果 a 和 b 是单个执行线程中的两个操作，则 a -&gt; b 如果操作 a 在操作 b 之前发生。</li><li>从获取：如果 a 是 put 操作，b 是 get 操作，返回 a 写入的值，则 a -&gt; b。</li><li>传递性：对于操作 a、b 和 c，如果 a -&gt;b 和 b -&gt; c，则 a -&gt; c</li></ul><p>图 2 中的执行说明了这些规则。</p><p><img src="/cops-thesis/causal.png" srcset="/img/loading.gif" lazyload alt></p><p>此外，因果一致性不排序并发操作。如果我们不能判断一个操作在另一个之前发生，我们就说两个操作是并发的。一个系统可以以任何顺序复制两个不相关的 put 操作，但是当 put 对同一个键有并发操作时，我们说它们是冲突的。</p><p>对于某些并发场景，<code>最后写入者胜</code>的规则能够保证集群对某一个值最终达成共识。然而应对某些<code>冲突写入</code>的场景，类似于 append 函数，原子计数器等场景，都需要更细致的考虑。</p><h3 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h3><p>每个客户端维护一个上下文来表示其操作的顺序。将此上下文视为包含项目的列表。每次操作后，客户端都会向其上下文中添加一个项目。这些项目在列表中的顺序捕获了版本之间的依赖关系。使用此上下文，客户端可以计算版本的依赖关系。</p><h3 id="LP-提供全局顺序"><a href="#LP-提供全局顺序" class="headerlink" title="LP 提供全局顺序"></a>LP 提供全局顺序</h3><p>使用 <code>Lamport Timestamp in higher bits + unique ID For Data Center in lower bits</code> 来支持所有操作的全序顺序。</p><p>通过结合逻辑时钟和 Wall Clock，即使不同数据中心的时间有较大误差，我们依然可以为所有操作给出一个全序排序。</p><p>时钟实现如下所示：</p><figure class="highlight pf"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs pf">T<span class="hljs-keyword">max</span> = highest version seen (<span class="hljs-keyword">from</span> <span class="hljs-literal">self</span> and others)<br>T = <span class="hljs-keyword">max</span>(T<span class="hljs-keyword">max</span> + <span class="hljs-number">1</span>, wall-clock time)<br></code></pre></div></td></tr></table></figure><h3 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h3><p>当客户端调用 put key 时，库会根据其上下文计算该 key 的依赖关系，并将该信息发送到本地主存储节点。在 COPS 集群写入所有计算的依赖项之前，此存储节点不会提交密钥的值。提交该值后，主存储节点使用 Lamport 时间戳为其分配一个唯一的版本号，并立即将该编号返回给客户端。通过不等待复制完成，COPS 消除了具有更强一致性保证的系统产生的大部分延迟。</p><p>主存储节点在本地提交写入后，将写入异步复制到其他集群。节点在复制它时包含有关写入依赖项的信息。当另一个集群中的节点收到此写入时，该节点会检查其集群中的本地节点是否满足所有依赖项。接收节点通过向负责这些依赖关系的本地节点发出依赖关系检查请求来做到这一点。如果本地节点没有写入依赖值，它会阻塞请求，直到写入该值。否则，它会立即响应。</p><p>总之，COPS 通过计算写入的依赖关系来保证因果一致性，并且在集群提交所有依赖关系之前不会在集群中提交写入。</p><h3 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h3><p>COPS 也满足本地集群中的读取。COPS 客户端可以指定他们是要读取密钥的最新版本还是特定的旧版本。当客户端库接收的读取响应，它增加了操作的情况下捕捉到潜在的因果关系。</p><h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><p>虽然因果一致性是一个流行的研究思想，但它有一些局限性。两个主要是：</p><ul><li>它无法捕获外部因果依赖性。一个典型的例子是一个电话：如果我做动作 A，打电话给我在另一个大陆的朋友告诉她关于 A 的事情，然后她做了动作 B，系统将无法捕捉到 A 和 B 之间的因果关系。针对此问题，Lamport 早已经给出了答案：只能通过强同步的物理时钟来实现，具体可以参考本人另一篇 <a href="https://tanxinyu.work/time-clock-order-in-distributed-system-thesis/">博客</a>。</li><li>管理冲突可能很困难，尤其是当<code>最后写入者胜</code>规则不够用时。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单学习一下因果一致性，虽然讲义中提到它在实际系统中应用不多，但个人感觉这是一个很有意义的方向。在未来，对于不追求数据线性一致性的场景，很可能跨数据中心的同步范式都会参考因果一致性而不是最终一致性。虽然牺牲了一点性能，但前者相比后者保证了一定程度的 safety，这是非常可贵的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-cops.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/17.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/cops.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://timilearning.com/posts/mit-6.824/lecture-17-cops/#lamport-timestamps-provide-a-global-order" target="_blank" rel="noopener">MIT 6.824: Lecture 17 - Causal Consistency, COPS</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Facebook 的 Memcached 系统扩展论文阅读</title>
    <link href="/scaling-memcached-thesis/"/>
    <url>/scaling-memcached-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本篇论文由 Facebook 2013 年在 NSDI 上发表，其系统地介绍了 Facebook 公司内部对于大规模缓存系统的使用实践。</p><p>这篇论文没有太多新的想法，但却传达了一个很重要的理念：不同的场景有不同的系统需求。在成本有限的情况下，并不一定线性一致性就是最好的，对于有些场景，最终一致性带来的收益远超我们的想像。</p><p>对于大部分 2C 应用，随着用户数量的逐渐增加，其后台数据存储系统大致是如此的进化路线：</p><ol><li><strong>单机 Web 服务器 + 单机数据库（MySQL / Oracle）</strong>： 随着负载增加，单机 Web 服务器逐渐占满了 CPU，需要横向扩展。</li><li><strong>多台无状态 Web 服务器 + 共享的单机数据库（MySQL / Oracle）</strong>：无状态的 Web 服务器可以横向扩展以获得更高的吞吐量。随着负载进一步增加，单机数据库成为了瓶颈。</li><li><strong>多台无状态 Web 服务器 + 关系数据库集群（分库分表 / NewSQL 数据库）</strong>： 横向扩展了关系数据库的性能，这里可以参考分库分表或者一些 NewSQL 产品。对于前者，跨分区的事务会是一个痛点。此外，这类应用的业务场景一般情况下都是读多写少的场景。对于写性能，只能通过横向扩展数据库的方式来解决。对于读性能，除了横向扩展数据库，还可以加一层缓存层以提升系统的吞吐量，同时也减少数据库的负载。</li><li><strong>多台无状态 Web 服务器 + 用于读加速的分布式缓存系统（Redis / Memcached） + 关系数据库集群（分库分表 / NewSQL 数据库）</strong>：此时对于读写性能基本都能够扩展，关系数据库中的数据也可以通过 CDC 同步到下游去做离线或近实时计算。此时需要进一步关注的便是缓存系统的一致性。</li></ol><p>脸书在 2013 年就已经进化到了第四个阶段，以下会简单介绍其架构：</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Facebook 的架构包括多个 web、memcached 和数据库服务器。一组 web 和 memcached 服务器组成一个前端集群，多个前端集群组成一个数据中心。这些数据中心在论文中称为 region 。一个 regions 内的前端集群共享同一个存储集群。Facebook 在全球不同地区复制集群，将一个 region 指定为主 region，将其他 region 指定为次要 region。</p><p>其架构图如下：</p><p><img src="/scaling-memcached-thesis/architecture.png" srcset="/img/loading.gif" lazyload alt></p><p>对于脸书的场景，其数据一般都是用户信息，好友信息，帖子信息，喜欢信息，照片信息等等。这些消息主要有两个特点：</p><ul><li>用户能够容忍适度的旧数据，但不能容忍非常旧的数据。</li><li>用户想要能够读自己所写。</li></ul><p>基于以上特点，Facebook 使用了 memcached 来减少其数据库的读取负载。Facebook 的工作负载以读取为主，而 memcached 可防止它们为每个请求访问数据库。他们使用 memcached 作为后备缓存。这意味着当 Web 服务器需要数据时，它首先尝试从缓存中获取数据。如果该值不在缓存中，Web 服务器将从数据库中获取数据，然后用数据填充缓存。</p><p>对于写入，Web 服务器会将键的新值发送到数据库，然后向缓存发送另一个请求以删除键。对该键的后续读取将从数据库中获取最新数据。</p><p>流程如下图所示：<br><img src="/scaling-memcached-thesis/cache.png" srcset="/img/loading.gif" lazyload alt></p><p>至于为什么在写数据库成功时要删除缓存系统中的 key 而不是 set 进去当前写入成功 key 的 value，大致原因是为了降低并发写入时出现 stale read 的概率，从而进一步满足用户读自己所写的需求。</p><p>需要注意的是，即使使用了 delete 的方案，还是不能完全避免 stale read 的可能性。归根原因，是因为在 db 处的更新和在 cache 处的更新很难保证原子性，我们只能尽量减少其不一致的概率而很难完全避免它。因此，对于每个 key 都设置合理的 TTL 时间和缓存过期策略也十分重要，这其实相当于给系统不一致的阈值定了一个上限，从而保证了最终一致性。这一点本论文没有介绍，但 Twitter 的内存缓存系统有介绍，可以参考本人另一篇 <a href="https://tanxinyu.work/twitter-cache-analysis-thesis/">阅读博客</a>。</p><p>对于如何保证数据库和缓存的一致性，该 <a href="https://mp.weixin.qq.com/s/Ii0b6ORmsxjmXsVRnhG5eA" target="_blank" rel="noopener">博客</a> 有一些有趣的思考。</p><p>对于缓存穿透，缓存击穿，缓存雪崩，可以简单看看 <a href="https://mp.weixin.qq.com/s/e9NqNZD5_kjf6nfzFtSY3w" target="_blank" rel="noopener">八股文</a>。</p><p>此外，缓存系统一般由两种并行处理策略：</p><ul><li>分片<ul><li>节省内存：每个 key 一个副本。</li><li>可横向扩展：流量均匀时能够均匀的利用所有节点的资源。</li><li>更多的长连接：客户端节点需要与很多节点建立连接。</li></ul></li><li>复制<ul><li>浪费内存：每个 key 多个副本。</li><li>对 Hot Key 友好：分片对 Hot Key 无帮助，而复制可以提升 Hot Key 的吞吐量。 </li><li>更少的长连接：一个节点上可能有多个分片的副本。</li></ul></li></ul><p>根据情况可以做取舍，一般分片和复制都是需要做的。</p><p>对于 Facebook，其存在两个全量异步复制的 region ，这一定程度上保证了跨 region 的容错，同时也减少了不同地域用户的读延迟。</p><p>在每个 region 内部，其首先将数据库在数据库层做了分片以支持高性能的横向扩展，接着其利用多个缓存集群缓存了相同的 Hot Key 来共享负载，同时其也单独将不那么 hot 的 key 放到一个默认缓存集群中以减少缓存成本。</p><p>对于工业界系统，Facebook 还仔细设计了网络协议（UDP 读，TCP 写），流量控制，网络布局，缓存集群冷启动，缓存节点宕机等实际情况。感兴趣的可以关注其论文，此处不再赘述。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单介绍了 Facebook 使用 Memcached 的实践。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-memcached.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/16.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/memcache-fb.pdf" target="_blank" rel="noopener">论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bitcoin 论文阅读</title>
    <link href="/bitcoin/"/>
    <url>/bitcoin/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>2008 年，中本聪设计出了比特币和区块链。在今天，区块链成为了热门的技术，其通过分布式账本技术和共识机制，构建了低成本互信机制。</p><p>区块链三个根本特性是去中心化、实现点对点的价值传递和低成本信任机制。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>区块链是一个划时代的技术，其使得我们能够不假装相信一个中央机构而实现可信的交易。</p><p>下面简单讨论一下一些设计要点：</p><p>首先，在公网的 P2P 系统中，我们必须设计出支持拜占庭容错的共识算法。相比 Raft 等非拜占庭容错的共识算法，区块链算法本质上利用了真实物理硬件的工作量证明 POF(Proof of Work) 而非可以随意捏造的 IP，域名等信息来标识节点从而解决女巫问题，其可以保证：只要网络中的大多数节点是无恶意的，恶意的节点就无法干被大家都承认的坏事。</p><p>其次，对于双花问题，其保证了最终只会有一个交易被所有节点均认可。这主要是由于区块链的 fork 机制。</p><p>最后，区块链精妙的利用了密码学知识，从理论上隔绝了钱被别人乱花的可能性，这使得黑客能做的也仅仅是欺诈而已。</p><p>总结一下，比特币虽然有不少缺点，比如性能低，交易延时高（交易至少需要 10 分钟，往往 1 个小时可信度会更高），浪费资源等，但其创新地设计了去中心化的分布式账本实现，这甚至使得人类对于交易的本质产生了更深刻的认识，从而进一步推进了人类文明的发展。</p><p>稍微详细的论文阅读笔记可以参考 <a href="https://www.cnblogs.com/xinzhao/p/8584477.html" target="_blank" rel="noopener">精读比特币论文</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单记录一下 6.824 课程对比特币所学。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-bitcoin.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/19.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/bitcoin.pdf" target="_blank" rel="noopener">论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spanner 论文阅读</title>
    <link href="/spanner-thesis/"/>
    <url>/spanner-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>Google Spanner 是 Google 一篇跨时代的论文，开启了 NewSQL 时代的序幕。</p><p>其主要有三点特色：</p><ul><li>2PC + 共识组来避免 2PC 的无限超时阻塞。</li><li>GPS 原子钟同步技术以支持快速的只读事务。</li><li>支持 ACID 的全球型 NewSQL 数据库。</li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>暂仅搬运一些资料，之后有时间再补。</p><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-spanner.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/13.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/spanner.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://cloud.google.com/spanner/docs/whitepapers?hl=zh-cn" target="_blank" rel="noopener">Spanner 白皮书</a></li><li><a href="https://toutiao.io/posts/zdqrx0/preview" target="_blank" rel="noopener">Spanner，True Time 和 CAP</a></li><li><a href="https://zhuanlan.zhihu.com/p/47870235" target="_blank" rel="noopener">Spanner 十问</a></li></ul><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ol><li>在 Spanner 中，只读事务可以从本地数据中心读取数据，以提高性能。但是，如果只读事务向少数副本发出请求，它可能得到过时的数据。这种行为可能会破坏严格的可序列化保证。那么 Spanner 如何应对这种情况以保持其正确性条件呢？</li></ol><blockquote><p>在 Spanner 中，每个事务都会根据 TrueTime 的 Start Rule 选择一个时间戳作为事务 id：对于写请求，其会在提交事务时 2pc 的 prepare 阶段选择 TT.now().latest 作为事务 id；对于读请求，其会在读事务开始时选择 TT.now().latest 作为事务 id。</p><p>每个 replica 都会维护一个递增的 t<sub>safe</sub>  变量，对于读事务 T，当 t<sub>safe</sub>  &gt;= 读事务 T 的 tid 时，可以执行该读事务而不违背外部一致性。</p><p>对于 t_safe，其等于 min(t<sub>safe</sub><sup>paxos</sup>,t<sub>safe</sub><sup>tm</sup>)。对于 t<sub>safe</sub><sup>paxos</sup>，其等于当前 replica 能够看到的最新写事务的 tid，注意到 Paxos 的 leader 会将写入事务按照时间序发送，因此一旦某 replica 发现了已经存在 tid 大于 T 的写事务，则表明所有 tid 小于等于读事务 T 的已提交写入事务均已同步到本地。对于 t <sub>safe</sub><sup>tm</sup>，需要了解每个 paxos group 都会有 replica 个数个 transaction manager，follower 的 transaction manager 可以根据 leader 发送过来的日志保持与 leader 的同步。如果当前 replica 的 transaction manager 不存在已 prepare 但还未 commit/abort 的事务，则 t<sub>safe</sub><sup>tm</sup> 为正无穷；否则为最小的已 prepare 但还未 commit/abort 事务的 tid – 1。对于 tid 大于 t<sub>safe</sub><sup>tm</sup> 的读事务，直接去读也是不安全的。因为这部分还未提交的事务可能会提交，直接读的话便会漏掉这些数据。</p><p>因此对于一个读事务 T，一旦某 replica 发现了本地维护的 t<sub>safe</sub> &gt;= 读事务 T 的 tid，则可以直接执行读事务，这不会违背外部一致性。否则该 replica 需要等待直到本地维护的 t<sub>safe</sub> 大于 读事务 T 的 tid 为止。</p><p>值得注意的是，这样的实现在部分场景下可能也有 liveness 的问题，比如该分片短期内没有新的写入事务且当前所有的事务都已 commit，即使所有 replica 都已经 catch up，t<sub>safe</sub> 仍然始终是最后一个写入事务的 tid。如果此时来了一个新的读事务，其似乎会被永远 block 住。因为该读事务的 tid 永远大于保持不动的 t<sub>safe</sub>。对于这种情况，该 replica 可以向 leader 发送一个 rpc，待 leader 等到 tt.now().earliest 大于该读事务的 tid 时返回 ack，此时该 replica 可以执行该读事务，因为未来产生的写事务 tid 都一定大于该读事务的 tid ，虽然其还未产生，但其一定不会对该读事务产生影响。</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单记录一下 6.824 课程对 Google Spanner 所学。</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
      <tag>Google</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Farm 论文阅读</title>
    <link href="/farm-thesis/"/>
    <url>/farm-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>Fram 结合了乐观事务和硬件优势，在保证可串行化的基础上实现了高性能的分布式事务框架。虽然其系统仅是一个原型系统，但其思想十分具有指导意义。</p><p>其主要利用了三点硬件特性：</p><ul><li>NV RAM：减少磁盘 IO 对性能的影响。（一次 RAM 写大致需要 200ns，一次 SSD 写大致需要 100us，一次 HDD 写大致需要 100ms）</li><li>Kernal Bypass：本地应用直接与网卡交互，无系统调用，无 CPU 参与。消除 Linux 内核网络栈对性能的影响，类似于 <a href="https://www.dpdk.org/" target="_blank" rel="noopener">dpdk</a>。</li><li>RDMA：跟远程节点交互时不需要远程节点的 CPU 参与，直接读对应内存，无系统调用，无 CPU 参与。消除 Linux 内核网络栈对性能的影响。</li></ul><p>其主要有一个特点：</p><ul><li>快：在 90 台数据分片过的机器上，可以达到 100 万事务/s，比 Spanner 快 100 倍。</li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>暂仅搬运一些资料，之后有时间再补。</p><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-farm.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/14.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://pdos.csail.mit.edu/6.824/papers/farm-2015.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://www.yuque.com/flyrzl/iv0mdq/fntw2a?language=zh-cn" target="_blank" rel="noopener">乐观并发控制 Optimistic Concurrency Control（OCC）</a></li><li><a href="https://www.jianshu.com/p/4128b38a2312" target="_blank" rel="noopener">不妥协：分布式事务的一致性，可用性和性能</a></li><li><a href="https://blog.csdn.net/hohomi77/article/details/102511679" target="_blank" rel="noopener">分布式系统：FaRM</a></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单记录一下 6.824 课程对 Farm 所学。</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式事务简介</title>
    <link href="/distributed-transactions/"/>
    <url>/distributed-transactions/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>事务是作为单个逻辑工作单元执行的一系列操作。一个逻辑工作单元必须有四个属性，称为原子性、一致性、隔离性和持久性 (ACID) 属性。分布式事务则是尝试在多节点的环境下实现这些语义。</p><p>分布式事务涉及的知识内容较多，本篇博客并没有将其彻底整理清楚，只是简单记录了一下 6.824 课程所学。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>对于分布式事务，可以将其细化为并发控制和原子提交两个子问题。前者是在说如何保证并发事务的串行隔离性，后者是在说当数据分片分布在不同的节点上时，如何保证事务在不同节点上提交与否的原子性。</p><h3 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h3><p>对于事务的并发控制模型，一般有两个方向：悲观事务和乐观事务。前者适合于数据竞争严重且重试代价大的场景，后者适用于数据竞争不严重且重试代价不大的场景。</p><h4 id="悲观事务"><a href="#悲观事务" class="headerlink" title="悲观事务"></a>悲观事务</h4><p>在事务执行过程中对事务所用到的数据都上锁。这里的锁从事务中第一次用到对应数据时开始，直到事务结束时才释放。</p><p>2PL（2-Phase-Lock）就是一种典型的悲观事务方法，但并不是到事务结束时才释放所有锁，而是事务过程中一旦不再使用某对象即可释放该对象的锁。因此，6.824 课程中介绍的 2PL 严格来说是 S2PL（Strict-2-Phase-Lock），即所有锁都是在事务结束的同时才释放的。S2PL 相比 2PL 的性能更差，但能够避免级联终止的发生，具体可以参考此 <a href="https://niceaz.com/2019/03/24/isolation-2pl-mvcc/" target="_blank" rel="noopener">博客</a>。</p><p>不论是 2PL 还是 S2PL，都有可能导致死锁，因此一般要从两个方面入手来避免死锁：死锁检测、死锁预防</p><ul><li>死锁检测：为相互等待的事务之间维护一张 graph， 检测 graph 中是否有环。如果检测到优化，则根据一定的策略选择终止一个事务，打破循环等待。</li><li>死锁预防：按照一定顺序进行加锁，锁超时则终止等。</li></ul><p>S2PL 严格意义上不能解决幻读的问题，因为其加的都是行锁，所以其并不能实现串行隔离性，这一点与 6.824 课程中的介绍似乎有些许出入，等到之后有时间再认真研究一番。</p><h4 id="乐观事务"><a href="#乐观事务" class="headerlink" title="乐观事务"></a>乐观事务</h4><p>在事务执行过程中获取事务所用到的数据时并不上锁，直到计算完毕提交时才加锁对数据进行验证，若无变化则提交，否则 abort 或重新获取最新数据并计算。</p><p>由于分布式乐观事务在提交之前获取数据进行计算时并不需要加锁，因此一般也可以通过结合 RDMA 等技术来显著提升性能。</p><h3 id="原子提交"><a href="#原子提交" class="headerlink" title="原子提交"></a>原子提交</h3><p>在分布式事务中，参与事务的所有节点必须全部执行 Commit 操作或全部执行 Abort 操作，即他们需要在”执行 Commit 还是 Abort”这一点上达成一致（其实就是共识）。理论上有许多原子提交协议：2PC 和 3PC 等等。</p><p>原子提交协议和共识协议：</p><ul><li>目的相同：<ul><li>共识问题：解决的是如何在分布式系统中的多个节点之间就某个提议达成共识。</li><li>原子提交问题：解决的是参与分布式事务的所有节点在”执行 Commit 还是 Abort”这一点上达成共识。</li></ul></li><li>范围不同：前者要求所有节点达成共识，后者要求大多数未故障的节点达成共识。</li></ul><p>有关 2PC, 3PC, TCC, SAGA 等原子提交协议的具体内容，可以参考此 <a href="https://mp.weixin.qq.com/s/MbPRpBudXtdfl8o4hlqNlQ" target="_blank" rel="noopener">博客</a>。</p><p>对于业务上的分布式事务，还有 Seata 和基于 MQ 的分布式事务实现等等，花样很多，但实现各异。他们不是本文的重点，感兴趣自行谷歌即可。</p><p>对于数据库内核中的分布式事务实现，一般都是通过 2PC 的方式。为什么不用 3PC 呢？2PC 严格来说是保证了 safety 但牺牲了较多的 liveness（部分场景下资源会被永远锁定），而且正常工作时需要发两轮 RPC 来提交一个事务，其性能是被很多人诟病的一点；3PC 虽然提高了 liveness（资源锁定一定会在有限时间内被解除），但其是以牺牲 safety 为代价的，同时正常工作时需要发三轮 RPC 来提交一个事务，性能更差，因此很多人认为使用 3PC 是实现分布式事务的一条歪路，工业界也几乎很少有人使用 3PC，这一点 PingCAP 的 CTO 在分布式之美论坛上也提到过。</p><p>事实上，不论是 Spanner 还是 TiDB，他们的方式都是通过将协调者和参与者都分别组成共识组的方式来避免单点故障，从而在保证 safety 的基础上提升 liveness（由于协调者节点的单点故障被共识组规避掉，参与者的资源锁定一定会在有限时间内被解除），当然，由于每一个操作和决定都需要在共识组中进行同步，不可避免的其性能也会更差，但相比 3PC，其至少没有牺牲 safety，这一点非常关键，因为只要保证了 safety，至少我们可以通过 scale out 的方式来提升性能。</p><p>对于 2PC，业界和学术界针对不同的数据模型也有一些特定的优化，比如针对 KV 模型的 Percolator 算法等，它可以将 2PC 在部分场景下优化为 1PC 并结合 Async Commit 的方式来提升性能，这里之后有时间再进行研究吧。</p><p>业界也有一些替换 2PC 的声音，可以参考此 <a href="https://www.jdon.com/51588" target="_blank" rel="noopener">博客</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客简单记录了 6.824 课程中分布式事务的内容，同时进行了一点点分析和拓宽，以做记录。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-2pc.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/12.html" target="_blank" rel="noopener">6.824 视频</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Aurora 论文阅读</title>
    <link href="/aurora-thesis/"/>
    <url>/aurora-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>Amazon Aurora 是一种与 MySQL 和 PostgreSQL 兼容的关系数据库，专为云而打造，既具有传统企业数据库的性能和可用性，又具有开源数据库的简单性和成本效益。</p><p>Amazon Aurora 的速度最高可以达到标准 MySQL 数据库的五倍、标准 PostgreSQL 数据库的三倍。它可以实现商用数据库的安全性、可用性和可靠性，而成本只有商用数据库的 1/10。</p><p>关于 Amazon Aurora 的进一步细节，可以参考 <a href="https://aws.amazon.com/cn/rds/aurora/?nc2=type_a&amp;aurora-whats-new.sort-by=item.additionalFields.postDateTime&amp;aurora-whats-new.sort-order=desc" target="_blank" rel="noopener">AWS 官网</a>。</p><p>2017 年，Amazon 在 SIGMOD 上发表了 Aurora 的论文，详细介绍了 Aurora 的设计思路和架构细节，以下顺着 6.824 课程的思路对 Amazon Aurora 进行简单的介绍。</p><h2 id="EC2（Elastic-Compute-Cloud）"><a href="#EC2（Elastic-Compute-Cloud）" class="headerlink" title="EC2（Elastic Compute Cloud）"></a>EC2（Elastic Compute Cloud）</h2><p>EC2 是 Amazon 最成功的云计算产品之一，用户可以租用 EC2 实例来部署网页或数据库服务等等，EC2 可以服务支持在线扩容，实时备份等功能。</p><p>最开始每个 EC2 实例往往以虚拟机的形式运行在物理节点上，其所有的磁盘 IO 都会通过虚拟机转化到对应的物理节点本地挂载的物理磁盘上。</p><p>对于无状态的网页服务，EC2 使用起来十分方便，因为其不需要关注容错，且很容易通过横向扩展 + 负载均衡的方式来提升性能。</p><p>对于有状态的数据库服务，比如 MYSQL，EC2 使用起来有一些缺点：</p><ul><li>受限的扩展：类似于 MYSQL 读写分离，单机 MYSQL 在 EC2 上可以做到读扩展，但不能做到写扩展。</li><li>受限的容错：由于没有做冗余备份，物理节点一旦挂了，其磁盘上的数据暂时不可用。</li></ul><h2 id="EBS（Elastic-Block-Store）"><a href="#EBS（Elastic-Block-Store）" class="headerlink" title="EBS（Elastic Block Store）"></a>EBS（Elastic Block Store）</h2><p>基于以上 EC2 支持 MYSQL 服务的缺点，Amazon 设计了 EBS 来进一步提升容错能力。</p><p>EBS 是一组具有容错能力的存储服务器，对外的抽象类似于 EC2 实例的磁盘，其利用默认副本数为 2 的 Chain Replication 和基于 Paxos 的配置管理器实现了容错。</p><p>这样其实是将 EC2 从有状态变成了无状态，一旦某个 EC2 宕机，另外启动一个 EC2 实例挂载相同的 EBS 即可恢复之前的状态。</p><p>然而，这样的设计依然具有一些缺点：</p><ul><li>巨大的数据流量：由于 EBS 对外的抽象类似于磁盘，所以对于 MYSQL 来说，其脏页和 redo 日志都会被同步到 EBS 中去，尤其对于前者，即使只改动了一个 page 中的一个字节也需要传输整个 page。</li><li>依然受限的容错：EC2-on-EBS 虽然比 EC2-on-Local-Disk 的容错性高，但处于 Chain Replication 的性能考虑，一组 EBS 服务器一定会在一个 AZ（Amazon 对机房或数据中心的抽象）中。因此，其对于某个 AZ 的断电，洪水等灾害依然无法能够做到容错。</li></ul><h2 id="RDS（Relational-Database-Service）"><a href="#RDS（Relational-Database-Service）" class="headerlink" title="RDS（Relational Database Service）"></a>RDS（Relational Database Service）</h2><p>基于 EBS 的缺点，Amazon 又提供了 DBaaS（database-as-a-service） 的云服务 RDS，该服务的目标是提供跨 AZ 的容错，其架构图如下所示：</p><p><img src="/aurora-thesis/EBS.png" srcset="/img/loading.gif" lazyload alt></p><p>与 EBS 相比，RDS 的容错性更强，但由于同步时需要跨 AZ，这导致数据写性能进一步下降，而且在没有减少数据流量的同时还增加了巨大的跨 AZ 流量。</p><h2 id="Aurora"><a href="#Aurora" class="headerlink" title="Aurora"></a>Aurora</h2><p>基于以上服务的缺点，Amazon 明确了其理想的容错和性能需求：</p><ul><li>即使一个 AZ 断电，写服务依然正常。</li><li>即使一个 AZ 断电 + 另一个副本不可用，读服务依然正常，该需求被称作 AZ + 1。</li><li>容忍个别慢副本对性能造成的影响。</li><li>能够快速修复宕机的副本。</li></ul><p>基于以上需求，Amazon 设计出了兼容 Mysql 协议的云数据库 Aurora，其架构图如下所示：</p><p><img src="/aurora-thesis/Aurora.png" srcset="/img/loading.gif" lazyload alt></p><p>Aurora 主要有两个创新点，他们共同使得 Aurora 相比 RDS 版的 MYSQL 有了 35 倍的性能提升：</p><ul><li>quorum 写：采用了 2+2+2 的三中心六副本部署方案。写只需要四个副本返回 ack 即可，这样即可满足上述对容错能力和性能的需求。</li><li>减少数据同步流量：使存储服务器具备将日志应用到 page 的能力，这样即可只同步物理日志而不同步脏页，从而减少大量的数据同步流量。</li></ul><p>对于 Aurora 的读写流程和一致模型，可以参考此 <a href="https://zhuanlan.zhihu.com/p/319806107" target="_blank" rel="noopener">博客</a> 和此 <a href="https://zhuanlan.zhihu.com/p/338582762" target="_blank" rel="noopener">博客</a>。</p><p>值得一提的是：为了存储层可扩展，Aurora 会将数据库文件切分成 10GB 大小的 segment，每个 segment 可以保存在不同的 6 个副本上，这保证了存储层的可扩展。然而由于只会有一个可写实例，所以其计算层并无法扩展，因此对于高并发大数据量的场景，还是需要分库分表。</p><p>总结一下：Aurora 通过对 IO 链路的优化和 quorum 写相比 RDS 版的 MYSQL 性能提升了 35 倍，但其本质上仍然是一个单机数据库。Aurora 可以被定性为一款云上的高性能单机关系数据库。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本博客沿着 6.824 课程的思路，对 Aurora 的由来，设计思路，具体架构进行了简单的介绍。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-aurora.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/10.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/aurora.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://aws.amazon.com/cn/rds/aurora/?nc2=type_a&amp;aurora-whats-new.sort-by=item.additionalFields.postDateTime&amp;aurora-whats-new.sort-order=desc" target="_blank" rel="noopener">Amazon Aurora 产品</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Frangipani 论文阅读</title>
    <link href="/frangipani-thesis/"/>
    <url>/frangipani-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Frangipani 是一篇很古老的分布式存储论文，其设计思想在今天看来有很多已经过时了，但也有一定的参考意义。</p><p>该论文主要介绍了三个方面的工作：</p><ul><li>cache coherence</li><li>distributed transactions</li><li>distributed crash recovery</li></ul><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>具体内容可以参考此 <a href="https://www.cnblogs.com/jamgun/p/14668522.html" target="_blank" rel="noopener">博客</a> 和 6.824 课程的 <a href="http://nil.csail.mit.edu/6.824/2020/notes/l-frangipani.txt" target="_blank" rel="noopener">讲义</a>，后者较为详细。</p><p>有关后两个工作可以直接参考以上博客的介绍，有关 cache coherence 可以进一步参考 <a href="https://mp.weixin.qq.com/s/HvgaXjHgD4_nVz81ipmbhg" target="_blank" rel="noopener">CPU 缓存的实现方式</a> 和基于 MESI 协议的 <a href="https://mp.weixin.qq.com/s/IT9clEXFb5hZJ8-ItheAng" target="_blank" rel="noopener">CPU 缓存一致性实现</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单记录一下 Frangipani 论文的主要思想并记录一些相关博客。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-frangipani.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/11.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/thekkath-frangipani.pdf" target="_blank" rel="noopener">论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chain Replication 论文阅读</title>
    <link href="/chain-replication-thesis/"/>
    <url>/chain-replication-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>对于 raft、paxos 这类共识算法，leader 节点需要将客户端的写请求编号并发送给所有 follower 以期望达成共识，这一定程度上导致写性能无法随节点个数线性增长，因为 leader 同步的数据量会随着节点数的增长而增长，从而使得主节点承载着更大的压力，往往成为了瓶颈。</p><p>2004 年，Chain Replication （之后简称 cr）方案被提出，其也能够保证多副本间的线性一致性。具体思路是每个节点只负责向后续节点进行备份，从而将压力分摊到整个链上。因为其与上述的共识协议相比，其每个节点的写入负载几乎一致，从而不存在单节点负载很高影响性能的问题。</p><p>以上都是论文中的吹的说法，我个人持怀疑态度：首先 raft 的 leader 向所有 follower 发送是并行的，而 cr 是串行的，因此就性能上，个人不觉得后者会更快；其次随着节点数增多，虽然 raft 的 leader 负载会更大可能增大延迟，但是 cr 一定会增加延迟（多一轮 RTT），因此就写扩展性上，我也没看到 cr 有什么明显的优势。至于说什么拆分读写负载，只能说 raft 早就提出 follower read 的解决方案了，cr 做的也不过是把读放到了另一个节点上，并无扩展性，craq 才相对做到了一定程度的读性能的可扩展性。 </p><p>但不论如何，很多顶级产品比如 Ceph，Parameter Server 等都用到了 cr，所以了解一下 cr 还是有必要的，其能够拓宽我们对共识协议的了解边界。毕竟其实现线性一致性的方式还是比较巧妙的，而且设计也比较简单，没 raft 那么多 corner case。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>有关 CR，可以参考此 <a href="https://zhuanlan.zhihu.com/p/344522347" target="_blank" rel="noopener">博客</a>。<br>有关 CRAQ，可以参考此 <a href="https://www.cnblogs.com/brianleelxt/p/13275647.html" target="_blank" rel="noopener">博客</a> 和此 <a href="https://zhuanlan.zhihu.com/p/344808961" target="_blank" rel="noopener">博客</a>。</p><p>CR 能够以很简单的设计实现多副本的线性一致性，不过其不能自己处理脑裂和分区的问题，因而还需要另一个高可用的配置服务器集群来协作提供高可用服务。</p><p>CRAQ 相比 CR 做了读性能优化，使得读性能可以线性扩展且保证线性一致性。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单记录了 cr 和 craq 的工作原理。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-craq.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/9.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf" target="_blank" rel="noopener">CR 论文</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/craq.pdf" target="_blank" rel="noopener">CRAQ 论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zookeeper 论文阅读</title>
    <link href="/zookeeper-thesis/"/>
    <url>/zookeeper-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Zookeeper 作为一个划时代的分布式协调服务，是 Hadoop 技术栈的重要组件。</p><p>本篇博客将讨论一些 zk 论文的知识点。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>最近比较忙，没多少时间总结了，论文内容概要可以参考这篇 <a href="https://keys961.github.io/2019/04/01/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-ZooKeeper/" target="_blank" rel="noopener">博客</a>，更详细的细节可以参考这篇 <a href="https://mp.weixin.qq.com/s/DwyPt5YZgqE0O0HYEC1ZMQ" target="_blank" rel="noopener">博客</a>。</p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="zk-or-etcd"><a href="#zk-or-etcd" class="headerlink" title="zk or etcd?"></a>zk or etcd?</h3><p>同为分布式协调服务和元数据存储服务的产品：老大哥 zk 伴随 NoSQL 运动崛起，坐拥 hadoop 技术栈孤独求败；后起之秀 etcd 拥抱云原生，相伴 k8s 来势汹汹。所以一个很直接的问题就出现了：zk or etcd？</p><p>网上有很多对两者优缺点的分析，例如该 <a href="https://juejin.cn/post/6844904147779600391" target="_blank" rel="noopener">博客</a>。</p><p>个人对这两个系统的具体了解没有很深入，仅仅从 zab 和 raft 算法出发谈谈自己的想法。</p><p>前面的 <a href="https://tanxinyu.work/consistency-and-consensus/#%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95">博客</a> 已经介绍过了，zab 保证的是顺序一致性语义，raft 保证的则是线性一致性语义。尽管他们都可以算强一致性，但顺序一致性并无时间维度的约束，所以可能并不满足现实世界的时序。也就是说，在现实世界中，顺序一致性是可能返回旧数据的。对于一个分布式协调服务，可能返回旧数据实际上是比较坑爹的一件事，尽管 zk 保证了单客户端 FIFO 的顺序，但有些场景还是有一些受限的。因此在这一点上，我认为 etcd 保证的线性一致性是更好的，zk 的顺序一致性有时候会有坑，这一点 PingCAP 的 CTO 也在知乎的”分布式之美”圆桌会谈上吐槽过。</p><p>当然，zk 既然有这么多的用户在用，就算有坑那一定也不是大坑，大部分情况下应该都是没有问题的。至于选谁更好，答案一定不是唯一的，根据自己的业务和理解有自己的判断就好。</p><h3 id="zk-是否能够保证线性一致性？"><a href="#zk-是否能够保证线性一致性？" class="headerlink" title="zk 是否能够保证线性一致性？"></a>zk 是否能够保证线性一致性？</h3><p>很多人可能会觉得既然 zk 支持线性一致性写，那么也可以通过 sync + read 来支持线性一致性读，理论上这样是可以支持线性一致性读的，但在 zk 真正的实现中是不能严格满足线性一致性的，具体可以参照 jepsen 中的 <a href="https://github.com/jepsen-io/jepsen/issues/399" target="_blank" rel="noopener">讨论</a>。不能严格满足线性一致性的根据原因就是 zk 在实现过程中并没有将 sync 当做一个空写日志去执行，而是直接让 leader 返回一个 zxid 给 follower，然而此时的 leader 并没有像 raft 那样通过 read index 发起一轮心跳或 lease read 的方式来确保自己一定是 leader，从而可能在网络分区脑裂的 corner case 下返回旧数据，因此无法在严格意义上满足线性一致性。当然，这种 corner case 在实际中很少见，而且也应该可以修复，所以从技术上来讲，zk 应该是可以用 sync + read 来支持线性一致性读的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客对 zk 论文的内容进行了简单的记录，最后进行了一些讨论。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-zookeeper.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/8.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/papers/zookeeper.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://iswade.github.io/translate/zookeeper/" target="_blank" rel="noopener">论文翻译</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用 IDEA 对分布式 IoTDB 进行调试</title>
    <link href="/cluster-iotdb-idea-debugger/"/>
    <url>/cluster-iotdb-idea-debugger/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在单机数据库中，寻找 bug 相对较为简单。因为一旦可以复现 bug，那我们可以利用 IDE 在服务端打断点一步步执行并跟踪查看堆栈信息来判断代码出错的位置从而最终找到问题。</p><p>在分布式数据库中，找 bug 就变得相对困难了。一方面是因为分布式数据库较难利用 IDE 打断点，其往往通过打 log 的方式来记录错误情况，另一方面是一条客户端请求过来后往往伴随着若干并行和跨节点的 rpc，因此如果通过查 log 的方式来寻找 bug，往往很耗费时间和精力。</p><p>在生产环境中，线上 debug 显然是一个不可取（<del>被运维打死</del>）的行为，因此业务只能通过完善日志调用链路的方式来追踪一个请求在分布式系统中的行为，这种方式一方面需要各个项目能够支持对同一 requestId 请求的追踪，另一方面也需要各个应用能够打出合理数量的日志，不能太影响性能但也不能遇到问题无法定位，此外还需要支持海量日志收集（类似于 Flume + Kafka ）和全文检索（ES 或 Spark/MR）的应用，总之这是一套相对较重的框架。就分布式追踪而言，目前较火的项目有 Skywalking，Zipkin 等等，可以参考这篇 <a href="https://icyfenix.cn/distribution/observability/" target="_blank" rel="noopener">博客</a> 的介绍。</p><p>在测试环境中，尽管我们也可以采用生产环境的 debug 方式，但显然我们希望能够找到效率更高的方式。万幸的是，Jetbrains 全家桶为我们提供分布式系统的 debug 方式。比如对于 Java 应用而言，IDEA 就提供了远程 debug 和本地多进程 debug 的方式。对于远程 debug，可以参考这篇 <a href="https://www.cnblogs.com/aligege/p/7308180.html" target="_blank" rel="noopener">博客</a> 介绍的方式对远程的应用进行 debug，也可以参照这篇 <a href="https://mp.weixin.qq.com/s/frwNMfr3wAkHaR9ZUXFcew" target="_blank" rel="noopener">博客</a> 介绍的方式对分布式 IoTDB 远程 debug；对于本地多进程 debug，本篇博客将介绍如何利用 IDEA 对分布式 IoTDB 进行调试。</p><p>有关 Apache IoTDB 可以参考 <a href="https://iotdb.apache.org/" target="_blank" rel="noopener">官方网站</a>。</p><h2 id="本地多进程-debug-调试"><a href="#本地多进程-debug-调试" class="headerlink" title="本地多进程 debug 调试"></a>本地多进程 debug 调试</h2><p>对于 IoTDB 集群的搭建示例，可以参照 <a href="https://github.com/apache/iotdb/blob/master/docs/zh/UserGuide/Cluster/Cluster-Setup.md" target="_blank" rel="noopener">官方文档</a>，其分布式模块的启动主类为 <a href="https://github.com/apache/iotdb/blob/master/cluster/src/main/java/org/apache/iotdb/cluster/ClusterMain.java" target="_blank" rel="noopener">ClusterMain.java</a>，其默认的三节点分布式配置参数文件夹可以参考 <a href="https://github.com/apache/iotdb/tree/master/cluster/src/test/resources" target="_blank" rel="noopener">这里</a>。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs JAVA"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;<br>  <span class="hljs-keyword">if</span> (args.length &lt; <span class="hljs-number">1</span>) &#123;<br>    logger.error(<br>        <span class="hljs-string">"Usage: &lt;-s|-a|-r&gt; "</span><br>            + <span class="hljs-string">"[-D&#123;&#125; &lt;configure folder&gt;] \n"</span><br>            + <span class="hljs-string">"-s: start the node as a seed\n"</span><br>            + <span class="hljs-string">"-a: start the node as a new node\n"</span><br>            + <span class="hljs-string">"-r: remove the node out of the cluster\n"</span>,<br>        IoTDBConstant.IOTDB_CONF);<br><br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br>  ...<br><br>&#125;<br></code></pre></div></td></tr></table></figure><p>可以看到其按照 seednodes 启动时指定 -s 即可，此外其也支持通过 <code>-D{}</code> 的方式来覆盖参数，因此我们可以利用 IDEA 分别指定不同的配置文件夹并用 debug 模式来启动三个 clusterMain 进程，这样即可达到本地多进程 debug 调试的理想效果。</p><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><ol><li>点击 <code>Edit Configurations...</code><br><img src="/cluster-iotdb-idea-debugger/step1.png" srcset="/img/loading.gif" lazyload alt></li><li>点击 <code>Add new Configuration</code><br><img src="/cluster-iotdb-idea-debugger/step2.png" srcset="/img/loading.gif" lazyload alt></li><li>点击 <code>Application</code><br><img src="/cluster-iotdb-idea-debugger/step3.png" srcset="/img/loading.gif" lazyload alt></li><li>编辑好红框的五个部分，指定配置名称，jdk 版本，启动模块，启动主类和启动参数 <code>-s</code>，然后点击绿框。<br><img src="/cluster-iotdb-idea-debugger/step4.png" srcset="/img/loading.gif" lazyload alt></li><li>点击 <code>Add VM options</code><br><img src="/cluster-iotdb-idea-debugger/step5.png" srcset="/img/loading.gif" lazyload alt></li><li>添加 <code>-D{}</code> 环境变量，例如我填的就是<code>-DIOTDB_CONF=/Users/txy/Study/incubator-iotdb/cluster/src/test/resources/node1conf</code><br><img src="/cluster-iotdb-idea-debugger/step6.png" srcset="/img/loading.gif" lazyload alt></li><li>复制两份 node1 的配置<br><img src="/cluster-iotdb-idea-debugger/step7.png" srcset="/img/loading.gif" lazyload alt></li><li>编辑好 node2 的名称和配置文件<br><img src="/cluster-iotdb-idea-debugger/step8.png" srcset="/img/loading.gif" lazyload alt></li><li>编辑好 node3 的名称和配置文件<br><img src="/cluster-iotdb-idea-debugger/step9.png" srcset="/img/loading.gif" lazyload alt></li><li>以 debug 模式分别启动 node1，node2 和 node3<br><img src="/cluster-iotdb-idea-debugger/step10.png" srcset="/img/loading.gif" lazyload alt></li><li>可以执行对应的请求来触发 bug，从而开始 debug 调试（此时相当于 idea 用 debug 模式启动了三个进程，构成了一个可以 debug 的三节点伪分布式 IoTDB）<br><img src="/cluster-iotdb-idea-debugger/step11.png" srcset="/img/loading.gif" lazyload alt></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本片博客简单介绍了如何使用 IDEA 调试分布式 IoTDB，希望能对大家 debug 分布式系统有所帮助。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://mp.weixin.qq.com/s/ra0aMHmmzst03v0rBdOVfQ" target="_blank" rel="noopener">手摸手教你阅读和调试大型开源项目 ZooKeeper</a></li><li><a href="https://mp.weixin.qq.com/s/frwNMfr3wAkHaR9ZUXFcew" target="_blank" rel="noopener">No.7 - 时序数据库随笔 - Apache IoTDB（单机&amp;集群）调试环境搭建</a></li><li><a href="https://iotdb.apache.org/" target="_blank" rel="noopener">IoTDB 官网</a></li><li><a href="https://github.com/apache/iotdb/tree/master" target="_blank" rel="noopener">IoTDB 代码库</a> </li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>IoTDB</tag>
      
      <tag>开发工具配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一致性模型与共识算法</title>
    <link href="/consistency-and-consensus/"/>
    <url>/consistency-and-consensus/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有关一致性模型和共识算法的一致性模型这两个问题，最近阅读了一些优质博客，学到了一些新的东西，同时感觉一些定义比较混乱，特此记录一下自己的理解。</p><h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><p>一致性问题是分布式领域最为基础也是最重要的问题，具体来历可以参考此 <a href="https://mp.weixin.qq.com/s/3odLhBtebF4cm58hl-87JA" target="_blank" rel="noopener">博客</a>。</p><p>一般来讲，分布式系统中的一致性按照对一致性要求的不同，主要分为强一致性，弱一致性这两大类，前者是基于 safety 的概念，后者是基于 liveness 的概念。</p><h3 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h3><p>强一致性包含线性一致性和顺序一致性，其中前者对 safety 的约束更强，也是分布式系统中能保证的最好的一致性。</p><h4 id="顺序一致性"><a href="#顺序一致性" class="headerlink" title="顺序一致性"></a>顺序一致性</h4><p>如果一个并发执行过程所包含的所有读写操作能够重排成一个全局线性有序的序列，并且这个序列满足以下两个条件，那么这个并发执行过程就是满足顺序一致性的：</p><ul><li>条件 I：重排后的序列中每一个读操作返回的值，必须等于前面对同一个数据对象的最近一次写操作所写入的值。</li><li>条件 II：原来每个进程中各个操作的执行先后顺序，在这个重排后的序列中必须保持一致。</li></ul><h4 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h4><p>线性一致性的定义，与顺序一致性非常相似，也是试图把所有读写操作重排成一个全局线性有序的序列，但除了满足前面的条件 I 和条件 II 之外，还要同时满足一个条件：</p><ul><li>条件 III：不同进程的操作，如果在时间上不重叠，那么它们的执行先后顺序，在这个重排后的序列中必须保持一致。</li></ul><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ul><li>它们都试图让系统“表现得像只有一个副本”一样。</li><li>它们都保证了程序执行顺序不会被打乱。体现在条件 II 对于进程内各个操作的排序保持上。</li><li>线性一致性考虑了时间先后顺序，而顺序一致性没有。</li><li>满足线性一致性的执行过程，肯定都满足顺序一致性；反之不一定。</li><li>线性一致性隐含了时效性保证（recency guarantee）。它保证我们总是能读到数据最新的值。</li><li>在顺序一致性中，我们有可能读到旧版本的数据。</li></ul><h3 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h3><p>弱一致性是指系统在数据成功写入之后，不承诺立即可以读到最新写入的值，也不会具体承诺多久读到，但是会尽可能保证在某个时间级别之后，可以让数据达到一致性状态。</p><p>可以根据能够恢复一致的时间将弱一致性进一步分类，如果是有限时间那就是最终一致性，如果是无限时间那实际上相当于没有一致性。对于前者，可以进一步分类，如下图所示：</p><p><img src="/consistency-and-consensus/consistency_level.png" srcset="/img/loading.gif" lazyload alt></p><p>其具体的定义已经在此篇 <a href="https://tanxinyu.work/base-theory/#%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E7%A7%8D%E7%B1%BB">博客</a> 中有过介绍，此处不再赘述。</p><p>有关线性一致性和可序列化之前的异同，可以参考此 <a href="https://int64.me/2020/%e4%b8%80%e8%87%b4%e6%80%a7%e6%a8%a1%e5%9e%8b%e7%ac%94%e8%ae%b0.html" target="_blank" rel="noopener">博客</a>。重点是来自 Jepsen 官网的一张图，如下所示：<br><img src="/consistency-and-consensus/consistency_serializable.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="一致性与共识的区别"><a href="#一致性与共识的区别" class="headerlink" title="一致性与共识的区别"></a>一致性与共识的区别</h2><p>一致性往往指分布式系统中多个副本对外呈现的数据的状态。如前面提到的顺序一致性、线性一致性，描述了多个节点对数据状态的维护能力。</p><p>共识性则描述了分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。</p><p>因此，一致性描述的是结果状态，共识则是一种手段。达成某种共识并不意味着就保障了一致性（这里的一致性指强一致性）。只能说共识机制，能够实现某种程度上的一致性。</p><p>实践中，要保障系统满足不同程度的一致性，核心过程往往需要通过共识算法来达成。</p><h2 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h2><p>常见的共识算法有 Paxos，Zab 和 Raft，此处暂只介绍后两种共识算法的一致性模型。</p><h3 id="ZooKeeper-的-Zab"><a href="#ZooKeeper-的-Zab" class="headerlink" title="ZooKeeper 的 Zab"></a>ZooKeeper 的 Zab</h3><p>一种说法是 ZooKeeper 是最终一致性，因为由于多副本、以及保证大多数成功的 Zab 协议，当一个客户端进程写入一个新值，另外一个客户端进程不能保证马上就能读到这个值，但是能保证最终能读取到这个值。</p><p>另外一种说法是 ZooKeeper 的 Zab 协议类似于 Paxos 协议，提供了线性一致性。</p><p>但这两种说法都不准确，ZooKeeper 文档中明确写明它的一致性是 Sequential consistency 即顺序一致性。</p><p>ZooKeeper 中针对同一个 follower A 提交的写请求 request1、request2，某些 follower 虽然可能不能在请求提交成功后立即看到（也就是强一致性），但经过自身与 leader 之间的同步后，这些 follower 在看到这两个请求时，一定是先看到 request1，然后再看到 request2，两个请求之间不会乱序，即顺序一致性。</p><p>其实，实现上 ZooKeeper 的一致性更复杂一些，ZooKeeper 的读操作是 sequential consistency 的，ZooKeeper 的写操作是 linearizability 的，关于这个说法，ZooKeeper 的官方文档中没有写出来，但是在社区的邮件组有详细的讨论。ZooKeeper 的论文 <a href="https://www.usenix.org/system/files/conference/atc16/atc16_paper-lev-ari.pdf" target="_blank" rel="noopener">《Modular Composition of Coordination Services》</a> 中也有提到这个观点，官网上也有 <a href="https://zookeeper.apache.org/doc/r3.4.9/zookeeperProgrammers.html#ch_zkGuarantees" target="_blank" rel="noopener">声明</a>。</p><p>总结一下，可以这么理解 ZooKeeper：从整体（read 操作 + write 操作）上来说是 sequential consistency，写操作实现了 Linearizability。</p><h3 id="etcd-的-Raft"><a href="#etcd-的-Raft" class="headerlink" title="etcd 的 Raft"></a>etcd 的 Raft</h3><p>对于 raft 算法，其写操作一定得从 leader 向 follower 同步，这是 raft 算法的基石，也是很难变动的。由于 leader 始终是瓶颈，所以即使我们增加节点，raft 算法的写吞吐也不能够线性扩展，反而会越来越差。对于读操作，raft 的默认方式是从 leader 读，这样就能够满足线性一致性，然而这样的实现方式也会导致读吞吐也不能随节点个数的增长而线性提升。zab 提出了一种保证顺序一致性的 follower read 优化，针对读请求能够利用所有节点的计算和 IO 资源，从而使得读吞吐能够线性扩展。raft 更进一步，提出了一种保证线性一致性的 follower read 优化，具体可以参考此 <a href="https://zhuanlan.zhihu.com/p/78164196" target="_blank" rel="noopener">博客</a>。</p><p>对于 raft 算法，其写请求自然是满足线性一致性的，对于读请求，需要做一些额外的工作来保证线性一致性，这一点论文中也有说明实现线性一致性读的两种方式：</p><ul><li>Read Index</li><li>Lease Read</li></ul><p>对于 Read Index 方法，leader 大致的流程如下：</p><ol><li>记录当前的 commit index，称为 Read Index</li><li>向 follower 发起一次心跳，如果大多数节点回复了，那就能确定现在仍然是 leader</li><li>等待状态机至少应用到 Read Index 记录的 Log</li><li>执行读请求，将结果返回给 Client</li></ol><p>follower 大致的流程如下：</p><ol><li>向 leader 请求其 commitIndex 来作为本次查询请求的 Read Index</li><li>该 leader 向 follower 发起一次心跳，如果大多数节点回复了，那就能确定现在仍然是 leader</li><li>该 leader 返回本地的 commitIndex 给 follower</li><li>等待状态机至少应用到 Read Index 记录的 Log</li><li>执行读请求，将结果返回给 Client</li></ol><p>实际上 Read Index 流程第二步的主要作用是为了让 leader 确保自己仍是 leader。设想这样的情况：发生了网络分区，leader 被分区到了少数派中，多数派已经产生了新的 leader 并进行了新的数据写入，此时尽管老 leader 发送心跳无法得到大多数节点的回复，但其也无法主动退位。如果对于查询请求 leader 不进行第二步的检查直接读状态机的话，就可能读到旧的数据，从而使得 raft 不满足线性一致性了。 </p><p>Lease Read 与 Read Index 类似，但更进一步省去了网络交互。基本的思路是 leader 取一个比 Election Timeout 小的租期，在租期不会发生选举，确保 leader 在这个周期不会变，所以就算老 leader 被分区到了少数派，直接读状态机也一定不会读到旧数据，因为租期内新 leader 一定还没有产生，也就不会有更新的数据了。因此 Lease Read 可以跳过 Read Index 流程的第二步，从而降低读延时提升读吞吐量。不过 Lease Read 的正确性和时间挂钩，因此时间的准确性至关重要，如果时钟漂移严重，这套机制就会有问题。</p><p>以上算是 raft 实现线性一致性读的直观解释了。 </p><p>对于以上实现方式，我们还可以分析探讨一下两个问题：</p><ul><li>如果读写请求都走 leader，要想保证线性一致性还需要上述 Read Index 流程的 1，3 步骤吗？</li><li>如果开启了 follower read，要想保证线性一致性 leader 还可以 wait-free 吗？</li></ul><p>对于第一个问题，我的想法是不需要。因为这个时候读写请求都在 leader 上进行，那么整个系统表现的相当于只有一个副本。分析理论的话：对于一个写入成功的写操作，其状态一定已经被 apply 到了 leader 的状态机上，所以与其有全局偏序关系的后续读请求在执行时一定能够感知到这个写操作，这满足线性一致性；如果没有全局偏序关系，则该读请求和上一个写请求就是并发请求，那么是否感知到这个写操作都是满足线性一致性的，而且一旦该读请求感知到了这个写操作，后续与其有全局偏序的读请求就都能感知到这个写操作，这也是满足线性一致性的。这也是 <a href="https://pingcap.com/blog-cn/linearizability-and-raft/" target="_blank" rel="noopener">PingCAP 线性一致性读博客</a> 中 wait-free 优化的具体含义：</p><blockquote><p>到此为止 Lease 省去了 ReadIndex 的第二步，实际能再进一步，省去第 3 步。这样的 LeaseRead 在收到请求后会立刻进行读请求，不取 commit index 也不等状态机。由于 Raft 的强 Leader 特性，在租期内的 Client 收到的 Resp 由 Leader 的状态机产生，所以只要状态机满足线性一致，那么在 Lease 内，不管何时发生读都能满足线性一致性。有一点需要注意，只有在 Leader 的状态机应用了当前 term 的第一个 Log 后才能进行 LeaseRead。因为新选举产生的 Leader，它虽然有全部 committed Log，但它的状态机可能落后于之前的 Leader，状态机应用到当前 term 的 Log 就保证了新 Leader 的状态机一定新于旧 Leader，之后肯定不会出现 stale read。</p></blockquote><p>对于第二个问题，我的想法是不可以。我们设想一个 follower apply 比 leader 快的场景（比如 leader 的磁盘是 HDD，follower 的磁盘是 SSD），比如 leader 和 follower 的日志本来均为 <code>[1，2]</code>，此时一个客户端执行了一个写请求，leader 将其进行了广播并进行了 commit，然后正在很慢的异步 apply 中，此时 leader 的日志为 <code>[1,2,3]</code>，commitIndex 为 3，applyIndex 为 2，follower 的日志为 <code>[1,2,3]</code>，commitIndex 为 3，applyIndex 为 3。此时另一个并发的客户端发起了一个查询请求，该查询请求路由到了 follower，follower 用了上述 Read Index 的步骤拿到了 leader 的 commitIndex 3 并确定自己的 applyindex &gt;= 3 后对状态机进行了查询然后返回。接着该客户端又发起了一个查询请求，该查询请求路由到了 leader，此时 leader 如果采用 wait-free 的方式，则只能对 applyindex 为 2 的状态机进行查询，那么就可能返回旧的数据。虽然此时这两个读请求和另一个写请求是并发关系，是否保证这个写操作的状态都符合线性一致性，但线性一致性还规定一旦读请求感知到了某个写操作，则与这个读请求有全局偏序关系的后续读请求都应该感知到这个写操作，那么这个例子描述的场景就不符合线性一致性了。通过这个例子我们可以看到，如果开启了 follower read，要想保证线性一致性 leader 不能再采用 wait-free 直接读的方式，必须获取 Read Index 才能保证线性一致性，这一点也可以参考 PingCAP CTO 的 <a href="https://zhuanlan.zhihu.com/p/78164196" target="_blank" rel="noopener">博客</a>。</p><p>做一个总结：</p><ul><li>如果不做 follower read 的优化，读吞吐无法随节点个数线性提升，但 leader 可以采用 wait-free 的方式对状态机直接做读操作，这样可以保证线性一致性。（注意：仍然需要通过心跳或 lease 的方式确保自己是 leader）</li><li>如果做了 follower read 的优化，读吞吐可以随节点个数线性提升，但 leader 不能再采用 wait-free 的方式对状态机直接做读操作，需要严格按照 Read Index 或 Lease Read 的方式才可以保证线性一致性。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客首先简单介绍了若干一致性模型，然后介绍了一致性和共识的关系，最后对于 zab 和 raft 的一致性模型进行了较为详细的分析讨论。此外，在撰写博客的过程中也发现了一些优质博客如下：</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/35596768" target="_blank" rel="noopener">分布式系统的一致性与共识性</a></li><li><a href="https://blog.csdn.net/chao2016/article/details/81149674" target="_blank" rel="noopener">强一致性、顺序一致性、弱一致性和共识</a></li><li><a href="https://zhuanlan.zhihu.com/p/48782892" target="_blank" rel="noopener">[译] 分布式系统中的一致性模型</a></li><li><a href="https://feilengcui008.github.io/post/raft%E8%AF%BB%E8%AF%B7%E6%B1%82/" target="_blank" rel="noopener">Raft 读请求性能分析</a></li><li><a href="https://segmentfault.com/a/1190000022248118" target="_blank" rel="noopener">共识、线性一致性与顺序一致性（强推！）</a></li><li><a href="https://mp.weixin.qq.com/s/qnvl_msvw0XL7hFezo2F4w" target="_blank" rel="noopener">条分缕析分布式：到底什么是一致性？（强推！）</a></li><li><a href="https://mp.weixin.qq.com/s/3odLhBtebF4cm58hl-87JA" target="_blank" rel="noopener">条分缕析分布式：浅析强弱一致性（强推！）</a></li><li><a href="https://mp.weixin.qq.com/s/wkXsRufVsbKqTwjzTgNqYQ" target="_blank" rel="noopener">条分缕析分布式：因果一致性和相对论时空（强推！）</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FLP 不可能定理介绍</title>
    <link href="/flp-theory/"/>
    <url>/flp-theory/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>FLP 不可能定理与 CAP，BASE 定理等一样，都是分布式系统的基本理论，因此我们有必要了解该理论。</p><p>本博客摘抄了此 <a href="https://mp.weixin.qq.com/s/LOUDWn7evcePCPGWar8vEA" target="_blank" rel="noopener">博客</a> 中对 FLP 不可能定理的部分描述。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>1985 年，Fisher、Lynch、Paterson 三位科学家就发表了关于分布式一致性问题的不可能定理：在完全异步的分布式网络中，故障容错问题无法被解决。（ <code>We have shown that a natural and important problem of fault-tolerant cooperative computing cannot be solved in a totally asynchronous model of computation</code>）</p><p>说得更直白点：在异步网络中，不可能存在能够容忍节点故障的一致性算法，哪怕只有一个节点故障。并且这里并没有考虑拜占庭错误，而是假设网络非常稳定、所有的消息都能被正确传递、并且仅被传递一次，即便如此都不可能找到能容忍哪怕只有一个节点失效的一致性协议，可见该结论有多强。（ <code>In this paper, we show the surprising result that no completely asynchronous consensus protocol can tolerate even a single unannounced process death. We do not consider Byzantine failures, and we assume that the message system is reliableit delivers all messages correctly and exactly once</code>）</p><p>现实生活中的系统往往都是异步系统。因为系统中各个节点之间的延时，是否宕机等等都是不确定的。那么，在最小化异步模型系统中，是否存在一个可以解决一致性问题的确定性共识算法？</p><p>FLP 不可能定理的最大适用前提是异步网络模型。何为同步、异步模型呢？</p><ul><li>所谓异步模型，是说从一个节点到另一个节点的消息延迟是有限的，但可能是无界的（finite but can be unbounded）。这就意味着如果一个节点没有收到消息，它无法判断消息到底是丢失了，还是只是延迟了。也就是说，我们无法通过超时时间来判断某个节点是否故障。</li><li>所谓同步模型，是说消息传递的延迟是有限的，且是有界的。这就意味着我们可以通过经验或采样精确估算消息的最大可能延迟，从而可以通过超时时间来确定消息是否丢失、节点是否故障。</li></ul><p>所幸的是，我们所处于的真实的网络世界更接近同步模型，在很多场景上，我们都可以通过经验或采样确定最大超时时间。举个通俗点的例子：你给朋友快递了一本书，朋友过了 3 天还没收到，此时朋友很难判断到底是快递延迟了，还是快递出问题送丢了。但是如果过了一个月，朋友仍没收到书，基本就可以断定快递送丢了。而背后的推论就是基于经验或统计：通常快递都能在 1-2 周内送达。显然，异步模型其实是反映了节点间通讯的最差情况、极端情况，异步模型包含了同步模型，即能在异步模型上有效的一致性协议，在同步模型上也同样有效。而同步模型是对异步模型做了修正和约束，从而使得更接近真实世界，也使得在实践中一致性问题有可能得到有效解。</p><p>另外，即便是在异步网络模型下，FLP 也并不意味着一致性永远无法达成，只是说无法保证在有界的时间（in bounded time）内达成。在实践上，如果放宽对 bounded time 的限制，仍然是有可能找到实践中的解法的。</p><p>根据 DLS 的 <a href="http://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf" target="_blank" rel="noopener">研究</a>，一致性算法按照网络模型可以分为三大类：</p><ul><li>部分同步网络模型（partially synchronous model）中的一致性协议可以容忍最多 1/3 的任意错误。这里的部分同步模型是指网络延迟是有界的，但是我们无法提前得知。这里的容错也包含了拜占庭类错误。</li><li>异步网络模型（asynchronous model）中的确定性协议无法容忍错误。这里的异步模型即是前文所说的网络延迟是无界的。该结论其实就是 FLP 不可能定理的含义，在完全异步网络中的确定性协议不能容忍哪怕只有一个节点的错误。</li><li>同步网络模型（synchronous model）可以达到惊人的 100% 容错，虽然对错误节点超过 1/2 时的节点行为有限制。这里的同步模型是指网络延迟一定是有界的，即小于某个已知的常数。</li></ul><p>从另一个角度来理解，FLP 实际上考虑了分布式系统的 3 个属性：安全 (safety)、活性（liveness)、容错：</p><ul><li>安全是说系统内各个节点达成的值是一致的、有效的。safety 其实是保证系统一致性运行的最低要求，其核心是 cannot do something bad，即不能干坏事、不能做错事。</li><li>活性是说系统内各个节点最终（在有限时间内）必须能够达成一致，即系统必须能够向前推进，不能永远处于达不成一致的状态。liveness 其实是更高要求，意味着不能只是不干坏事，也不能一直不干事，you must do something good，即必须使得整个系统能良好运转下去。</li><li>容错是说该协议在有节点故障的情况下也必须能有效。</li></ul><p>FLP 不可能定理其实意味着在异步网络中，不可能存在同时满足这三者的分布式一致性协议。因为分布式环境中，节点故障几乎是必然的，因此容错是必须要考虑的因素，所以 FLP 不可能定理就意味着一致性协议在能做到容错的情况下，没办法同时做到安全性与系统活性。通常在实践中，我们可以做出部分牺牲，比如牺牲一部分安全性，意味着系统总能很快达成结论，但结论的可靠性不足；或者牺牲一部分系统活性，意味着系统达成的结论非常可靠，但可能长时间、甚至永远都在争论中，无法达成结论。所幸的是，很多时候现实世界的鲁棒性很强，使一致性协议失效的倒霉事件发生的概率也很可能极低。例如分布式共识协议 Paxos 和 Raft 都是保证了容错性和 safety，然后通过随机超时时间来规避 liveness 的问题。</p><p><img src="/flp-theory/flp.png" srcset="/img/loading.gif" lazyload alt></p><p>FLP 不可能定理的推导和应用可以参考此 <a href="https://www.daimajiaoliu.com/daima/479430766100400" target="_blank" rel="noopener">博客</a>。</p><p>此外，有关论文 <a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf" target="_blank" rel="noopener">Impossibility of Distributed Consensus with One Faulty Process</a> 的阅读博客可以参考 <a href="https://www.inlighting.org/archives/understand-flp-impossibility/" target="_blank" rel="noopener">理解 FLP-Impossibility 论文</a>。</p><h2 id="与-CAP-定理的区别"><a href="#与-CAP-定理的区别" class="headerlink" title="与 CAP 定理的区别"></a>与 CAP 定理的区别</h2><p>CAP 与 FLP 看起来有相似之处，其实二者并不尽相同，二者是从不同的维度思考问题，另外即使是很相似的概念，内涵也并不完全一样。比如：</p><ul><li>FLP 面对的是分布式一致性问题，而 CAP 面对的是分布式网络中的数据同步与复制。</li><li>FLP 是说在异步网络模型中，三者不可能同时实现；而 CAP 是说在所有场景下，三者都不可能同时实现。</li><li>FLP 中的 liveness 强调的是一致性算法的内在属性；而 CAP 中的 availability 强调的是一致性算法对外呈现的外在属性。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客摘抄了部分优质博客对 FLP 不可能定理的介绍，以做学习记录和索引。</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Time, Clocks, and the Ordering of Events in a Distributed System 论文阅读</title>
    <link href="/time-clock-order-in-distributed-system-thesis/"/>
    <url>/time-clock-order-in-distributed-system-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>这篇论文是 Leslie Lamport 于 1978 年发表的，并在 2007 年被选入 SOSP 的名人堂，被誉为第一篇真正的”分布式系统”论文，该论文曾一度成为计算机科学史上被引用最多的论文（截止 2022 年 3 月 6 日已达到 13071 次）。论文的作者 Lamport 享有分布式计算原理之父的美誉，并且因其对分布式系统研究作出的卓越贡献，于 2013 年被授予了图灵奖。</p><p>这篇论文之所以经典，是因为它揭示了分布式系统的某些深层本质，深深地影响了人们对于分布式系统的思考方式。</p><p>当然，这篇论文除了理论意义和历史价值之外，它与业界一些重要的分布式系统实践也都有紧密的联系。比如，在大规模的分布式环境下产生单调递增的时间戳，是个很难的问题，而谷歌的全球级分布式数据库 Spanner 就解决了这个问题，甚至能够在跨越遍布全球的多个数据中心之间高效地产生单调递增的时间戳。做到这一点，靠的是一种称为 TrueTime 的机制，而这种机制的理论基础就是 Lamport 这篇论文中的物理时钟算法（两者之间有千丝万缕的联系）。再比如，这篇论文中定义的「Happened Before」关系，不仅在分布式系统设计中成为考虑不同事件之间关系的基础，而且在多线程编程模型中也是重要的概念。另外，还有让很多人忽视的一点是，利用分布式状态机来实现数据复制的通用方法（Replicated State Machine，简称 RSM），其实也是这篇论文首创的。</p><p>总之，如果在整个分布式的技术领域中，你只有精力阅读一篇论文，那一定要选这一篇了。只有理解了这篇论文中揭示的这些涉及时间、时钟和排序的概念，我们才能真正在面对分布式系统的设计问题时游刃有余。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>本来想写点什么，但是又感觉写的都是垃圾。因此只能强推这篇 <a href="https://mp.weixin.qq.com/s/FZnJLPeTh-bV0amLO5CnoQ" target="_blank" rel="noopener">博客</a>，将这篇论文讲的十分透彻，我跪了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文首先介绍了应该如何认识时间，时钟和排序，接着引入了偏序关系，全序关系，逻辑时钟，物理时钟等概念，最后给出了现实世界中一种可行的为所有事件排序的方案。</p><p>对于为分布式系统中的所有事件进行排序这个问题，Lamport 首先指出简单的物理时钟是不可行的，因为一方面物理时钟很难绝对准确，另一方面不同进程的物理时钟也一定会有误差，因此需要先从逻辑时钟入手。</p><p>为此，Lamport 利用逻辑时钟定义了偏序关系：偏序关系能够为进程内部的事件和进程之间的因果事件排序，对于进程之间的独立事件无法排序。其实从系统内部的视角来看，对进程之间的独立事件进行排序本无意义。</p><p>因此，Lamport 在偏序关系的基础上又定义了全序关系：即通过一些人为规定的方式，可以把进程之间的独立事件进行排序，这样再结合偏序关系即可达到排序所有事件的理想效果，复制状态机的思想便起源于这里。</p><p>然而，这样人为规定的全序方案在现实世界来看可能违背因果一致性，产生这个现象的根本原因是逻辑时钟没有和真实的物理时钟绑定。即对于两个进程间的独立事件，系统无法感知到这两个事件在现实世界中有先后关系，所以可能给时间上发生更晚的事件指定更小的逻辑时间。因此我们得出结论：要想为分布式系统的所有事件排序，仅仅使用逻辑时钟是不行的，还是需要使用物理时钟才行。</p><p>在牛顿的物理体系下，时间是绝对的。在爱因斯坦的物理体系下，时间是相对的。根据相对论，任何信息传递的速度，最快就是光速。而一个事件要想对另一个事件产生影响，至少要在那个事件发生之前传递一定的信息到达所在的空间位置。举个最简单的例子，太阳光从太阳表面射出后大约需要 8.3 分钟才能到达地球，那么即使太阳发生了大爆炸，至少也需要 8.3 分钟才能对地球产生实质影响。</p><p>基于此，Lamport 结合相对论的知识介绍了我们所在的现实世界就是一种偏序时空，并进一步证明：如果物理时钟的误差能够限定到一个范围内，则违反因果一致性的现象就不会出现，即我们便可以为分布式系统中的所有事件排序。简单来讲：对于两个进程间的独立事件，如果他们在物理世界中存在时空偏序关系，那信息的传递也需要一定的时间。只要系统能够保证：系统内部的时间误差不会超过两个外部事件产生因果关系的时间，则就能够正确的为所有事件排序。这也是 Google TrueTime 正确性的理论支撑。</p><p>一个分布式系统自成宇宙，它是对现实世界的一种刻画。分布式系统由不同的进程组成，而不同的进程分布在不同的空间，每个进程可以看成一个单独的参照系。当我们按照这样的观点重新审视这个世界的时候，会产生一些很有意思的想法。</p><p>分布式系统是一个模拟系统。如果仅仅使用逻辑时钟，就相当于在使用一种系统内部自洽的方式对时间进行了模拟。由于逻辑时钟跟物理时间无关，因此我们站在系统内是不能感知到现实世界的时间流逝的。系统之所以会发现违反了因果一致性，是因为存在一种系统外的信息传递方式。</p><p>假设我们生活在模拟系统内部，我们会发现，有人在一个较早的逻辑时刻（对应较小的时间戳）接收到了其他人在较晚的逻辑时刻（对应较大的时间戳）的信息，相当于接收到了来自未来的信息，而且这个信息是通过不在这个系统内的某种机制传递的。据此，我们也许不需要特意“向外看”，就能推断出在这个系统外部，还有一个世界（我们的这个现实世界）。</p><p>同理，在我们当前生活的这个现实世界中，信息传递的速度受限于光速，而且时间永远向前流逝。也许某一天，我们发现了某种超越光速的信息传递手段，或者我们接收到了来自未来的信息（意味着我们可以预知未来了），那么，也许就说明，在我们这个世界的底层，还有一个更大的未知世界存在在那里。</p><p>在诺兰的《星际穿越》中，<code>爱是我们唯一能感知到穿越时空维度的东西</code>作为主旨贯穿了整部电影。主角在黑洞内用爱穿越了时空维度的限制，向女儿传递了缺少的关键数据，女儿也正是意识到这一点才带领人类走出了绝境。光不能逃逸黑洞，但爱可以，这是多么浪漫的主旨呀。</p><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>说起来有些感慨，这篇学术论文不仅深入到了分布式系统的基础层面，还延伸到了宇宙的本质，引起了我们对世界的无限遐想。</p><p>在我的内心深处，毫无疑问这篇论文是我读过的最佳论文，没有之一。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://mp.weixin.qq.com/s/FZnJLPeTh-bV0amLO5CnoQ" target="_blank" rel="noopener">分布式领域最重要的一篇论文，到底讲了什么？</a></li><li><a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf" target="_blank" rel="noopener">论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VM-FT 论文阅读</title>
    <link href="/vm-ft-thesis/"/>
    <url>/vm-ft-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本论文主要介绍了一个用于提供容错虚拟机 (fault-tolerant virtual machine) 的企业级商业系统，该系统包含了两台位于不同物理机的虚拟机，其中一台为 primary，另一台为 backup，backup 备份了 primary 的所有执行。当 primary 出现故障时，backup 可以上线接管 primary 的工作，以此来提供容错。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>论文内容可以参考此 <a href="https://www.cnblogs.com/brianleelxt/p/13245754.htmls" target="_blank" rel="noopener">博客</a> 和此 <a href="https://developer.51cto.com/art/202103/649693.htm" target="_blank" rel="noopener">博客</a>。</p><h2 id="分布式容错方案"><a href="#分布式容错方案" class="headerlink" title="分布式容错方案"></a>分布式容错方案</h2><p>分布式系统中需要对一份数据进行冗余存储才能提供容错性，因此问题是：</p><blockquote><p>如果有一份会随时变动的数据，如何确保它正确地存储于网络中的几台不同机器之上？</p></blockquote><p>对于 primary/backup 型的同步方式，可行的解决方案有两种：状态转移（State Transfer）和操作转移（Operation Transfer）。</p><h3 id="状态转移"><a href="#状态转移" class="headerlink" title="状态转移"></a>状态转移</h3><p>对于状态转移，其方案是 primary 持续地将所有状态（包括 CPU、内存和 I/O 设备等或者整个状态机实例）变化发送给 backup，backup 不需要耗费太多 CPU 资源就可以达到跟 leader 相同的状态，这也导致传输的数据量往往会大很多。当然也可以有一些优化，比如只传送相比上次变化的数据等等，但总之这种方法所需带宽非常大，延迟较高，因此在工业界中应用不多。</p><h3 id="操作转移"><a href="#操作转移" class="headerlink" title="操作转移"></a>操作转移</h3><p>操作转移能够运行的前提是状态机，其特性是：</p><blockquote><p>任何初始状态一样的状态机，如果执行的命令序列一样，则最终达到的状态也一样。如果将此特性应用在多参与者进行协商共识上，可以理解为系统中存在多个具有完全相同的状态机（参与者），这些状态机能最终保持一致的关键就是起始状态完全一致和执行命令序列完全一致。</p></blockquote><p>操作转移一般有两种复制级别：</p><ul><li>机器级别：按序复制 CPU 指令，中断，客户端请求等等来保证不同节点间状态一致，这也就是本文的解决方案。这种方案需要解决若干问题，比如多节点间如何处理不明确性命令（获取当前时间），如果避免脑裂等等。看了论文之后，感觉很多关键点在论文中并没有纰漏实现细节，比如 disk server，test-and-set 等。</li><li>应用级别：按序复制明确性的操作来保证不同节点间的状态一致。比如 MySQL Cluster 的主从全同步复制需要保证所有的从节点接受成功才能返回成功，这一定程度上会导致扩展性受限，即每增加一个 Slave 节点，都导致造成整个系统可用性风险增加一分。因此也出现了基于 Paxos，Raft 的 quorum 同步方案，即一旦系统中过半数的节点中完成了状态的转换，就认为数据的变化已经被正确地存储在系统当中，这样就可以容忍少数（通常是不超过半数）的节点失联，使得增加机器数量对系统整体的可用性变成是有益的，这也是目前大多数应用的容错方案。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>作为一篇 10 年前的论文，在那时 Raft 还没有出现，Paxos 还没有得到广泛的承认，该论文对于分布式容错方案提出了一种基于机器级别的操作转移方案，拓展了理论的边界并证明了工业界可用，可以说是比较划时代的贡献了。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-vm-ft.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/4.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://dl.acm.org/doi/pdf/10.1145/1899928.1899932" target="_blank" rel="noopener">论文</a></li><li><a href="https://icyfenix.cn/distribution/consensus/" target="_blank" rel="noopener">分布式共识算法讲解</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GFS 论文阅读</title>
    <link href="/gfs-thesis/"/>
    <url>/gfs-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>单机文件系统我们见得已经很多，像 xfs，ext4 等等都已经是很出名的单机文件系统。然而，单机文件系统的容量始终是有限的，随着数据量的不断增大，就算对单机不断的 scale up 也会逐渐达到上限。因此，支持 scale out 的分布式文件系统是技术的必然。作为世界上数据量可能最多的公司，Google 在 21 世纪初就已经遇到了这个挑战，随之其开发了 GFS 这个创时代的分布式文件系统并将该成果发表在了 2003 年的 SOSP 会议上，之后随着 MapReduce 和 BigTable 论文的发表，Google 的三架马车整整齐齐，掀开了大数据时代的帷幕，引领工业界开始了辉煌的 NoSQL 运动。</p><p>之后，MapReduce 和 BigTable 或多或少都被新时代的大数据技术栈替代和压榨，只有 GFS 在大规模分布式文件系统领域鲜有敌手，只有某些针对不同场景的优化竞品而已，例如针对海量小文件做了优化的 HayStack/F4。总之，即使在 2021 年的今天，学习 GFS 的设计思想也是十分有意义的。</p><p>PS：云改变了分布式文件系统的走向，S3 等正在以成本低，可托管等特性挑战着 HDFS 的地位，例如新起之秀 <a href="https://juicefs.com/" target="_blank" rel="noopener">JuiceFS</a>。他们支持可横向扩展的 TiKV 作为元数据存储，在大数据量下的扩展性上相比 HDFS 有着更优雅的解决方案。</p><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>实现一个高可用，可扩展，高性能，低成本，可容错的大规模分布式文件系统，同时为用户提供近可能简单的文件读写接口并屏蔽底层的复杂实现细节。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本来打算好好的写一篇博客总结一下自己时隔两年后再读 GFS 的理解，但是偶然看到了一篇写的很详细且有作者想法的 <a href="https://spongecaptain.cool/post/paper/googlefilesystem/" target="_blank" rel="noopener">博客</a>，因此就没必要浪费时间自己再写一遍了，感兴趣的可以去详读这篇博客。</p><p>对于博客中所述，有一处有关 chunk version 的地方我个人不太认同，原文如下：</p><blockquote><p>Master 节点在接受到修改请求时，会找此 file 文件最后一个 chunk 的 up-to-date 版本（最新版本），最新版本号应当等于 Master 节点的版本号；</p><p>什么叫最新版本。chunk 使用一个 chunk version 进行版本管理（分布式环境下普遍使用版本号进行管理，比如 Lamport 逻辑时钟）。一个修改涉及 3 个 chunk 的修改，如果某一个 chunk 因为网络原因没能够修改成功，那么其 chunk version 就会落后于其他两个 chunk，此 chunk 会被认为是过时的。</p><p>Master 在选择好 primary 节点后递增当前 chunk 的 chunk version，并通过 Master 的持久化机制持久化；</p><p>通过 Primary 与其他 chunkserver，发送修改此 chunk 的版本号的通知，而节点接收到次通知后会修改版本号，然后持久化；</p><p>Primary 然后开始选择 file 最后一个文件的 chunk 的末尾 offset 开始写入数据，写入后将此消息转发给其他 chunkserver，它们也对相同的 chunk 在 offset 处写入数据；</p></blockquote><p>博客作者认为 Master 维护 chunk version 的步骤是先递增当前 chunk 的 chunk version 再本地持久化，然后通知 Primary。个人认为这样不妥，因为一旦 Master 在持久化完 chunk version 和通知到 Primary 之间挂了，在 Master 重启之后，其会与所有 chunkserver 进行心跳来获取这些 chunkserver 拥有的 chunk 和其 chunk version，接着 Matser 会发现该 chunk 的所有 chunk version 都小于其从磁盘恢复的该 chunk 的 chunk version，从而认为真正持有最新 chunk version 的 chunkserver 还未恢复，进而不为该 chunk 提供服务。</p><p>因此我认为，Master 维护 chunk version 的步骤应该是先递增当前 chunk 的 chunk version 并通知 Primary，得到确切回复后再本地持久化，这样一旦 Master 在期间挂了，其恢复之后会发现 chunkserver 心跳上来的消息中，该 chunk 的 chunk version 大于本地磁盘恢复的 chunk version，从而认为 chunkserver 的 chunk version 最新并更新且持久化本地的 chunk version，进而能够提供服务，这样就与论文中的描述自恰了。</p><p>除以上一点外，其他的细节个人觉得博客都讲的很正确很 make sense 了~</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>优秀的设计往往很简单</li><li>很难设计出一个满足所有业务场景的系统，针对不同的场景会有不同的解决方案</li><li>设计系统时就需要考虑到系统的瓶颈在何处（磁盘，网络，CPU）</li><li>单节点的性能即使不高也没太大问题，扩展性更重要</li></ul><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-gfs.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/3.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf" target="_blank" rel="noopener">论文</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
      <tag>Google</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库系统调优时有关操作系统的知识与测试监控</title>
    <link href="/operating-system-performance-testing/"/>
    <url>/operating-system-performance-testing/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在测试数据库的性能时，往往需要通过从网卡，CPU，内存，磁盘，代码等方面出发进行性能调优，这期间可能会纵向扩展机器以获得更好的性能。然而，在不同的硬件机器上测试时，有时的结果可能与预期相差较多，单从软件方面进行猜想可能并不靠谱。因此，需要对机器硬件进行一定的了解和对应的测试，这样就能够在调优分析时利用底层的硬件信息来支撑瓶颈分析，从而更可能做出正确的判断。本篇博客将从网卡，CPU，内存，磁盘出发来介绍一些基本的知识和性能评测方式，最后也会介绍 Linux 下常用的性能测试工具 sysbench 的使用和性能监控工具 glances 的使用。</p><h2 id="网卡"><a href="#网卡" class="headerlink" title="网卡"></a>网卡</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>网卡，即网络接口卡（network interface card），也叫 NIC 卡，是一种允许网络连接的计算机硬件设备。网卡应用广泛，市场上有许多不同种类，如 PCIE 网卡，服务器网卡。</p><p>基于不同的速度，网卡有 10Mbps，100Mbps， 10/100Mbps 自适应卡，1000Mbps、10Gbps、25Gbps、100Gbps 甚至更高速度的网卡。10Mbps、100Mbps 和 10/100Mbps 自适应网卡适用于小型局域网、家庭或办公室。1000Mbps 网卡可为快速以太网提供更高的带宽。10Gbps, 25Gbps, 100Gbps 网卡以及更高速度的网卡则受到大企业与数据中心的欢迎。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>Linux 下要想得知本机的网卡速率。可以查也可以测。<br>对于查，可以使用 <code>ifconfig</code> 找到网卡对应的设备名，然后使用 <code>ethtool &lt;device&gt;</code> 来查看对应网卡设备的额定速率。如下图所示：<br><img src="/operating-system-performance-testing/ethtool.png" srcset="/img/loading.gif" lazyload alt><br>对于测，可以使用 iperf 或者 iperf3 来测量 tcp/udp 协议的吞吐量，进而测试网卡的性能。当然，由于连接参数（比如客户端连接数，包大小）的不同，测试时可能也跑不满理论带宽，因此对实际线上系统调优操作系统网络栈就是一个可以优化性能的方向。<br>iperf 和 iperf3 的具体使用方式可参考此 <a href="https://www.cnblogs.com/cloudwas/p/13084815.html" target="_blank" rel="noopener">博客</a>。</p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>市面上常说的千兆网卡速率是 1000Mbps，即 125MB/s；万兆网卡速率是 10000Mbps，即 1.22GB/s；十万兆网卡速率是 100000Mbps，即 12.21 GB/s。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><h3 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h3><p>中央处理器（CPU），是电子计算机的主要设备之一，电脑中的核心配件。其功能主要是解释计算机指令以及处理计算机软件中的数据。CPU 是计算机中负责读取指令，对指令译码并执行指令的核心部件。中央处理器主要包括两个部分，即控制器、运算器，其中还包括高速缓冲存储器及实现它们之间联系的数据、控制的总线。</p><p>CPU 的性能与以下衡量指标都有关系，具体可以参考此 <a href="https://mp.weixin.qq.com/s/Hrn9J2l_Di3gZy0BvPcx6A" target="_blank" rel="noopener">博客</a>。</p><ul><li>主频（时钟频率）</li><li>外频（基准频率）</li><li>总线 (FSB) 频率</li><li>CPU 的位和字长</li><li>倍频系数</li><li>缓存</li><li>CPU 内核和 I/O 工作电压</li><li>制造工艺</li><li>指令集</li><li>CPU 扩展指令集</li><li>架构（如 UMA 或者 NUMA 架构），具体可以参考此 <a href="https://www.cnblogs.com/linhaostudy/p/9980383.html" target="_blank" rel="noopener">博客</a>。</li></ul><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>Linux 下想要得知本机有关 CPU 的信息，可以使用 <code>lscpu</code> 指令，其会显示 CPU 的型号，架构，主频大小，缓存大小，物理和逻辑核心数等等，如下图所示。<br><img src="/operating-system-performance-testing/lscpu.png" srcset="/img/loading.gif" lazyload alt></p><p>我们在知道 CPU 型号之后也可以去相关网站寻找更多有关此 cpu 的数据信息，比如 <a href="https://www.cpubenchmark.net/" target="_blank" rel="noopener">PassMark</a>。</p><p>在系统运行过程中，可以评测 CPU 使用率的一个重要参考指标就是平均负载（load average）。如下图所示<br><img src="/operating-system-performance-testing/load.png" srcset="/img/loading.gif" lazyload alt></p><p>平均负载是指单位时间内平均活跃进程数，包括可运行状态的进程数，以及不可中断状态的进程（如等待 IO, 等待硬件设备响应），其可以一定程度上反映一段时间内 CPU 的繁忙程度。但是平均负载高 CPU 的使用率不一定高，其主要表现如下，具体可参考此 <a href="https://www.cnblogs.com/maxwellsky/p/10629564.html" target="_blank" rel="noopener">博客</a>。</p><ul><li>CPU 密集型进程，导致平均负载和 CPU 使用率比较高</li><li>IO 密集型进程，等待 IO 会导致平均负载升高，但是 CPU 使用率不一定高</li><li>等待 CPU 的进程调度也会导致平均负载升高，此时 CPU 使用率也高</li></ul><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h3 id="介绍-2"><a href="#介绍-2" class="headerlink" title="介绍"></a>介绍</h3><p>内存是计算机中重要的部件之一，它是与 CPU 进行沟通的桥梁。计算机中所有程序的运行都是在内存中进行的，因此内存的性能对计算机的影响非常大。内存也被称为内存储器，其作用是用于暂时存放 CPU 中的运算数据，以及与硬盘等外部存储器交换的数据。只要计算机在运行中，CPU 就会把需要运算的数据调到内存中进行运算，当运算完成后 CPU 再将结果传送出来，内存的运行也决定了计算机的稳定运行。内存是由内存芯片、电路板、金手指等部分组成的。</p><p>有关内存的发展，分类等详细信息可以参考 <a href="https://baike.baidu.com/item/%E5%86%85%E5%AD%98" target="_blank" rel="noopener">百度百科</a>。</p><h3 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h3><p>Linux 可以通过 <code>free -h</code> 命令来查看本机的内存大小等等，如下图所示<br><img src="/operating-system-performance-testing/memory.png" srcset="/img/loading.gif" lazyload alt><br>具体参数含义为：</p><ul><li>total：服务器内存总大小：31G</li><li>used：已经使用了多少内存：26G</li><li>free：未被任何应用使用的真实空闲内存</li><li>shared：被共享的物理内存</li><li>buff/cache：缓冲、缓存区内存数，缓存在应用之中</li><li>available：真正剩余的可被程序应用的内存数</li><li>Swap：swap 分区的大小</li></ul><h4 id="free-和-available-的区别"><a href="#free-和-available-的区别" class="headerlink" title="free 和 available 的区别"></a>free 和 available 的区别</h4><p>free 是真正尚未被使用的物理内存数量。<br>available 是应用程序认为可用内存数量，available = free + buffer + cache （注：只是大概的计算方法）</p><p>Linux 为了提升读写性能，会消耗一部分内存资源缓存磁盘数据，对于内核来说，buffer 和 cache 其实都属于已经被使用的内存。但当应用程序申请内存时，如果 free 内存不够，内核就会回收 buffer 和 cache 的内存来满足应用程序的请求。</p><h4 id="buff-和-cache-的区别"><a href="#buff-和-cache-的区别" class="headerlink" title="buff 和 cache 的区别"></a>buff 和 cache 的区别</h4><p>buffer 名为缓冲，cache 名为缓存。</p><p><img src="/operating-system-performance-testing/buffer_cache.png" srcset="/img/loading.gif" lazyload alt></p><ul><li><p>cache：文件系统层级的缓存，从磁盘里读取的内容是存储到这里，这样程序读取磁盘内容就会非常快，比如使用 grep 和 find 等命令查找内容和文件时，第一次会慢很多，再次执行就快好多倍，几乎是瞬间。但如上所说，如果对文件的更新不关心，就没必要清 cache，否则如果要实施同步，必须要把内存空间中的 cache 清楚下。</p></li><li><p>buffer：磁盘等块设备的缓冲，内存的这一部分是要写入到磁盘里的。这种情况需要注意，位于内存 buffer 中的数据不是即时写入磁盘，而是系统空闲或者 buffer 达到一定大小统一写到磁盘中，所以断电易失，为了防止数据丢失所以我们最好正常关机或者多执行几次 sync 命令，让位于 buffer 上的数据立刻写到磁盘里。</p></li></ul><h4 id="swap-是什么"><a href="#swap-是什么" class="headerlink" title="swap 是什么"></a>swap 是什么</h4><p>在 Linux 下，swap 的作用类似 Windows 系统下的“虚拟内存”。当物理内存不足时，拿出部分硬盘空间当 swap 分区（虚拟成内存）使用，从而解决内存容量不足的情况。</p><p>swap 意思是交换，顾名思义，当某进程向 OS 请求内存发现不足时，OS 会把内存中暂时不用的数据交换出去，放在 swap 分区中，这个过程称为 swap out。当某进程又需要这些数据且 OS 发现还有空闲物理内存时，又会把 swap 分区中的数据交换回物理内存中，这个过程称为 swap in。</p><p>当然，swap 大小是有上限的，一旦 swap 使用完，操作系统会触发 OOM-Killer 机制，把消耗内存最多的进程 kill 掉以释放内存。</p><p>有关数据库与 swap 的关系以及 swap 的细节机制可以参考此 <a href="http://hbasefly.com/2017/05/24/hbase-linux/?lkfgjq=xbbdl2&amp;ekpqfu=awbp92" target="_blank" rel="noopener">博客</a>。</p><h3 id="补充-1"><a href="#补充-1" class="headerlink" title="补充"></a>补充</h3><p>CPU 的处理速度一般约为 10GB /s，常用的 DDR4 内存到 CPU 的吞吐一般约在 30GB/s ，所以内存的吞吐量往往不会成为瓶颈。当然，不同的语言对内存管理的方式不同，某些自动管理内存的语言（比如 Java）会出现 STW (Stop the world）的状况来调整内存空间，其会暂停所有用户线程，对性能影响很大。因此，基于业务负载和语言特性制定更好的 GC 策略能够更好地利用 CPU，从而进一步发掘内存的吞吐量。</p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><h3 id="介绍-3"><a href="#介绍-3" class="headerlink" title="介绍"></a>介绍</h3><p>磁盘是指利用磁记录技术存储数据的存储器。 磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失。 早期计算机使用的磁盘是软磁盘（Floppy Disk，简称软盘），如今常用的磁盘是硬磁盘（Hard disk，简称硬盘）。</p><p>目前常见的硬盘大可分为三类：机械硬盘（HDD）采用磁性碟片来存储，固态硬盘（SSD）采用闪存颗粒来存储，混合硬盘（HHD）是把磁性碟片和闪存集成到一起的一种硬盘。</p><p>HDD 和 SSD 的区别主要如下：<br><img src="/operating-system-performance-testing/comparison.jpg" srcset="/img/loading.gif" lazyload alt></p><p>总体上来说，HDD 主要为 SATA 和 SAS 接口，目前家用类别的 HDD 多为 SATA 接口，SAS 接口则为企业级应用。SAS 可满足高性能、高可靠性的应用，SATA 则满足大容量、非关键业务的应用。</p><p>此外业界也常用多块 HDD 来组装磁盘阵列（比如 RAID 5 等等），从而提供更好的吞吐量和磁盘级别的容错，具体细节可参考此 <a href="https://mp.weixin.qq.com/s/WRYQFRnf28RBK3CUkN7REg" target="_blank" rel="noopener">博客</a>。</p><p>至于固态硬盘，其常见接口和速率如下图所示：<br><img src="/operating-system-performance-testing/ssd.jpg" srcset="/img/loading.gif" lazyload alt></p><h3 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h3><p>Linux 可以通过 <code>df -hT</code> 命令来查看本机磁盘设备挂载的磁盘目录，文件系统以及容量等等，如下图所示<br><img src="/operating-system-performance-testing/df.png" srcset="/img/loading.gif" lazyload alt></p><p>此外还可以通过 <code>fdisk -l &lt;device&gt;</code> 命令来查看磁盘设备的源信息，比如可以通过此命令来查看磁盘是 SSD 还是 HDD，如果有”heads”（磁头），”track”（磁道）和”cylinders”（柱面）等等则就是 HDD，否则则是 SSD。如下图所示就是 SSD。<br><img src="/operating-system-performance-testing/fdisk.png" srcset="/img/loading.gif" lazyload alt></p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># SSD 示例</span><br><span class="hljs-attr">Disk /dev/nvme0n1:</span> <span class="hljs-number">238.5</span> <span class="hljs-string">GiB,</span> <span class="hljs-number">256060514304</span> <span class="hljs-string">bytes,</span> <span class="hljs-number">500118192</span> <span class="hljs-string">sectors</span><br><span class="hljs-attr">Units:</span> <span class="hljs-string">sectors</span> <span class="hljs-string">of</span> <span class="hljs-number">1</span> <span class="hljs-string">*</span> <span class="hljs-number">512</span> <span class="hljs-string">=</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span><br><span class="hljs-string">Sector</span> <span class="hljs-string">size</span> <span class="hljs-string">(logical/physical):</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span> <span class="hljs-string">/</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span><br><span class="hljs-string">I/O</span> <span class="hljs-string">size</span> <span class="hljs-string">(minimum/optimal):</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span> <span class="hljs-string">/</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span><br><span class="hljs-attr">Disklabel type:</span> <span class="hljs-string">dos</span><br><span class="hljs-attr">Disk identifier:</span> <span class="hljs-number">0xad91c214</span><br><br><span class="hljs-comment"># HDD 示例</span><br><span class="hljs-attr">Disk /dev/sda:</span> <span class="hljs-number">120.0</span> <span class="hljs-string">GB,</span> <span class="hljs-number">120034123776</span> <span class="hljs-string">bytes</span><br><span class="hljs-number">255</span> <span class="hljs-string">heads,</span> <span class="hljs-number">63</span> <span class="hljs-string">sectors/track,</span> <span class="hljs-number">14593</span> <span class="hljs-string">cylinders</span><br><span class="hljs-string">Units</span> <span class="hljs-string">=</span> <span class="hljs-string">cylinders</span> <span class="hljs-string">of</span> <span class="hljs-number">16065</span> <span class="hljs-string">*</span> <span class="hljs-number">512</span> <span class="hljs-string">=</span> <span class="hljs-number">8225280</span> <span class="hljs-string">bytes</span><br><span class="hljs-string">Sector</span> <span class="hljs-string">size</span> <span class="hljs-string">(logical/physical):</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span> <span class="hljs-string">/</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span><br><span class="hljs-string">I/O</span> <span class="hljs-string">size</span> <span class="hljs-string">(minimum/optimal):</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span> <span class="hljs-string">/</span> <span class="hljs-number">512</span> <span class="hljs-string">bytes</span><br><span class="hljs-attr">Disk identifier:</span> <span class="hljs-number">0x00074f7d</span><br></code></pre></div></td></tr></table></figure><p>如果想要测试磁盘的 IOPS 或者吞吐量，则可以使用一些磁盘测试工具进行测试，如 smartctl，sysbench 等等，后文会介绍如何使用 sysbench 测量磁盘性能。</p><p>有关文件系统的区别（xfs or ext4），可以参考此 <a href="https://segmentfault.com/a/1190000008481493" target="_blank" rel="noopener">博客</a>。至于具体性能，由于上层应用不同，其在不同文件系统上的表现也不同，建议实际测试一下才能知道真实场景下哪个更优秀，一般情况下选择 xfs 就够用了。</p><p>有关磁盘 IO 的理论细节可以参考美团技术团队的 <a href="https://tech.meituan.com/2017/05/19/about-desk-io.html" target="_blank" rel="noopener">博客</a>，十分详细。</p><h3 id="补充-2"><a href="#补充-2" class="headerlink" title="补充"></a>补充</h3><ul><li>吞吐量<ul><li>对于顺序读写，普通的 HDD 的吞吐量一般在 100 MB/s 左右，某些企业级 HDD 能够达到 200 MB/s 左右。对于随机读写，HDD 的性能表现很差，一般是几十兆每秒。</li><li>对于顺序读写，普通的 SSD 的吞吐量一般在 300~500MB/s 左右，某些企业级 SSD（例如适配 PCIE 3.0 接口）甚至能够达到 2GB/s。对于随机读写，SSD 的性能相比顺序读写下降较少，一般也是几百兆每秒。 </li></ul></li><li>时延<ul><li>图胜千言<br><img src="/operating-system-performance-testing/latency.jpg" srcset="/img/loading.gif" lazyload alt></li></ul></li></ul><h2 id="sysbench-测试工具"><a href="#sysbench-测试工具" class="headerlink" title="sysbench 测试工具"></a>sysbench 测试工具</h2><p>sysbench 是一款开源的多线程性能测试工具，可以执行 CPU/内存/线程/IO/数据库等方面的性能测试。<br>sysbench 支持以下几种测试模式 ：</p><ol><li>CPU 运算性能</li><li>内存分配及传输速度</li><li>磁盘 IO 性能</li><li>POSIX 线程性能</li><li>互斥锁性能测试</li><li>数据库性能 (OLTP 基准测试）。目前 sysbench 主要支持 MySQL，PostgreSQL 等几种数据库。</li></ol><p>sysbench 的安装建议直接参考 <a href="https://github.com/akopytov/sysbench" target="_blank" rel="noopener">官方 repo</a>，最详细最不踩坑。具体负载参数可以用 <code>sysbench --help</code> 查看也可以参考官方 repo，当然也可以查看此 <a href="https://blog.51cto.com/3842834/2364563" target="_blank" rel="noopener">博客</a> 和此 <a href="https://blog.51cto.com/cyent/2350925" target="_blank" rel="noopener">博客</a>。</p><p>以下列出几种测试实例：</p><h3 id="CPU-运算性能"><a href="#CPU-运算性能" class="headerlink" title="CPU 运算性能"></a>CPU 运算性能</h3><h4 id="单核性能"><a href="#单核性能" class="headerlink" title="单核性能"></a>单核性能</h4><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=cpu</span> <span class="hljs-string">--cpu-max-prime=5000</span> <span class="hljs-string">run</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">1</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-attr">Prime numbers limit:</span> <span class="hljs-number">5000</span><br><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">CPU speed:</span><br>    <span class="hljs-attr">events per second:</span>  <span class="hljs-number">3325.67</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0004s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">33274</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                    <span class="hljs-number">0.30</span><br>         <span class="hljs-attr">avg:</span>                                    <span class="hljs-number">0.30</span><br>         <span class="hljs-attr">max:</span>                                    <span class="hljs-number">1.21</span><br>         <span class="hljs-attr">95th percentile:</span>                        <span class="hljs-number">0.30</span><br>         <span class="hljs-attr">sum:</span>                                 <span class="hljs-number">9995.62</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">33274.0000</span><span class="hljs-string">/0.00</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">9.9956</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h4 id="多核性能"><a href="#多核性能" class="headerlink" title="多核性能"></a>多核性能</h4><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=cpu</span> <span class="hljs-string">--cpu-max-prime=5000</span> <span class="hljs-string">--threads=192</span> <span class="hljs-string">run</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">192</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-attr">Prime numbers limit:</span> <span class="hljs-number">5000</span><br><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">CPU speed:</span><br>    <span class="hljs-attr">events per second:</span> <span class="hljs-number">411077.30</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0017s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">4112237</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                    <span class="hljs-number">0.30</span><br>         <span class="hljs-attr">avg:</span>                                    <span class="hljs-number">0.46</span><br>         <span class="hljs-attr">max:</span>                                  <span class="hljs-number">147.50</span><br>         <span class="hljs-attr">95th percentile:</span>                        <span class="hljs-number">0.46</span><br>         <span class="hljs-attr">sum:</span>                              <span class="hljs-number">1885541.21</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">21417.9010</span><span class="hljs-string">/378.98</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">9.8205</span><span class="hljs-string">/0.14</span><br></code></pre></div></td></tr></table></figure><h3 id="内存吞吐量"><a href="#内存吞吐量" class="headerlink" title="内存吞吐量"></a>内存吞吐量</h3><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=memory</span> <span class="hljs-string">--memory-block-size=4k</span> <span class="hljs-string">--memory-total-size=740G</span> <span class="hljs-string">run</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">1</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-attr">Running memory speed test with the following options:</span><br>  <span class="hljs-attr">block size:</span> <span class="hljs-string">4KiB</span><br>  <span class="hljs-attr">total size:</span> <span class="hljs-string">757760MiB</span><br>  <span class="hljs-attr">operation:</span> <span class="hljs-string">write</span><br>  <span class="hljs-attr">scope:</span> <span class="hljs-string">global</span><br><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">Total operations:</span> <span class="hljs-number">31972684</span> <span class="hljs-string">(3195628.16</span> <span class="hljs-string">per</span> <span class="hljs-string">second)</span><br><br><span class="hljs-number">124893.30</span> <span class="hljs-string">MiB</span> <span class="hljs-string">transferred</span> <span class="hljs-string">(12482.92</span> <span class="hljs-string">MiB/sec)</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0001s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">31972684</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                    <span class="hljs-number">0.00</span><br>         <span class="hljs-attr">avg:</span>                                    <span class="hljs-number">0.00</span><br>         <span class="hljs-attr">max:</span>                                    <span class="hljs-number">0.10</span><br>         <span class="hljs-attr">95th percentile:</span>                        <span class="hljs-number">0.00</span><br>         <span class="hljs-attr">sum:</span>                                 <span class="hljs-number">7085.34</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">31972684.0000</span><span class="hljs-string">/0.00</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">7.0853</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h3 id="磁盘性能"><a href="#磁盘性能" class="headerlink" title="磁盘性能"></a>磁盘性能</h3><h4 id="顺序读写"><a href="#顺序读写" class="headerlink" title="顺序读写"></a>顺序读写</h4><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=fileio</span> <span class="hljs-string">--num-threads=1</span> <span class="hljs-string">--file-num=20</span> <span class="hljs-string">--file-total-size=4G</span> <span class="hljs-string">--file-test-mode=seqrewr</span> <span class="hljs-string">prepare(run)</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">1</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-attr">Extra file open flags:</span> <span class="hljs-string">(none)</span><br><span class="hljs-number">20</span> <span class="hljs-string">files,</span> <span class="hljs-number">204.</span><span class="hljs-string">8MiB</span> <span class="hljs-string">each</span><br><span class="hljs-string">4GiB</span> <span class="hljs-string">total</span> <span class="hljs-string">file</span> <span class="hljs-string">size</span><br><span class="hljs-string">Block</span> <span class="hljs-string">size</span> <span class="hljs-string">16KiB</span><br><span class="hljs-string">Periodic</span> <span class="hljs-string">FSYNC</span> <span class="hljs-string">enabled,</span> <span class="hljs-string">calling</span> <span class="hljs-string">fsync()</span> <span class="hljs-string">each</span> <span class="hljs-number">100</span> <span class="hljs-string">requests.</span><br><span class="hljs-string">Calling</span> <span class="hljs-string">fsync()</span> <span class="hljs-string">at</span> <span class="hljs-string">the</span> <span class="hljs-string">end</span> <span class="hljs-string">of</span> <span class="hljs-string">test,</span> <span class="hljs-string">Enabled.</span><br><span class="hljs-string">Using</span> <span class="hljs-string">synchronous</span> <span class="hljs-string">I/O</span> <span class="hljs-string">mode</span><br><span class="hljs-string">Doing</span> <span class="hljs-string">sequential</span> <span class="hljs-string">rewrite</span> <span class="hljs-string">test</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">File operations:</span><br>    <span class="hljs-attr">reads/s:</span>                      <span class="hljs-number">0.00</span><br>    <span class="hljs-attr">writes/s:</span>                     <span class="hljs-number">50759.51</span><br>    <span class="hljs-attr">fsyncs/s:</span>                     <span class="hljs-number">10153.80</span><br><br><span class="hljs-attr">Throughput:</span><br>    <span class="hljs-string">read,</span> <span class="hljs-attr">MiB/s:</span>                  <span class="hljs-number">0.00</span><br>    <span class="hljs-string">written,</span> <span class="hljs-attr">MiB/s:</span>               <span class="hljs-number">793.07</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0011s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">609479</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                    <span class="hljs-number">0.00</span><br>         <span class="hljs-attr">avg:</span>                                    <span class="hljs-number">0.02</span><br>         <span class="hljs-attr">max:</span>                                    <span class="hljs-number">1.68</span><br>         <span class="hljs-attr">95th percentile:</span>                        <span class="hljs-number">0.01</span><br>         <span class="hljs-attr">sum:</span>                                 <span class="hljs-number">9834.28</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">609479.0000</span><span class="hljs-string">/0.00</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">9.8343</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h4 id="乱序读写"><a href="#乱序读写" class="headerlink" title="乱序读写"></a>乱序读写</h4><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=fileio</span> <span class="hljs-string">--num-threads=1</span> <span class="hljs-string">--file-num=20</span> <span class="hljs-string">--file-total-size=4G</span> <span class="hljs-string">--file-test-mode=rndrw</span> <span class="hljs-string">prepare(run)</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">1</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-attr">Extra file open flags:</span> <span class="hljs-string">(none)</span><br><span class="hljs-number">20</span> <span class="hljs-string">files,</span> <span class="hljs-number">204.</span><span class="hljs-string">8MiB</span> <span class="hljs-string">each</span><br><span class="hljs-string">4GiB</span> <span class="hljs-string">total</span> <span class="hljs-string">file</span> <span class="hljs-string">size</span><br><span class="hljs-string">Block</span> <span class="hljs-string">size</span> <span class="hljs-string">16KiB</span><br><span class="hljs-attr">Number of IO requests:</span> <span class="hljs-number">0</span><br><span class="hljs-attr">Read/Write ratio for combined random IO test:</span> <span class="hljs-number">1.50</span><br><span class="hljs-string">Periodic</span> <span class="hljs-string">FSYNC</span> <span class="hljs-string">enabled,</span> <span class="hljs-string">calling</span> <span class="hljs-string">fsync()</span> <span class="hljs-string">each</span> <span class="hljs-number">100</span> <span class="hljs-string">requests.</span><br><span class="hljs-string">Calling</span> <span class="hljs-string">fsync()</span> <span class="hljs-string">at</span> <span class="hljs-string">the</span> <span class="hljs-string">end</span> <span class="hljs-string">of</span> <span class="hljs-string">test,</span> <span class="hljs-string">Enabled.</span><br><span class="hljs-string">Using</span> <span class="hljs-string">synchronous</span> <span class="hljs-string">I/O</span> <span class="hljs-string">mode</span><br><span class="hljs-string">Doing</span> <span class="hljs-string">random</span> <span class="hljs-string">r/w</span> <span class="hljs-string">test</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">File operations:</span><br>    <span class="hljs-attr">reads/s:</span>                      <span class="hljs-number">43044.01</span><br>    <span class="hljs-attr">writes/s:</span>                     <span class="hljs-number">28696.01</span><br>    <span class="hljs-attr">fsyncs/s:</span>                     <span class="hljs-number">14348.50</span><br><br><span class="hljs-attr">Throughput:</span><br>    <span class="hljs-string">read,</span> <span class="hljs-attr">MiB/s:</span>                  <span class="hljs-number">672.54</span><br>    <span class="hljs-string">written,</span> <span class="hljs-attr">MiB/s:</span>               <span class="hljs-number">448.36</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0007s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">861345</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                    <span class="hljs-number">0.00</span><br>         <span class="hljs-attr">avg:</span>                                    <span class="hljs-number">0.01</span><br>         <span class="hljs-attr">max:</span>                                    <span class="hljs-number">0.41</span><br>         <span class="hljs-attr">95th percentile:</span>                        <span class="hljs-number">0.04</span><br>         <span class="hljs-attr">sum:</span>                                 <span class="hljs-number">9816.61</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">861345.0000</span><span class="hljs-string">/0.00</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">9.8166</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h3 id="POSIX-线程性能"><a href="#POSIX-线程性能" class="headerlink" title="POSIX 线程性能"></a>POSIX 线程性能</h3><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span>  <span class="hljs-string">--test=threads</span> <span class="hljs-string">--num-threads=200</span> <span class="hljs-string">--thread-yields=100</span> <span class="hljs-string">--thread-locks=1</span> <span class="hljs-string">run</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">200</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">10.</span><span class="hljs-string">0140s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">54268</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                   <span class="hljs-number">11.03</span><br>         <span class="hljs-attr">avg:</span>                                   <span class="hljs-number">36.88</span><br>         <span class="hljs-attr">max:</span>                                   <span class="hljs-number">86.79</span><br>         <span class="hljs-attr">95th percentile:</span>                       <span class="hljs-number">47.47</span><br>         <span class="hljs-attr">sum:</span>                              <span class="hljs-number">2001322.28</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">271.3400</span><span class="hljs-string">/3.10</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">10.0066</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h3 id="互斥锁性能"><a href="#互斥锁性能" class="headerlink" title="互斥锁性能"></a>互斥锁性能</h3><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-string">&gt;</span> <span class="hljs-string">sudo</span> <span class="hljs-string">sysbench</span> <span class="hljs-string">--test=mutex</span> <span class="hljs-string">--mutex-num=2048</span> <span class="hljs-string">--mutex-locks=20000</span> <span class="hljs-string">--mutex-loops=5000</span> <span class="hljs-string">run</span><br><br><span class="hljs-string">sysbench</span> <span class="hljs-number">1.0</span><span class="hljs-number">.20</span> <span class="hljs-string">(using</span> <span class="hljs-string">bundled</span> <span class="hljs-string">LuaJIT</span> <span class="hljs-number">2.1</span><span class="hljs-number">.0</span><span class="hljs-string">-beta2)</span><br><br><span class="hljs-attr">Running the test with following options:</span><br><span class="hljs-attr">Number of threads:</span> <span class="hljs-number">1</span><br><span class="hljs-string">Initializing</span> <span class="hljs-string">random</span> <span class="hljs-string">number</span> <span class="hljs-string">generator</span> <span class="hljs-string">from</span> <span class="hljs-string">current</span> <span class="hljs-string">time</span><br><br><span class="hljs-string">Initializing</span> <span class="hljs-string">worker</span> <span class="hljs-string">threads...</span><br><br><span class="hljs-string">Threads</span> <span class="hljs-string">started!</span><br><br><span class="hljs-attr">General statistics:</span><br>    <span class="hljs-attr">total time:</span>                          <span class="hljs-number">0.</span><span class="hljs-string">0387s</span><br>    <span class="hljs-attr">total number of events:</span>              <span class="hljs-number">1</span><br><br><span class="hljs-string">Latency</span> <span class="hljs-string">(ms):</span><br>         <span class="hljs-attr">min:</span>                                   <span class="hljs-number">38.49</span><br>         <span class="hljs-attr">avg:</span>                                   <span class="hljs-number">38.49</span><br>         <span class="hljs-attr">max:</span>                                   <span class="hljs-number">38.49</span><br>         <span class="hljs-attr">95th percentile:</span>                       <span class="hljs-number">38.25</span><br>         <span class="hljs-attr">sum:</span>                                   <span class="hljs-number">38.49</span><br><br><span class="hljs-attr">Threads fairness:</span><br>    <span class="hljs-string">events</span> <span class="hljs-string">(avg/stddev):</span>           <span class="hljs-number">1.0000</span><span class="hljs-string">/0.00</span><br>    <span class="hljs-string">execution</span> <span class="hljs-string">time</span> <span class="hljs-string">(avg/stddev):</span>   <span class="hljs-number">0.0385</span><span class="hljs-string">/0.00</span><br></code></pre></div></td></tr></table></figure><h2 id="glances-监控工具"><a href="#glances-监控工具" class="headerlink" title="glances 监控工具"></a>glances 监控工具</h2><p>glances 是一个基于 python 语言开发，可以为 Linux 或者 Unix 性能提供监视和分析性能数据的功能。glances 在用户的终端上显示重要的系统信息，并动态的进行更新，让管理员实时掌握系统资源的使用情况，而动态监控并不会消耗大量的系统资源，比如 CPU 资源，通常消耗小于 2%，glances 默认每两秒更新一次数据。同时 glances 还可以将监控数据导出到文件中，便于以后使用其他可视化工具（例如 grafana）对报告进行分析和图形绘制。</p><p>glances 可以分析系统的：</p><ul><li>CPU 使用率</li><li>内存使用率</li><li>内核统计信息和运行队列信息</li><li>磁盘 I/O 速度、传输和读/写比率</li><li>磁盘适配器</li><li>网络 I/O 速度、传输和读/写比率</li><li>页面监控</li><li>进程监控-消耗资源最多的进程</li><li>计算机信息和系统资源</li></ul><p>当然，也可以用一些专业的服务器监控平台，其包含的信息可能更详细。但是 glances 的一个重要优点是开箱即用，不用专门部署，具体安装方式和参数可参考 <a href="https://github.com/nicolargo/glances" target="_blank" rel="noopener">官方 repo</a>，使用示例如下图所示：<br><img src="/operating-system-performance-testing/glances.jpeg" srcset="/img/loading.gif" lazyload alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客简单介绍了网卡，CPU，内存和磁盘的一些理论知识和我个人认为写的比较好的博客，最后介绍了 Linux 下常用的性能测试工具 sysbench 的使用和性能监控工具 glances 的使用。</p><p>本篇博客涉及了较多硬件和操作系统的知识，其实这些都可以挖的更深，由于水平和时间有限，暂不继续深挖，希望看完本博客之后能对大家的系统调优有所帮助。</p>]]></content>
    
    
    
    <tags>
      
      <tag>测试</tag>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开源协议解读</title>
    <link href="/open-source-license/"/>
    <url>/open-source-license/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>越来越多的开发者与设计者希望将自己的产品开源，以便其他人可以在他们的代码基础上做更多事，开源社区也因此充满生机。然而一旦开源，如何为代码选择开源许可证就是一个非常重要的问题。</p><p>相信很多人和我一样，在 Github 创建 repo 时对可以选择的多种 license 很迷糊，不知道该选哪个好，因此本篇博客就简单介绍一下常见的 license 和他们之间的区别，以做记录和学习。</p><h2 id="什么是许可协议"><a href="#什么是许可协议" class="headerlink" title="什么是许可协议"></a>什么是许可协议</h2><p>关于授权的确切含义存在很多困惑。当你授权你的作品时，你并没有放弃你的任何权利，你仍然拥有该作品的原始版权（或专利）。许可协议所做的是授予其他人使用该作品的特定权限。</p><p>不管产品是免费向公众分发还是出售，制定一份许可协议非常有用，否则，对于前者，你相当于放弃了自己所有的权利，任何人都没有义务表明你的原始作者身份，对于后者，你将不得不花费比开发更多的精力用来逐个处理用户的授权问题。</p><p>开源许可使得其他人无需寻求特殊许可就可以很容易地对项目做出贡献。它还保护了你作为原始创造者的身份，确保你至少能从自己的贡献中获得一些荣誉，这也有助于防止别人把你的工作据为己有。</p><h2 id="常见许可协议"><a href="#常见许可协议" class="headerlink" title="常见许可协议"></a>常见许可协议</h2><p>目前，国际公认的开源许可证共有 80 多种。它们的共同特征是，都允许用户免费地使用、修改、共享源码，但是都有各自的使用条件。以下介绍一些常见的许可协议</p><h3 id="GNU-GPL"><a href="#GNU-GPL" class="headerlink" title="GNU GPL"></a>GNU GPL</h3><p>GNU GPL（GNU General Public License）同其它的自由软件许可证一样，许可社会公众享有：运行、复制软件的自由，发行传播软件的自由，获得软件源码的自由，改进软件并将自己作出的改进版本向社会发行传播的自由。 </p><p>GPL 还规定：只要这种修改文本在整体上或者其某个部分来源于遵循 GPL 的程序，该修改文本的整体就必须按照 GPL 流通，不仅该修改文本的源码必须向社会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制。因此，一项遵循 GPL 流通的程序不能同非自由的软件合并。GPL 所表达的这种流通规则称为 copyleft，表示与 copyright（版权）的概念“相左”。</p><p>GPL 协议最主要的几个原则：</p><ol><li>确保软件自始至终都以开放源代码形式发布，保护开发成果不被窃取用作商业发售。任何一套软件，只要其中使用了受 GPL 协议保护的第三方软件的源程序，并向非开发人员发布时，软件本身也就自动成为受 GPL 保护并且约束的实体。也就是说，此时它必须开放源代码。</li><li>GPL 大致就是一个左侧版权（Copyleft，或译为“反版权”、“版权属左”、“版权所无”、“版责”等）的体现。你可以去掉所有原作的版权信息，只要你保持开源，并且随源代码、二进制版附上 GPL 的许可证就行，让后人可以很明确地得知此软件的授权信息。GPL 精髓就是，只要使软件在完整开源的情况下，尽可能使使用者得到自由发挥的空间，使软件得到更快更好的发展。</li><li>无论软件以何种形式发布，都必须同时附上源代码。例如在 Web 上提供下载，就必须在二进制版本（如果有的话）下载的同一个页面，清楚地提供源代码下载的链接。如果以光盘形式发布，就必须同时附上源文件的光盘。</li><li>开发或维护遵循 GPL 协议开发的软件的公司或个人，可以对使用者收取一定的服务费用。但还是一句老话——必须无偿提供软件的完整源代码，不得将源代码与服务做捆绑或任何变相捆绑销售。</li></ol><p>GPL 协议和 BSD, Apache Licence 等鼓励代码重用的许可协议很不一样。GPL 的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。这也就是为什么我们能用免费的各种 linux，包括商业公司的 linux 和 linux 上各种各样的由个人，组织，以及商业软件公司开发的免费软件了。</p><h3 id="GNU-LGPL"><a href="#GNU-LGPL" class="headerlink" title="GNU LGPL"></a>GNU LGPL</h3><p>LGPL 是 GPL 的一个为主要为类库使用设计的开源协议。和 GPL 要求任何使用/修改/衍生之 GPL 类库的的软件必须采用 GPL 协议不同。LGPL 允许商业软件通过类库引用 (link) 方式使用 LGPL 类库而不需要开源商业软件的代码。这使得采用 LGPL 协议的开源代码可以被商业软件作为类库引用并发布和销售。</p><p>但是如果修改 LGPL 协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用 LGPL 协议。因此 LGPL 协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以 LGPL 协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。</p><p>GPL/LGPL 都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品。</p><h3 id="GNU-AGPL"><a href="#GNU-AGPL" class="headerlink" title="GNU AGPL"></a>GNU AGPL</h3><p>原有的 GPL 协议，由于现在云服务厂商兴起（如：AWS）产生了一定的漏洞，比如使用 GPL 的自由软件，但是并不发布于网络之中，则可以自由的使用 GPL 协议却不开源自己私有的解决方案。AGPL 增加了对此做法的约束。</p><p>GPL 的约束生效的前提是“发布”软件，即使用了 GPL 成分的软件通过互联网或光盘 release 软件，就必需明示地附上源代码，并且源代码和产品也受 GPL 保护。</p><p>这样如果不“发布”就可以不受约束了。比如使用 GPL 组件编写一个 Web 系统，不发布这个系统，但是用这个系统在线提供服务，同时不开源系统代码。</p><h3 id="GNU-SSPL"><a href="#GNU-SSPL" class="headerlink" title="GNU SSPL"></a>GNU SSPL</h3><p>SSPL (Server Side Public License) 为 MongoDB 基于 GPLv3 上修改并提出的软件授权协议。</p><p>MongoDB 认为 AGPL “Remote Network Interaction” 条款叙述不够明确，容易造成混淆。加上许多云端服务商一直在挑战 AGPL 的底线，大量使用 MongoDB 来进行营利行为却不遵守 AGPL，所以才提出明确定义的 SSPL。</p><p>SSPL 服务器端公共授权。许可证更改并不影响当前使用社区服务器的常规用户。根据 MongoDB 之前的 GNU AGPLv3 协议，想要将 MongoDB 作为公共服务运行的公司必须将他们的软件开源，或需要从 MongoDB 获得商业许可，该公司解释说，“然而，MongoDB 的普及使一些组织在违反 GNU AGPLv3 协议的边缘疯狂试探，甚至直接违反了协议。”</p><p>尽管 SSPL 与 GNU GPLv3 没有什么不同，但 SSPL 会明确要求托管 MongoDB 实例的云计算公司要么从 MongoDB 获取商业许可证，要么向社区开源其服务代码。最近闹得特别火的 <a href="https://mp.weixin.qq.com/s/qCJx3sw-Om3y1JwRoCnDbQ" target="_blank" rel="noopener">ElasticSearch 修改开源协议</a> 就是从 Apache 2.0 修改到了 SSPL 协议以限制 AWS 厂商。</p><p>但是，大名鼎鼎的 OSI（Open Source Initiative）在官网上明确说 SSPL 是伪开源许可证（fauxpen source license），感兴趣的吃瓜群众可以关注此 <a href="https://mp.weixin.qq.com/s/CQsWm2rBAYNRIW7OHYsqNQ" target="_blank" rel="noopener">推送</a>。</p><h3 id="BSD"><a href="#BSD" class="headerlink" title="BSD"></a>BSD</h3><p>BSD 是 “Berkeley Software Distribution” 的缩写，意思是”伯克利软件发行版”。</p><p>BSD 在软件分发方面的限制比别的开源协议（如 GNU GPL）要少。该协议有多种版本，最主要的版本有两个，新 BSD 协议与简单 BSD 协议，这两种协议经过修正，都和 GPL 兼容，并为开源组织所认可。</p><p>新 BSD 协议（3 条款协议）在软件分发方面，除需要包含一份版权提示和免责声明之外，没有任何限制。另外，该协议还禁止拿开发者的名义为衍生产品背书，但简单 BSD 协议删除了这一条款。</p><h3 id="MIT"><a href="#MIT" class="headerlink" title="MIT"></a>MIT</h3><p>MIT 是和 BSD 一样宽范的许可协议，源自麻省理工学院（Massachusetts Institute of Technology, MIT），又称 X11 协议。</p><p>MIT 协议可能是几大开源协议中最宽松的一个，核心条款是：该软件及其相关文档对所有人免费，可以任意处置，包括使用，复制，修改，合并，发表，分发，再授权，或者销售。唯一的限制是，软件中必须包含上述版权和许可提示。</p><p>这意味着：你可以自由使用，复制，修改，可以用于自己的项目。可以免费分发或用来盈利。唯一的限制是必须包含许可声明。</p><p>MIT 协议是所有开源许可中最宽松的一个，除了必须包含许可声明外，再无任何限制。</p><h3 id="Apache"><a href="#Apache" class="headerlink" title="Apache"></a>Apache</h3><p>Apache License（Apache 许可证），是 Apache 软件基金会发布的一个自由软件许可证。</p><p>Apache 协议 2.0 和别的开源协议相比，除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。</p><p>Apache 协议还有以下需要说明的地方：</p><ol><li>永久权利：一旦被授权，永久拥有。</li><li>全球范围的权利：在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。</li><li>授权免费，且无版税：前期，后期均无任何费用。</li><li>授权无排他性：任何人都可以获得授权</li><li>授权不可撤消：一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码。</li></ol><p>分发代码方面包含一些要求，主要是，要在声明中对参与开发的人给予认可并包含一份许可协议原文。</p><h3 id="MPL"><a href="#MPL" class="headerlink" title="MPL"></a>MPL</h3><p>MPL（Mozilla Public License 1.1）协议允许免费重发布、免费修改，但要求修改后的代码版权归软件的发起者。这种授权维护了商业软件的利益，它要求基于这种软件的修改无偿贡献版权给该软件。这样，围绕该软件的所有代码的版权都集中在发起开发人的手中。但 MPL 是允许修改，无偿使用得。MPL 软件对链接没有要求。（要求假如你修改了一个基于 MPL 协议的源代码，则必须列入或公开你所做的修改，假如其他源代码不是基于 MPL 则不需要公开其源代码）</p><h3 id="Creative-Commons"><a href="#Creative-Commons" class="headerlink" title="Creative Commons"></a>Creative Commons</h3><p>Creative Commons (CC) 并非严格意义上的开源许可，它主要用于设计。Creative Commons 有多种协议，每种都提供了相应授权模式，CC 协议主要包含 4 种基本形式：</p><ol><li>署名权<br>必须为原始作者署名，然后才可以修改，分发，复制。</li><li>保持一致<br>作品同样可以在 CC 协议基础上修改，分发，复制。</li><li>非商业<br>作品可以被修改，分发，复制，但不能用于商业用途。但商业的定义有些模糊，比如，有的人认为非商业用途指的是不能销售，有的认为是甚至不能放在有广告的网站，也有人认为非商业的意思是非盈利。</li><li>不能衍生新作品<br>你可以复制，分发，但不能修改，也不能以此为基础创作自己的作品。</li></ol><p>CC 许可协议的这些条款可以自由组合使用。大多数的比较严格的 CC 协议会声明 “署名权，非商业用途，禁止衍生”条款，这意味着你可以自由的分享这个作品，但你不能改变它和对其收费，而且必须声明作品的归属。这个许可协议非常的有用，它可以让你的作品传播出去，但又可以对作品的使用保留部分或完全的控制。最少限制的 CC 协议类型当属 “署名”协议，这意味着只要人们能维护你的名誉，他们对你的作品怎么使用都行。</p><h2 id="许可协议区别"><a href="#许可协议区别" class="headerlink" title="许可协议区别"></a>许可协议区别</h2><p>根据使用条件的不同，开源许可证分成两大类。</p><ul><li>宽松式许可证</li><li>Copyleft 许可证</li></ul><h3 id="宽松式许可证"><a href="#宽松式许可证" class="headerlink" title="宽松式许可证"></a>宽松式许可证</h3><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>宽松式许可证（permissive license）是最基本的类型，对用户几乎没有限制。用户可以修改代码后闭源。</p><p>它有三个基本特点。</p><ol><li>没有使用限制：用户可以使用代码，做任何想做的事情。</li><li>没有担保：不保证代码质量，用户自担风险。</li><li>披露要求（notice requirement）：用户必须披露原始作者。</li></ol><h4 id="常见许可证"><a href="#常见许可证" class="headerlink" title="常见许可证"></a>常见许可证</h4><p>常见的宽松式许可证有四种。它们都允许用户任意使用代码，区别在于要求用户遵守的条件不同。</p><ol><li>BSD（二条款版）：分发软件时，必须保留原始的许可证声明。</li><li>BSD（三条款版）：分发软件时，必须保留原始的许可证声明。不得使用原始作者的名字为软件促销。</li><li>MIT：分发软件时，必须保留原始的许可证声明，与 BSD（二条款版）基本一致。</li><li>Apache 2：分发软件时，必须保留原始的许可证声明。凡是修改过的文件，必须向用户说明该文件修改过；没有修改过的文件，必须保持许可证不变。</li></ol><h3 id="Copyleft-许可证"><a href="#Copyleft-许可证" class="headerlink" title="Copyleft 许可证"></a>Copyleft 许可证</h3><h4 id="Copyleft-的含义"><a href="#Copyleft-的含义" class="headerlink" title="Copyleft 的含义"></a>Copyleft 的含义</h4><p>Copyleft 是理查德·斯托曼发明的一个词，作为 Copyright （版权）的反义词。</p><p>Copyright 直译是”复制权”，这是版权制度的核心，意为不经许可，用户无权复制。作为反义词，Copyleft 的含义是不经许可，用户可以随意复制。</p><p>但是，它带有前提条件，比宽松式许可证的限制要多。</p><ul><li>如果分发二进制格式，必须提供源码</li><li>修改后的源码，必须与修改前保持许可证一致</li><li>不得在原始许可证以外，附加其他限制</li></ul><p>上面三个条件的核心就是：修改后的 Copyleft 代码不得闭源。</p><h4 id="常见许可证-1"><a href="#常见许可证-1" class="headerlink" title="常见许可证"></a>常见许可证</h4><p>常见的 Copyleft 许可证也有四种（对用户的限制从最强到最弱排序）。</p><ol><li>Affero GPL (AGPL)：如果云服务（即 SAAS）用到的代码是该许可证，那么云服务的代码也必须开源。</li><li>GPL：如果项目包含了 GPL 许可证的代码，那么整个项目都必须使用 GPL 许可证。</li><li>LGPL：如果项目采用动态链接调用该许可证的库，项目可以不用开源。</li><li>Mozilla（MPL）：只要该许可证的代码在单独的文件中，新增的其他文件可以不用开源。</li></ol><h3 id="区别示意图"><a href="#区别示意图" class="headerlink" title="区别示意图"></a>区别示意图</h3><p>图胜千言<br><img src="/open-source-license/license1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/open-source-license/license2.jpeg" srcset="/img/loading.gif" lazyload alt></p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="什么叫分发（distribution）"><a href="#什么叫分发（distribution）" class="headerlink" title="什么叫分发（distribution）"></a>什么叫分发（distribution）</h3><p>除了 Affero GPL (AGPL) ，其他许可证都规定只有在”分发”时，才需要遵守许可证。换言之，如果不”分发”，就不需要遵守。</p><p>简单说，分发就是指将版权作品从一个人转移到另一个人。这意味着，如果你是自己使用，不提供给他人，就没有分发。另外，这里的”人”也指”法人”，因此如果使用方是公司，且只在公司内部使用，也不需要遵守许可证。</p><p>云服务（SaaS）是否构成”分发”呢？答案是不构成。所以你使用开源软件提供云服务，不必提供源码。但是，Affero GPL (AGPL) 许可证除外，它规定云服务也必须提供源码。</p><h3 id="开源软件的专利如何处理"><a href="#开源软件的专利如何处理" class="headerlink" title="开源软件的专利如何处理"></a>开源软件的专利如何处理</h3><p>某些许可证（Apache 2 和 GPL v3）包含明确的条款，授予用户许可，使用软件所包含的所有专利。</p><p>另一些许可证（BSD、MIT 和 GPL v2）根本没提到专利。但是一般认为，它们默认给予用户专利许可，不构成侵犯专利。</p><p>总得来说，除非有明确的”保留专利”的条款，使用开源软件都不会构成侵犯专利。</p><h3 id="什么是披露要求"><a href="#什么是披露要求" class="headerlink" title="什么是披露要求"></a>什么是披露要求</h3><p>所有的开源许可证都带有”披露要求”（notice requirement），即要求软件的分发者必须向用户披露，软件里面有开源代码。</p><p>一般来说，你只要在软件里面提供完整的原始许可证文本，并且披露原始作者，就满足了”披露要求”。</p><h3 id="GPL-病毒是真的吗"><a href="#GPL-病毒是真的吗" class="headerlink" title="GPL 病毒是真的吗"></a>GPL 病毒是真的吗</h3><p>GPL 许可证规定，只要你的项目包含了 GPL 代码，整个项目就都变成了 GPL。有人把这种传染性比喻成”GPL 病毒”。</p><p>很多公司希望避开这个条款，既使用 GPL 软件，又不把自己的专有代码开源。理论上，这是做不到的。因为 GPL 的设计目的，就是为了防止出现这种情况。</p><p>但是实际上，不遵守 GPL，最坏情况就是被起诉。如果你向法院表示无法履行 GPL 的条件，法官只会判决你停止使用 GPL 代码（法律上叫做”停止侵害”），而不会强制要求你将源码开源，因为《版权法》里面的”违约救济”没有提到违约者必须开源，只提到可以停止侵害和赔偿损失。</p><h2 id="如何选择开源协议"><a href="#如何选择开源协议" class="headerlink" title="如何选择开源协议"></a>如何选择开源协议</h2><p>推荐一个 <a href="https://choosealicense.com/" target="_blank" rel="noopener">网站</a>，有助于我们每个人做开源协议的选择。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>随着时代的发展，开源协议也一直在迭代进化，希望我们大家都能够了解开源协议，遵守开源协议并捍卫开源协议。</p><p>这篇博客参考了许多相关博客以做一个汇总总结，如有侵权之处可联系我删除~</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.ruanyifeng.com/blog/2011/05/how_to_choose_free_software_licenses.html" target="_blank" rel="noopener">如何选择开源许可证？（阮一峰）</a><br><a href="https://zhuanlan.zhihu.com/p/135292511" target="_blank" rel="noopener">简介 5 大开源许可协议</a><br><a href="https://mp.weixin.qq.com/s/HDNYTwifzGOYTcu3x3wFjg" target="_blank" rel="noopener">拒绝云服务商白嫖，Elasticsearch 和 Kibana 变更开源许可协议</a><br><a href="https://mp.weixin.qq.com/s/wwlAH2MBAsujaPeqKqtjmw" target="_blank" rel="noopener">全球各种开源协议介绍</a><br><a href="https://mp.weixin.qq.com/s/1UXjwKjX22vIvRimr5BLNw" target="_blank" rel="noopener">若你要开源自己的代码，此文带你了解开源协议</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>开源</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Twitter 内存缓存系统分析论文阅读</title>
    <link href="/twitter-cache-analysis-thesis/"/>
    <url>/twitter-cache-analysis-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>基于一个物理现实：内存操作比磁盘操作快若干个数量级。现代网站服务广泛使用了类似 redis ，memcached 的内存缓存系统。其思想很简单：尽管海量数据最终都需要落盘持久化，但如果能够将一些常用的数据在内存中缓存以供读请求直接获取，则不仅能够降低请求时延，还能够提升系统吞吐量，而且也能够减少底层数据管理系统比如关系型数据库的负载。</p><p>内存缓存系统的大规模商用激发了业界对其的研究，现有的研究主要集中在如何提高吞吐量，如何减少缓存缺失率等等。由于用户场景与缓存系统的性能息息相关，之前也出现了生产系统的分析，但其针对的用户场景过少。这就导致了理论和生产环境之间的一个巨大 gap，因此业界需要一个能够包含大量用户场景的内存缓存系统分析；此外，业界对内存缓存系统的前提假设都是写少读多，而且许多理论比如内存管理都是基于数据大小是恒定这一假设来做的，那么实际上线的生产环境也都是理论假设的这样吗？此外，一些看似不重要的特性，比如 TTL 受到了业界极少的关注，那么它对于生产系统的性能影响真的很小吗？带着这些问题，我们开始介绍这篇论文。</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>首先介绍数据情况，Twitter 内部的内存缓存集群都是单租户单层的容器化实例，这样的架构方便作者直接将集群的分析结果与商业逻辑对应，更能够反映现象的真实原因。可以看到，Twitter 的内存缓存集群很大。</p><p><img src="/twitter-cache-analysis-thesis/1.png" srcset="/img/loading.gif" lazyload alt></p><p>为了保证分析不受采样方法的影响，作者未取样的收集了两段区间为一周的集群请求全量元信息，在 80TB 的数据基础上做了详细的分析。而且，作者也将数据适度脱敏后进行了开源，能够让任何人去继续分析。</p><p><img src="/twitter-cache-analysis-thesis/2.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="缓存场景"><a href="#缓存场景" class="headerlink" title="缓存场景"></a>缓存场景</h2><p>Twitter 内部的内存缓存系统主要有三种应用场景：</p><p><img src="/twitter-cache-analysis-thesis/3.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="存储缓存"><a href="#存储缓存" class="headerlink" title="存储缓存"></a>存储缓存</h3><p>将一些在磁盘上的热点数据缓存在内存中，来减少底层涉及磁盘的数据系统比如关系型数据库的压力。</p><h3 id="计算缓存"><a href="#计算缓存" class="headerlink" title="计算缓存"></a>计算缓存</h3><p>缓存一些计算结果或预结算结果。随着 BI 时代的到来，许多公司都会利用机器学习的方法做用户画像或者是实时流推荐。这些算法的每次计算很难在秒级以下，而且用户的画像也一般不会在几小时内发生变化，因此企业一般会每计算一次用户的画像就将其设置一个几分钟或几小时的 TTL 存储到缓存中，这样既能够大幅度减少计算资源的消耗也能够保持 BI 逻辑，这种使用方式正在逐渐流行。</p><h3 id="瞬态数据缓存"><a href="#瞬态数据缓存" class="headerlink" title="瞬态数据缓存"></a>瞬态数据缓存</h3><p>有一些数据是不需要持久化的，只存在于内存缓存中。比如限速场景会把用户的请求存储到缓存中进行统计，一旦超速即开始限速，过期后隐形删除这些统计日志即可。</p><h2 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h2><h3 id="写多读少场景广泛存在"><a href="#写多读少场景广泛存在" class="headerlink" title="写多读少场景广泛存在"></a>写多读少场景广泛存在</h3><p>如下图所示，这是一个有关写请求占总请求比率的集群比例概率分布图。<br><img src="/twitter-cache-analysis-thesis/4.png" srcset="/img/loading.gif" lazyload alt><br>作者将比率大于 30% 的集群定义为写多读少负载，可以看到 twitter 内部至少 35 % 的集群都是写多读少的负载，这打破了业界对于内存缓存系统的前提假设，也展示了生产和理论之间的 gap。对于写多读少场景，长尾效应，扩展性受限都成了问题，而这一块却几乎没有学者研究过，因此作者为业界指明了一条研究方向：即写多读少场景内存缓存系统的优化。</p><h3 id="对象大小"><a href="#对象大小" class="headerlink" title="对象大小"></a>对象大小</h3><p>下图是集群中有关对象大小的若干集群比例概率分布图。<br><img src="/twitter-cache-analysis-thesis/5.png" srcset="/img/loading.gif" lazyload alt></p><h4 id="元数据大小"><a href="#元数据大小" class="headerlink" title="元数据大小"></a>元数据大小</h4><p>从前三张子图中可以看到，大部分对象数据都很小，那相比之下，原本被忽视的元数据消耗就非常大了，比如 memcached 中每个对象的元数据就有 56 字节。现有的研究大多数都是通过增加元数据来提高缓存命中率的。而实际上对于小对象场景来说，最小化元数据的大小能够增大缓存个数，也是一条提升性能的方向。</p><h4 id="key-大小"><a href="#key-大小" class="headerlink" title="key 大小"></a>key 大小</h4><p>在上图的第四张子图中可以观察到，对于 60 % 的 workload，key 和 value 的大小都在一个数量级，这很让人惊异。在观察了许多实际 key 后，作者发现很多业务使用了较为冗长的 key，比如把很长的多段命名空间都扔到了里面，这浪费了许多空间。由于直接让业务团队将 key 改小是不可行的，所以内存缓存系统也可以为 key 增加一个轻量级的压缩，这样也能够有效的增大缓存空间。这个工作实现起来很容易，但之前没有人观察到过这个现象，因此这也是作者的贡献。</p><h3 id="对象大小的动态分布"><a href="#对象大小的动态分布" class="headerlink" title="对象大小的动态分布"></a>对象大小的动态分布</h3><p>当前，内存缓存系统大多假设对象随着时间的推移大小不变，然而在生产系统中，作者观察到大部分时间中，其对象大小的分布并不是恒定的。</p><p><img src="/twitter-cache-analysis-thesis/6.png" srcset="/img/loading.gif" lazyload alt></p><p>这个不恒定主要有两种表现形式：</p><ul><li><p>第一种是周期性的变化，比如很多负载都具有白天对象更大的特征。如图所示，亮度发生变化代表分布发生了变化，很多亮度是有周期出现的。</p></li><li><p>第二种是临时的突变，过后即恢复。如图所示，存在个别无规律的亮点。</p></li></ul><p>这些突变给缓存系统的内存管理带来了很多挑战，就如同操作系统的内部碎片和外部碎片一样。作者实际测试发现，现有缓存系统的主流内存管理技术 slab-class ，在面对可变对象大小时表现十分受限，作者认为内存管理技术方面需要更大的创新，比如随着机器学习的发展，动态的预测缓存行为并做出智能的内存管理就是一个可行的方向。</p><h3 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h3><p>TTL，一个限定对象生命周期的内存缓存系统特有参数，作者进行了细致的分析。对应前面提到内存缓存的三种场景，TTL 都有作用。</p><h4 id="TTL-使用场景"><a href="#TTL-使用场景" class="headerlink" title="TTL 使用场景"></a>TTL 使用场景</h4><p><img src="/twitter-cache-analysis-thesis/7.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>保证不一致上界：部分对一致性要求较低的业务可能在写缓存失败时并不重试，这可能最终导致缓存与实际数据的不一致，因此用户可以使用 TTL 这个属性给这个最终一致性的区间定一个上界，从而达到性能和不一致上限都得到保证的可控结果。</li><li>定期更新：用户画像随着时间推移可能逐渐变得不准确，不实时，因此需要一个 TTL 属性来隐性指示计算，即哪怕新一轮计算结果还没触发，每过 TTL 时间请求用户的画像就得重新计算一次，这其实是一个实时性和计算资源之间的 trade-off。</li><li>隐形删除：比如限速场景可以把用户每条请求数据的 TTL 设置为限速的时间窗口，这样既能够达到限速的目的又能够在一段时间后隐形删除掉这些数据。</li></ul><h4 id="小-TTL-能够限制工作集合的大小"><a href="#小-TTL-能够限制工作集合的大小" class="headerlink" title="小 TTL 能够限制工作集合的大小"></a>小 TTL 能够限制工作集合的大小</h4><p><img src="/twitter-cache-analysis-thesis/8.png" srcset="/img/loading.gif" lazyload alt></p><p>如图所示，作者统计了在有无 TTL 场景下的对象集合总大小和活跃对象集合大小，可以看到活跃的对象集合大小相比总大小始终在一个固定范围内。因此如果能够对过期数据清理得当，那么实际上不需要很大的缓存资源就能提供一个不错的缓存命中率。因此作者得出了结论，有效的主动过期策略比驱逐还要更重要。</p><p>现有的主动驱逐策略主要有两种：一种是 Facebook 提出的环形缓冲区策略，它在 TTL 个数较少或者多但不连续时表现都不好；另一种是当前 redis 的定期删除策略，由于其是遍历实现的，而为了保证及时删除扫表时间至少要和最小的 ttl 在一个量级 ，则对于较大的 ttl，其数据会被扫描多次。这样也一定程度上造成了 cpu 时间的浪费，而且也容易有缓存雪崩问题。因此作者认为有效的主动过期策略也需要进一步的创新。</p><h3 id="更多发现"><a href="#更多发现" class="headerlink" title="更多发现"></a>更多发现</h3><h4 id="生产数据统计"><a href="#生产数据统计" class="headerlink" title="生产数据统计"></a>生产数据统计</h4><p>请求激增不一定就是热点导致的，可能就是均匀的涨了一些。</p><h4 id="对象分布"><a href="#对象分布" class="headerlink" title="对象分布"></a>对象分布</h4><p>尽管有些许偏差，但针对对象的请求基本符合幂率分布</p><h4 id="驱逐策略"><a href="#驱逐策略" class="headerlink" title="驱逐策略"></a>驱逐策略</h4><p>尽管不同负载的表现情况不一样，但 FIFO 与 LRU 策略在大部分负载下的表现近似。这也预示业务可能实际没必要费事费力的去搞 LRU 策略，简单的 FIFO 就能达到类似的性能的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>证明了写多读少内存缓存场景的广泛存在，指明了一个可以研究的领域。</li><li>大多数场景的对象很小，要想提升吞吐量可以从减少元数据大小和适度压缩 key 入手。</li><li>在内存缓存的生产系统中，对象的大小并不是恒定不变的。基于对象大小固定不变进行的理论推理都存在问题。</li><li>有效的主动过期策略比驱逐策略更管用。</li></ul><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>本文作者基于世界上最大的实时内容公司之一 Twitter 的内存缓存统计数据，使用强有力的数据分析纠正了若干业界对于内存缓存的误区，辩驳了若干业界的前提假设和主流思想，并提出了若干研究方向，开创了多个子领域。我个人认为这是一篇很有意义的文章。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="https://www.usenix.org/system/files/osdi20-yang.pdf" target="_blank" rel="noopener">论文</a><br><a href="https://www.usenix.org/sites/default/files/conference/protected-files/osdi20_slides_yang.pdf" target="_blank" rel="noopener">PPT</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spark 论文阅读</title>
    <link href="/spark-thesis/"/>
    <url>/spark-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在 Apache Spark 广泛使用以前，业界主要使用 MapReduce 和 Dryad 这样的集群计算框架来对大数据进行分布式处理。这类计算框架，最大的优点旨在帮助程序员专注业务编程，而非花精力分发计算任务和实现程序容错。</p><p>MapReduce 虽然对利用集群中的计算资源做了各类抽象，但还没有实现对集群内存的抽象封装。这样对那些需要重复利用中间结果集的应用就很不友好，比如机器学习和图算法，PageRank, K-means 聚类以及逻辑回归等等。此外，MapReduce 也很难支持高效的交互式数据分析，因涉及大量的即席数据查询，为确保下一次数据集可以被重用，需要借助存储物化结果集，这引发大量写入实体磁盘的操作，导致执行时间拉长。</p><p>意识到这个问题的存在，学者们做了大量尝试，比如 Pregel，它把大量中间数据缓存起来，专为图计算封装了框架；HaLoop 则提供了实现迭代算法的 MapReduce 接口。但这些仅仅对个案有帮助，回到通用的计算上来，毫无优势。比如最常见的数据分析，装载多样化多源头数据，展开即席查询等等。</p><p>综上，MapReduce 的局限可以总结为：</p><ul><li>编程模型的表达能力有限，仅靠 MapReduce 难以实现部分算法。</li><li>对分布式内存资源的使用方式有限，使得其难以满足迭代式分析场景和交互式分析场景，比如迭代式机器学习算法及图算法，交互式数据挖掘等。</li></ul><p>Spark RDD 作为一个分布式内存资源抽象便致力于解决 Hadoop MapReduce 的上述问题：</p><ul><li>通过对分布式集群的内存资源进行抽象，允许程序高效复用已有的中间结果。</li><li>提供比 MapReduce 更灵活的编程模型，兼容更多的高级算法。</li></ul><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>RDD（Resilient Distributed Dataset，弹性分布式数据集）本质上是一种只读、分片的记录集合，只能由所支持的数据源或是由其他 RDD 经过一定的转换（Transformation）来产生。通过由用户构建 RDD 间组成的产生关系图，每个 RDD 都能记录到自己是如何由还位于持久化存储中的源数据计算得出的，即其血统（Lineage）。</p><p><img src="/spark-thesis/lineage.jpg" srcset="/img/loading.gif" lazyload alt></p><p>Spark 为 RDD 提供了 Transformation 和 Action 两种操作，前者可以从其他数据源读入数据生成 RDD 或利用已有的 RDD 生成新的只读 RDD。后者可对 RDD 进行计算操作并把一个结果值返回给客户端，或是将 RDD 里的数据写出到外部存储。</p><p><img src="/spark-thesis/Transformation_Action.jpg" srcset="/img/loading.gif" lazyload alt></p><p>Transformation 与 Action 的区别还在于，对 RDD 进行 Transformation 并不会触发计算：Transformation 方法所产生的 RDD 对象只会记录住该 RDD 所依赖的 RDD 以及计算产生该 RDD 的数据的方式；只有在用户进行 Action 操作时，Spark 才会调度 RDD 计算任务，依次为各个 RDD 计算数据，这是 RDD 典型的惰性计算。</p><h2 id="分布式共享内存模型对比"><a href="#分布式共享内存模型对比" class="headerlink" title="分布式共享内存模型对比"></a>分布式共享内存模型对比</h2><p>相比于 RDD 只能通过粗粒度的”转换”来创建（或是说写入数据），分布式共享内存（Distributed Shared Memory，DSM）是另一种分布式系统常用的分布式内存抽象模型：应用在使用分布式共享内存时可以在一个全局可见的地址空间中进行随机的读写操作。类似的系统包括了一些常见的分布式内存数据库（如 Redis、Memcached）。其最大的优点在于写一次，多机同步。集群中的所有计算机节点，在同一内存位置存储了同一份数据。弊端也很明显，一旦数据损坏，所有数据都要重新还原或重做；同步导致的延迟会很高，因为系统要保障数据的完整性，这在分布式数据库中常见。</p><p><img src="/spark-thesis/comparison.png" srcset="/img/loading.gif" lazyload alt></p><p>RDD 产生的方式限制了其只适用于那些只会进行批量数据写入的应用程序，但却使得 RDD 可以使用更为高效的高可用机制。RDD 与 DSM 的区别在于，前者是粗放式写入，通过转换函数生成，而后者在内存任意位置均可写入。RDD 不能很好地支持大批量随机写入，却可以很好的支持批量写入和分区容错。前面也说道，血统依赖是 RDD 容错的利器，丢失分区可重生。</p><p>RDD 的第二大优势在于，备份节点可以迅速的被唤起，去代替那些缓慢节点执行任务。即在缓慢节点执行任务的同时，备份节点同时也执行相同的任务，哪个节点快就用那个节点的结果。而 DSM 则会被备份节点干扰，引起大家同时缓慢，因为共享内存之间会同步状态，互相干扰。</p><p>RDD 还有两大优化点：基于数据存储分发任务和溢出缓存至硬盘。在大量写入的操作中，比如生成 RDD，会选择离数据最近的节点开始任务；而在只读操作中，大量数据没法存入内存时，会自动存到硬盘上而不是报错停止执行。</p><h2 id="计算调度"><a href="#计算调度" class="headerlink" title="计算调度"></a>计算调度</h2><p>前面我们提到，RDD 在物理形式上是分片的，其完整数据被分散在集群内若干机器的内存上。当用户通过 Transformation 创建出新的 RDD 后，新的 RDD 与原本的 RDD 便形成了依赖关系。根据用户所选 Transformation 操作的不同，RDD 间的依赖关系可以被分为两种：</p><ul><li>窄依赖（Narrow Dependency）：父 RDD 的每个分片至多被子 RDD 中的一个分片所依赖</li><li>宽依赖（Wide Dependency）：父 RDD 中的分片可能被子 RDD 中的多个分片所依赖</li></ul><p><img src="/spark-thesis/dependency.jpg" srcset="/img/loading.gif" lazyload alt></p><p>通过将窄依赖从宽依赖中区分出来，Spark 便可以针对 RDD 窄依赖进行一定的优化。首先，窄依赖使得位于该依赖链上的 RDD 计算操作可以被安排到同一个集群节点上流水线进行；其次，在节点失效需要恢复 RDD 时，Spark 只需要恢复父 RDD 中的对应分片即可，恢复父分片时还能将不同父分片的恢复任务调度到不同的节点上并发进行。</p><p>总的来说，一个 RDD 由以下几部分组成：</p><ul><li>其分片集合</li><li>其父 RDD 集合</li><li>计算产生该 RDD 的方式</li><li>描述该 RDD 所包含数据的模式、分片方式、存储位置偏好等信息的元数据</li></ul><p>在用户调用 Action 方法触发 RDD 计算时，Spark 会按照定义好的 RDD 依赖关系绘制出完整的 RDD 血统依赖，并根据图中各节点间依赖关系的不同对计算过程进行切分：</p><p><img src="/spark-thesis/stage.jpg" srcset="/img/loading.gif" lazyload alt></p><p>简单来说，Spark 会把尽可能多的可以流水线执行的窄依赖 Transformation 放到同一个 Job Stage 中，而 Job Stage 之间则要求集群对数据进行 Shuffle。Job Stage 划分完毕后，Spark 便会为每个 Partition 生成计算任务（Task）并调度到集群节点上运行。</p><p>在调度 Task 时，Spark 也会考虑计算该 Partition 所需的数据的位置：例如，如果 RDD 是从 HDFS 中读出数据，那么 Partition 的计算就会尽可能被分配到持有对应 HDFS Block 的节点上；或者，如果 Spark 已经将父 RDD 持有在内存中，子 Partition 的计算也会被尽可能分配到持有对应父 Partition 的节点上。对于不同 Job Stage 之间的 Data Shuffle，目前 Spark 采取与 MapReduce 相同的策略，会把中间结果持久化到节点的本地存储中，以简化失效恢复的过程。</p><p>当 Task 所在的节点失效时，只要该 Task 所属 Job Stage 的父 Job Stage 数据仍可用，Spark 只要将该 Task 调度到另一个节点上重新运行即可。如果父 Job Stage 的数据也已经不可用了，那么 Spark 就会重新提交一个计算父 Job Stage 数据的 Task，以完成恢复。有趣的是，从论文来看，Spark 当时还没有考虑调度模块本身的高可用，不过调度模块持有的状态只有 RDD 的血统图和 Task 分配情况，通过状态备份的方式实现高可用也是十分直观的。</p><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>Spark 为 RDD 提供了三种存储格式：</p><ul><li>内存中反序列化的 Java 对象；</li><li>内存中序列化的 Java 对象；</li><li>硬盘存储</li></ul><p>访问速度从快到慢，即第一种方式最快，无需任何转换就可以被自由访问。最后一种最慢，因每次使用，需从硬盘抽取数据，有不必要的 IO 开销。</p><p>当内存吃紧，新建的 RDD 分区没有足够内存存储时，Spark 会采用回收分区方式，以给新分区提供空间。回收机制采用的是常规 LRU（Least Recently Used）算法，即最近最少使用的算法。这套回收机制很有用，至少目前来说是。但权值机制也很有用，比如设定 RDD 的权限等级，控制 RDD 分区被回收的可能性。</p><h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>前面已经提到，Spark 可以利用血统依赖来恢复出现故障的 RDD，这样即可不用对中间结果做持久化。然而，在部分长链场景下，做 checkpoint 来持久化也是有必要的。这是因为如果血统依赖足够长，在故障之后，RDD 的恢复需要经历相当多的步骤，会导致时间过多的消耗，此时如果有 checkpoint 即可减少较多的时间消耗。</p><p>Spark 将 checkpoint 的决策留给了用户。实现 checkpoint 的 API 是 persist 的 replicate 开关，即：<br><figure class="highlight css"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs css"><span class="hljs-selector-tag">rdd</span><span class="hljs-selector-class">.persist</span>(<span class="hljs-selector-tag">REPLICATE</span>)<br></code></pre></div></td></tr></table></figure></p><p>通过定期将数据暂存至稳定的存储设备，可以保证在性能不大幅度下降的情况下优化 RDD 失效后的过长重算。</p><h2 id="评测"><a href="#评测" class="headerlink" title="评测"></a>评测</h2><p><img src="/spark-thesis/performance.jpg" srcset="/img/loading.gif" lazyload alt></p><p>Spark 在性能方面表现出众，对标物是 Hadoop，以下是基于 Amazon EC2 做出的 4 组对比数据：</p><ol><li>在图运算和迭代机器学习方面，优先 Hadoop 20 倍速度。性能的提高得益于无需硬盘 I/O，且在内存中的 Java 对象计算，没有序列化和反序列化的开销。</li><li>性能与扩展性都很好。单测一张分析报表，就比 Hadoop 提高了 40 倍性能</li><li>当有节点故障时，Spark 能自动恢复已丢失的分区</li><li>查询 1TB 的数据，延迟仅在 5-7 秒。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来说，Spark RDD 的亮点在于如下两点：</p><ul><li>通过对分布式集群的内存资源进行抽象，允许程序高效复用已有的中间结果且保证高可用性。</li><li>提供比 MapReduce 更灵活的编程模型，兼容更多的高级算法。</li></ul><p>比起类似于分布式内存数据库的那种分布式共享内存模型，Spark RDD 巧妙地利用了其不可变和血统依赖的特性实现了对分布式内存资源的抽象，很好地支持了批处理程序的使用场景，同时大大简化了节点失效后的数据恢复过程。</p><p>同时，我们也应该意识到，Spark 是对 MapReduce 的一种补充而不是替代：将那些能够已有的能够很好契合 MapReduce 模型的计算作业迁移到 Spark 上不会收获太多的好处（例如普通的 ETL 作业）。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-spark.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/15.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://zhuanlan.zhihu.com/p/36288538" target="_blank" rel="noopener">Spark 博客</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>分布式计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为什么选择 git 来作为代码版本控制系统</title>
    <link href="/git-or-svn/"/>
    <url>/git-or-svn/</url>
    
    <content type="html"><![CDATA[<h2 id="版本控制系统"><a href="#版本控制系统" class="headerlink" title="版本控制系统"></a>版本控制系统</h2><p>代码作为软件研发的核心产物，在整个开发周期都在递增，不断合入新需求以及解决 bug 的新 patch，这就需要有一款系统，能够存储、追踪文件的修改历史，记录多个版本的开发和维护。于是，版本控制系统（Version Control Systems）应运而生，主要分为两类，集中式和分布式。</p><h2 id="集中式版本控制系统"><a href="#集中式版本控制系统" class="headerlink" title="集中式版本控制系统"></a>集中式版本控制系统</h2><p><img src="https://pic2.zhimg.com/80/v2-974ee843e5b45fa3c81701dcd86ce8e9_1440w.png" srcset="/img/loading.gif" lazyload alt></p><p>集中化的版本控制系统，诸如 CVS，SVN 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。</p><p>这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。</p><p><img src="/git-or-svn/c-vcs.png" srcset="/img/loading.gif" lazyload alt></p><p>集中式版本控制系统的优点：</p><ol><li>操作简单，使用没有难度，可轻松上手。</li><li>文件夹级权限控制，权限控制粒度小。</li><li>对客户端配置要求不高，无需存储全套代码。</li></ol><p>集中式版本控制系统的缺点：</p><ol><li>网络环境要求高，相关人员必须联网才能工作。</li><li>中央服务器的单点故障影响全局，如果服务器宕机，所有人都无法工作。</li><li>中央服务器在没有备份的情况下，磁盘一旦被损坏，将丢失所有数据。</li></ol><h2 id="分布式版本控制系统"><a href="#分布式版本控制系统" class="headerlink" title="分布式版本控制系统"></a>分布式版本控制系统</h2><p><img src="https://pic2.zhimg.com/80/v2-fb54a44c9918cd2228224b89a64fa7d1_1440w.png" srcset="/img/loading.gif" lazyload alt></p><p>分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。可能有人会问，我们公司使用 git 工具，也有”中央服务器”啊？其实，这个所谓的”中央服务器”仅仅是用来方便管理多人协作，任何一台客户端都可以胜任它的工作，它和所有客户端没有本质区别。</p><p><img src="/git-or-svn/d-vcs.png" srcset="/img/loading.gif" lazyload alt></p><p>分布式版本控制系统的优点：</p><ol><li>版本库本地化，版本库的完整克隆，包括标签、分支、版本记录等。</li><li>支持离线提交，适合跨地域协同开发。</li><li>分支切换快速高效，创建和销毁分支廉价。</li></ol><p>分布式版本控制系统的缺点：</p><ol><li>学习成本高，不容易上手。</li><li>只能针对整个仓库创建分支，无法根据目录建立层次性的分支。</li></ol><h2 id="svn-or-git"><a href="#svn-or-git" class="headerlink" title="svn or git?"></a>svn or git?</h2><p>svn 和 git 作为集中式和分布式版本控制系统的代表，都有广大的使用群体，两者的优缺点经常被比较。其实，工具对我们来说，就是帮助我们有效提升工作的效率与质量，最适合的就是最好的。我们引用几个开发场景来看看两个版本控制工具的适用范围。</p><h3 id="场景一"><a href="#场景一" class="headerlink" title="场景一"></a>场景一</h3><p>公司 A，非纯技术开发，项目包含大量媒体设计文件，相关人员只需下载自己关注的部分文件；员工 PC 电脑配置不高，没有空间拷贝整个项目资料。</p><p>适用：svn</p><p>分析：只需公司有一个足够大的服务器硬盘，员工本地只存储自己相关的文件夹，不必下载不想关的媒体文件，避免浪费文件传输时间。</p><h3 id="场景二"><a href="#场景二" class="headerlink" title="场景二"></a>场景二</h3><p>公司 B，嵌入式底层开发，项目人员较多并且分布在两个城市，代码庞大；用分支管理多机种并行开发，机种间经常相互合并新特性，新 patch。</p><p>适用：git</p><p>分析：</p><ol><li>git 有能力高效管理类似 Linux 内核一样的超大规模项目；</li><li>git 实现了离线开发、代码审核特性，解决了跨地域协同开发中代码质量和编码协同的问题；</li><li>分支管理功能强大，便于查询和追溯分支间的提交历史；</li><li>git 基于 DAG（有向非环图）的设计比 svn 的线性提交提供更好的合并追踪，避免不必要的冲突，提高工作效率。</li></ol><p><img src="https://pic2.zhimg.com/80/v2-6349574ea7ed79d1e9aa65fdd84bb141_1440w.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="场景三"><a href="#场景三" class="headerlink" title="场景三"></a>场景三</h3><p>公司 C，某行业软件开发，包含敏感重要数据，代码仓库和版本发布权限掌握在客户手中，代码安全要求高，公司开发人员先将代码提交到本地仓库，只有在客户审核通过才能提交到发布仓库。</p><p>适用：git</p><p>分析：</p><ol><li>git 通过哈希加密保证数据的完整性，防止恶意篡改；</li><li>代码分布存储，异地容灾，保证数据安全；</li><li>git 支持团队成员自建本地版本库和分支，只有客户发出合并请求，开发人员才能提交代码，客户可以对提交说明、代码规范等方面逐一审核。</li></ol><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>可以参考此 <a href="https://draveness.me/whys-the-design-git-the-best/" target="_blank" rel="noopener">博客</a> 和 Linus 2007 年在 Google Talk 中对 Git 的 <a href="https://www.bilibili.com/video/av34867224?t=1494" target="_blank" rel="noopener">介绍</a>。</p><p>上文首先介绍了集中式管理系统的缺点：</p><ul><li>工程师必须都需要连接网络才能开发，在网络状况不好或者无网络的情况下无法进行提交；<ul><li>很多人可能认为自己并没有离线工作的需求，但是这实际上在我们的日常工作中也比较常见，百兆带宽虽然已经能够满足日常开发的需求，不过在复杂的网络环境下，很多时候我们还是会遇到无法联网或者网络极差的场景，例如在飞机和火车上；</li><li>对于一个较大的分布式开发团队，在实际生产中我们也难以保证所有成员都能同时通过骨干网等高速网络连接到同一个主仓库；</li></ul></li><li>对中心仓库的提交和改动，例如创建分支等操作对于所有的开发人员都是可见的；<ul><li>当我们使用集中式的开发模型时，无论是提交代码还是创建新的实验分支，这些操作其实都会改变所有人共享的代码库，这也就意味着如果某个开发者创建了很多的实验分支，所有开发者的代码库也都会变大；</li><li>虽然我们能在中心仓库中创建分支，但是由于中心仓库中不存在名空间，如果开发者创建分支没有遵循特定的命名规则，就非常容易出现命名冲突的问题，例如各种 test 分支；</li></ul></li><li>当前仓库的所有开发者都需要有直接向主仓库提交代码的权限，否则他们就无法进行开发；<ul><li>同时让项目中的所有开发者具有写权限其实是一件危险的事情，我们并不是知道这些开发者是否有着足够的经验操作主仓库，一旦出现操作上的失误，所有的成员都将面临这一失误带来的风险；</li></ul></li></ul><p>接着 Git 完美的解决了以上问题：</p><ul><li>Git 作为分布式的版本控制系统能够让开发者离线工作和本地提交，不仅能够避免直接提交大量代码带来的风险，还能帮助我们限制对主仓库的授权，减少由于命名空间导致的冲突问题；</li><li>Git 在优化性能时选择了合并分支作为主要的性能衡量指标，将合并分支变成了成本非常低的操作以鼓励分支的使用；</li><li>Git 通过 SHA-1 哈希来保证仓库中数据的可靠性，我们通过 SHA-1 就可以对数据进行校验，保证整个提交链条上的所有数据的稳定性和可靠性，也帮助我们抵御了来自攻击者的恶意篡改；</li></ul><p>此外也可参考此 <a href="https://www.zhihu.com/question/25491925" target="_blank" rel="noopener">知乎上大家的讨论</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>不难看出，git 凭借自身的优势，完美解决了大多数公司对版本控制工具的诉求。在当今敏捷开发成为主流，研发周期短，跨地域协同开发多的大形势下，选择 git 是大势所趋。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/27374348" target="_blank" rel="noopener">如何选择版本控制系统 —-为什么选择 Git 版本控制系统</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>33 条常用 git 命令详解</title>
    <link href="/git-common-command/"/>
    <url>/git-common-command/</url>
    
    <content type="html"><![CDATA[<p>参考我的 <a href="https://github.com/OneSizeFitsQuorum/git-tips" target="_blank" rel="noopener">Github Repo</a>。</p><p>由于作者能力有限，描述必然会有纰漏，欢迎提交 PR、创建 Issue 进一步交流。</p><p>如果看完之后有所收获，求求给个 Star 以表支持。😊</p>]]></content>
    
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MapReduce 论文阅读</title>
    <link href="/mapreduce-thesis/"/>
    <url>/mapreduce-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>在 20 世纪初，包括本文作者在内的 Google 的很多程序员，为了处理海量的原始数据，已经实现了数以百计的、专用的计算方法。这些计算方法用来处理大量的原始数据，比如，文档抓取（类似网络爬虫的程序）、Web 请求日志等等；也为了计算处理各种类型的衍生数据，比如倒排索引、Web 文档的图结构的各种表示形势、每台主机上网络爬虫抓取的页面数量的汇总、每天被请求的最多的查询的集合等等。</p><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>大多数以上提到的数据处理运算在概念上很容易理解。然而由于输入的数据量巨大，因此要想在可接受的时间内完成运算，只有将这些计算分布在成百上千的主机上。如何处理并行计算、如何分发数据、如何处理错误？所有这些问题综合在一起，需要大量的代码处理，因此也使得原本简单的运算变得难以处理。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>为了解决上述复杂的问题，本文设计一个新的抽象模型，使用这个抽象模型，用户只要表述想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在了一个库里面：利用一个输入 key/value pair 集合来产生一个输出的 key/value pair 集合。</p><p>MapReduce 库的用户可以用两个函数表达这个计算：Map 和 Reduce。</p><ul><li>用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。MapReduce 库把所有具有相同中间 key 值 I 的中间 value 值集合在一起后传递给 reduce 函数。</li><li>用户自定义的 Reduce 函数接受一个中间 key 的值 I 和相关的一个 value 值的集合。Reduce 函数合并这些 value 值，形成一个较小的 value 值的集合。一般的，每次 Reduce 函数调用只产生 0 或 1 个输出 value 值。通常 Map 通过一个迭代器把中间 value 值提供给 Reduce 函数，这样 Reduce Worker 就可以处理无法全部放入内存中的大量的 value 值的集合。</li></ul><p>在概念上，用户定义的 Map 和 Reduce 函数都有相关联的类型：<br><figure class="highlight livescript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs livescript"><span class="hljs-keyword">map</span><span class="hljs-function"><span class="hljs-params">(k1,v1)</span> -&gt;</span><span class="hljs-keyword">list</span>(k2,v2)<br>reduce<span class="hljs-function"><span class="hljs-params">(k2,<span class="hljs-keyword">list</span>(v2))</span> -&gt;</span><span class="hljs-keyword">list</span>(v2)<br></code></pre></div></td></tr></table></figure><br>比如，输入的 key 和 value 值与输出的 key 和 value 值在类型上推导的域不同。此外，中间 key 和 value 值与输出 key 和 value 值在类型上推导的域相同。</p><h3 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h3><p>通过将 Map 调用的输入数据自动分割为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区（例如，hash(key) mod R），Reduce 调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指定。</p><p><img src="/mapreduce-thesis/mapreduce.png" srcset="/img/loading.gif" lazyload alt></p><p>上图展示了 MapReduce 实现中操作的全部流程。当用户调用 MapReduce 函数时，将发生下面的一系列动作：</p><ol><li>用户程序首先调用的 MapReduce 库将输入文件分成 M 个数据片度，每个数据片段的大小一般从 16MB 到 64MB（可以通过可选的参数来控制每个数据片段的大小）。然后用户程序在机群中创建大量的程序副本。</li><li>这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是 worker 程序，由 master 分配任务。有 M 个 Map 任务和 R 个 Reduce 任务将被分配，master 将一个 Map 任务或 Reduce 任务分配给一个空闲的 worker。</li><li>被分配了 map 任务的 worker 程序读取相关的输入数据片段，从输入的数据片段中解析出 key/value pair，然后把 key/value pair 传递给用户自定义的 Map 函数，由 Map 函数生成并输出的中间 key/value pair，并缓存在内存中。</li><li>缓存中的 key/value pair 通过分区函数分成 R 个区域，之后周期性的写入到本地磁盘上。缓存的 key/value pair 在本地磁盘上的存储位置将被回传给 master，由 master 负责把这些存储位置再传送给 Reduce worker</li><li>当 Reduce worker 程序接收到 master 程序发来的数据存储位置信息后，使用 RPC 从 Map worker 所在主机的磁盘上读取这些缓存数据。当 Reduce worker 读取了所有的中间数据后，通过对 key 进行排序后使得具有相同 key 值的数据聚合在一起。由于许多不同的 key 值会映射到相同的 Reduce 任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。</li><li>Reduce worker 程序遍历排序后的中间数据，对于每一个唯一的中间 key 值，Reduce worker 程序将这个 key 值和它相关的中间 value 值的集合传递给用户自定义的 Reduce 函数。Reduce 函数的输出被追加到所属分区的输出文件。</li><li>当所有的 Map 和 Reduce 任务都完成之后，master 唤醒用户程序。在这个时候，在用户程序里的对 MapReduce 调用才返回。</li></ol><h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><h4 id="worker-故障"><a href="#worker-故障" class="headerlink" title="worker 故障"></a>worker 故障</h4><p>master 与 worker 之间同步心跳，对于失效的 worker，根据其类型来做进一步处理：</p><ul><li>Map worker 故障：由于 Map 任务将数据临时存储在本地，所以需要重新执行。</li><li>Reduce worker 故障：由于 Reduce 任务将数据存储在全局文件系统中 ，所以不需要重新执行。</li></ul><h4 id="master-故障"><a href="#master-故障" class="headerlink" title="master 故障"></a>master 故障</h4><p>MapReduce 任务重新执行</p><h4 id="故障语义保证"><a href="#故障语义保证" class="headerlink" title="故障语义保证"></a>故障语义保证</h4><p>当用户提供的 Map 和 Reduce 操作是输入确定性函数（即相同的输入产生相同的输出）时，MapReduce 的分布式实现在任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。</p><ul><li>Map worker 任务的原子提交：每个 Map 任务生成 R 个本地临时文件，当一个 Map 任务完成时，worker 发送一个包含 R 个临时文件名的完成消息给 master。如果 master 从一个已经完成的 Map 任务再次接收到一个完成消息，master 将忽略这个消息；</li><li>Reduce worker 任务的原子提交：当 Reduce 任务完成时，Reduce worker 进程以原子的方式把临时文件重命名为最终的输出文件。如果同一个 Reduce 任务在多台机器上执行，针对同一个最终的输出文件将有多个重命名操作执行。MapReduce 依赖底层文件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 Reduce 任务产生的数据。</li></ul><h3 id="存储位置优化"><a href="#存储位置优化" class="headerlink" title="存储位置优化"></a>存储位置优化</h3><p>核心思想：本地读文件以减少流量消耗</p><p>MapReduce 的 master 在调度 Map 任务时会考虑输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务（例如，分配到一个和包含输入数据的机器在一个交换机里的 worker 机器上执行）。</p><h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><p>理想情况下，M 和 R 应当比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。</p><p>实际使用时建议用户选择合适的 M 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样，上面描写的输入数据本地存储优化策略才最有效），另外，也建议把 R 值设置使用的 worker 机器数量的小倍数。比如：M=200000，R=5000，使用 2000 台 worker 机器。</p><h3 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h3><p>影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”：在运算过程中，如果有一台机器花了很长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。</p><p>为了解决落伍者的问题，当一个 MapReduce 操作接近完成的时候，master 调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、还是备用（backup）任务进程完成了任务，MapReduce 都把这个任务标记成为已经完成。此个机制通常只会占用比正常操作多几个百分点的计算资源。但能减少近 50% 的任务完成总时间。</p><h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><h4 id="分区函数"><a href="#分区函数" class="headerlink" title="分区函数"></a>分区函数</h4><p>MapReduce 缺省的分区函数是使用 hash 方法（比如，hash(key) mod R) 进行分区。hash 方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。比如，输出的 key 值是 URLs，有的用户希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，MapReduce 库的用户需要提供专门的分区函数。例如，使用“hash(Hostname(urlkey))mod R”作为分区函数就可以把所有来自同一个主机的 URLs 保存在同一个输出文件中。</p><h4 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h4><p>MapReduce 确保在给定的分区中，中间 key/value pair 数据的处理顺序是按照 key 值增量顺序处理的。这样的顺序保证对每个分成生成一个有序的输出文件，这对于需要对输出文件按 key 值随机存取的应用非常有意义，对在排序输出的数据集也很有帮助。</p><h4 id="Combiner-函数"><a href="#Combiner-函数" class="headerlink" title="Combiner 函数"></a>Combiner 函数</h4><p>在某些情况下，Map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 Reduce 函数满足结合律和交换律。在 2.1 节的词数统计程序是个很好的例子。由于词频率倾向于一个 zipf 分布（齐夫分布），每个 Map 任务将产生成千上万个这样的记录<the,1>。所有的这些记录将通过网络被发送到一个单独的 Reduce 任务，然后由这个 Reduce 任务把所有这些记录累加起来产生一个数字。MapReduce 允许用户指定一个可选的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</the,1></p><p>Combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，Combiner 和 Reduce 函数是一样的。Combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。Reduce 函数的输出被保存在最终的输出文件里，而 Combiner 函数的输出被写到中间文件里，然后被发送给 Reduce 任务。</p><p>部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。</p><h4 id="输入和输出的类型"><a href="#输入和输出的类型" class="headerlink" title="输入和输出的类型"></a>输入和输出的类型</h4><p>支持常用的类型，可以通过提供一个简单的 Reader 接口实现来支持一个新的输入类型。Reader 并非一定要从文件中读取数据，比如可以很容易的实现一个从数据库里读记录的 Reader，或者从内存中的数据结构读取数据的 Reader。</p><h4 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h4><p>在某些情况下，MapReduce 的使用者发现，如果在 Map 或 Reduce 操作过程中增加辅助的输出文件会比较省事。MapReduce 依靠程序 writer 把这种“副作用”变成原子的和幂等的。通常应用程序首先把输出结果写到一个临时文件中，在输出全部数据之后，在使用系统级的原子操作 rename 重新命名这个临时文件。</p><h4 id="跳过损坏的记录"><a href="#跳过损坏的记录" class="headerlink" title="跳过损坏的记录"></a>跳过损坏的记录</h4><p>每个 worker 进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。 在执行 Map 或者 Reduce 操作之前，MapReduce 库通过全局变量保存记录序号。如果用户程序触发了一个系统信号，消息处理函数将用“最后一口气”通过 UDP 包向 master 发送处理的最后一条记录的序号。当 master 看到在处理某条特定记录不止失败一次时，master 就标志着条记录需要被跳过，并且在下次重新执行相关的 Map 或者 Reduce 任务的时候跳过这条记录。</p><h4 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h4><p>支持本地串行执行以方便调试</p><h4 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h4><p>master 支持嵌入 HTTP 服务器以显示一组状态信息页面，用户可以监控各种执行状态。状态信息页面显示了包括计算执行的进度，比如已经完成了多少任务、有多少任务正在处理、输入的字节数、中间数据的字节数、输出的字节数、处理百分比等等</p><h4 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h4><p>MapReduce 库使用计数器统计不同事件发生次数。比如，用户可能想统计已经处理了多少个单词、已经索引的多少篇 German 文档等等。</p><p>这些计数器的值周期性的从各个单独的 worker 机器上传递给 master（附加在 ping 的应答包中传递）。master 把执行成功的 Map 和 Reduce 任务的计数器值进行累计，当 MapReduce 操作完成之后，返回给用户代码。 </p><p>计数器当前的值也会显示在 master 的状态页面上，这样用户就可以看到当前计算的进度。当累加计数器的值的时候，master 要检查重复运行的 Map 或者 Reduce 任务，避免重复累加（之前提到的备用任务和失效后重新执行任务这两种情况会导致相同的任务被多次执行）。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li>分布式的 Grep：Map 函数输出匹配某个模式的一行，Reduce 函数是一个恒等函数，即把中间数据复制到输出。</li><li>计算 URL 访问频率：Map 函数处理日志中 web 页面请求的记录，然后输出 (URL,1)。Reduce 函数把相同 URL 的 value 值都累加起来，产生 (URL, 记录总数）结果。</li><li>网络链接倒排：Map 函数在源页面（source）中搜索所有的链接目标（target）并输出为 (target,source)。Reduce 函数把给定链接目标（target）的链接组合成一个列表，输出 (target,list(source))。</li><li>每个主机的检索词向量：检索词向量用一个（词，频率）列表来概述出现在文档或文档集中的最重要的一些词。Map 函数为每一个输入文档输出（主机名，检索词向量），其中主机名来自文档的 URL。Reduce 函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的（主机名，检索词向量）。</li><li>倒排索引：Map 函数分析每个文档输出一个（词，文档号）的列表，Reduce 函数的输入是一个给定词的所有（词，文档号），排序所有的文档号，输出（词，list（文档号）)。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。</li><li>分布式排序：Map 函数从每个记录提取 key，输出 (key,record)。Reduce 函数不改变任何的值。这个运算依赖分区机制和排序属性。</li></ul><h2 id="经验分享"><a href="#经验分享" class="headerlink" title="经验分享"></a>经验分享</h2><ul><li>约束编程模式使得并行和分布式计算非常容易，也易于构造容错的计算环境；</li><li>网络带宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节约了网络带宽。</li><li>多次执行相同的任务可以减少硬件配置不平衡带来的负面影响，同时解决了由于机器失效导致的数据丢失问题。</li></ul><h2 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h2><ul><li>通过简单的接口实现了自动的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现了在大量普通 PC 机上的高性能计算。</li><li>向工业界证明了 MapReduce 模型在分布式计算上的可行性，拉开了分布式计算的序幕并影响了其后所有的计算框架，包括现在流行的批处理框架 Spark 和流处理框架 Flink 都很受其影响。</li></ul><h2 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h2><ul><li>基于历史局限性和当时的成本考虑，没有利用内存去更高效的处理数据，不过也为 Spark 提供了思路。</li><li>没有将资料调度和计算调度分离，使得 MapReduce 系统看起来较为冗杂。在开源的 Hadoop 生态中，MapReduce 现只关注于计算，具体的资源调度由 Yarn 管理。 </li></ul><h2 id="相关系统"><a href="#相关系统" class="headerlink" title="相关系统"></a>相关系统</h2><ul><li>分布式存储系统：GFS/Colossus/HDFS</li><li>批处理框架：Spark</li><li>流处理框架：Flink</li><li>高可用机制：Chubby/ZooKeeper</li></ul><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l01.txt" target="_blank" rel="noopener">6.824 讲义</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/video/1.html" target="_blank" rel="noopener">6.824 视频</a></li><li><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">论文</a></li><li><a href="https://github.com/Cxka/paper/blob/0a72fe0b354b65bac25e45163163eb2573f1faf2/map-reduce/map-reduce-cn.pdf" target="_blank" rel="noopener">中文翻译</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>Google</tag>
      
      <tag>分布式计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MaxCompute 跨域流量优化论文阅读</title>
    <link href="/maxcompute-yugong-thesis/"/>
    <url>/maxcompute-yugong-thesis/</url>
    
    <content type="html"><![CDATA[<h2 id="相关背景"><a href="#相关背景" class="headerlink" title="相关背景"></a>相关背景</h2><p>随着大数据技术的长足发展，大公司和云供应商在全球创建了数十个地理上分散的数据中心（分布式数据中心）。一个典型的数据中心可包含数万台计算机，这些数据中心为许多大规模的 IT 企业提供了计算和存储能力。在管理这种大规模、分布式数据中心的过程中，减少跨数据中心流量是提高整体性能的核心瓶颈之一。</p><h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>MaxCompute 是阿里巴巴的大型数据管理和分析平台，管理着数十个分布式数据中心。每个数据中心都包含成千上万台服务器，并且通过广域网（WAN）相互连接。这些数据中心每天新增 500 万张数据表，并为阿里巴巴的各种业务应用程序（例如淘宝，天猫等）执行多达 700 万次的分析工作。 MaxCompute 中的作业每天生产和使用大量数据，形成了复杂的数据依赖关系。尽管这些依赖关系大多都在本地数据中心内部，随着业务的增长，来自非本地数据中心的依赖关系也在迅速增加。由于跨数据中心的依赖关系，使得 MaxCompute 中大约产生了数百 PB 通过广域网传输的数据。</p><p>日益增长的跨数据中心传输需求带来了多个方面的问题。WAN 的带宽约为 Tbps，而数据中心内网络的聚合带宽则大得多；另外，WAN 延迟是数据中心内部网络延迟的 10-100 倍。除网速之外， WAN 的成本也十分昂贵。如今，跨 DC 的带宽已成为一种非常宝贵的资源，同时也是 MaxCompute 运营的性能瓶颈。在优化之前，WAN 的成本占 MaxCompute 总体运营成本的很大一部分——考虑到 MaxCompute 的日常运营规模庞大，这是巨大的财务负担。正因如此，减少跨地区带宽的使用已经逐渐成为阿里巴巴数据中心业务的一大挑战。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>MaxCompute 研发了一个跨域流量优化系统 Yugong（意译：愚公），其通过与 MaxCompute 在大范围生产环境下进行协同运算，极大地降低了由项目迁移（project migration）、副本拷贝（table replication）以及计算调度（job outsourcing）所产生的大量跨数据中心带宽流量，由此有效地降低了运营成本。</p><h3 id="业务数据分析"><a href="#业务数据分析" class="headerlink" title="业务数据分析"></a>业务数据分析</h3><p>MaxCompute 业务场景中的数据有 project，table 和 partition 三个级别。project 可以类比于关系数据库中 database 的概念，通常是业务功能上相近的表的集合。table 是用户数据的某一张关系型数据表，partition 是 table 根据时间进行分区的子表，通常每张表每天会产生一个分区。 </p><p>其特性如下：</p><ul><li>project，job 和 table 遵循幂律分布。作业和表之间的跨 DC 依赖关系呈现出长尾现象。相对较少的热表和大型作业在跨 DC 依赖关系中占很大一部分。</li><li>不论是数据大小还是分区数量，大部分作业的输入都要比输出大得多。</li><li>连续几天创建的表分区具有相似的大小。一个分区的大小比它的表的大小小数百倍。大多数作业是周期性的，连续几天的表访问模式是稳定的。</li><li>最近的表分区被更频繁地访问，其他作业对其依赖的数量随着访问偏移量的增加呈指数级下降。</li><li>一些表经常被远程 DC 中的作业读取，因此复制这些表可以节省跨 DC 的带宽。另外，调度一些作业在它们的非默认 DC 中运行可以减少跨 DC 带宽的使用。</li><li>DC 具有动态且不可预测的资源利用模式，在同一时间段内可能存在不同的资源瓶颈。</li></ul><h3 id="模型概述"><a href="#模型概述" class="headerlink" title="模型概述"></a>模型概述</h3><p>下图为下文常用到的一些符号及其解释。<br><img src="/maxcompute-yugong-thesis/notation.png" srcset="/img/loading.gif" lazyload alt></p><p>在下文中，我们将尝试最小化一天中跨集群的总带宽使用。我们假设连接每对 DC 的广域网具有相同的单位成本。我们假设来自同一个分时表的所有分区的大小是相同的，作业每天重复出现，并且它们的表访问模式连续几天都是相同的。因此，我们只需要考虑一天内运行的作业。我们使用“所有作业”来表示“在当前日期 t<sub>cur</sub> 上运行的所有作业”。表访问模式仅由在 t<sub>cur</sub> 上运行的作业生成。作业和访问模式实际上在几天内缓慢变化，我们将在 table replication 节再介绍如何应用于生产环境。</p><p><img src="/maxcompute-yugong-thesis/model_1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/maxcompute-yugong-thesis/model_2.png" srcset="/img/loading.gif" lazyload alt></p><p>该分析模型在计算上是棘手的，因为它是（| T | + | P |）×| DC | 的整数规划问题，其中 | T | 是表的总数，| P | 是项目总数，并且 | DC | 是数据中心的数量。</p><p>根据前文讲述的业务数据分析，我们可以利用我们的发现来简化问题。由于作业倾向于读取最近的分区，并且它们对分区的依赖关系的大小随访问偏移的增加而呈指数下降，因此有理由首先假设我们有足够/无限的项目复制存储大小迁移，然后使用启发式方法确定固定存储预算下的寿命。这种简化极大地降低了模型的复杂性，因为我们实际上删除了存储空间的限制。</p><p>通过这种简化，我们可以将问题分解为两个问题：</p><ol><li>一个项目迁移问题，该问题首先在假定复制存储预算不受限制的情况下找到项目放置计划 P，</li><li>一个表复制问题，该问题在给定项目放置计划 P 后生成表复制计划 R，同时满足存储空间的约束。这种分离对于我们的生产环境也是很自然的，因为由于较高的迁移成本，项目放置/迁移不能频繁执行，而表复制计划可以更频繁地更新。</li></ol><h3 id="项目迁移"><a href="#项目迁移" class="headerlink" title="项目迁移"></a>项目迁移</h3><p>在简化的项目迁移模型中，我们删除了存储空间约束。根据给定的项目布置计划，可以通过以下方法获得 DC d 的最小跨 DC 带宽成本 BW<sup>opt（d）</sup>：</p><ol><li>从表 i 的 DC 中远程读取每个表 i 的所有必需数据。 如果从表 i 读取的数据量小于其分区的总大小； </li><li>否则将表 i 的所有分区存储在 DC d 中，并每天复制其最新分区。 </li></ol><p>因此，BW<sup>opt（d）</sup> 由以下公式 12 给出：</p><p><img src="/maxcompute-yugong-thesis/project_migration_1.png" srcset="/img/loading.gif" lazyload alt></p><p>上面关于 R<sub>i</sub><sup>t</sup>（d）沿时间维度 t 的总和有助于消除为每个时间分区共同考虑复制策略的复杂性。我们的目标是找到一个项目放置计划 P，以使总 BW<sup>opt（d）</sup> 最小化：</p><p><img src="/maxcompute-yugong-thesis/project_migration_2.png" srcset="/img/loading.gif" lazyload alt></p><p>即使进行了这种简化，项目和表的数量仍然很大，因为我们有成千上万个项目和数百万个表。我们利用跨 DC 依赖关系的幂律分布来进一步减小问题的大小，即少量表构成了大部分跨 DC 的依赖。因此，我们仅考虑项目迁移模型中具有最大依赖项大小的少数表。此外，在解决问题时，我们还发现，对少量项目进行迁移可以显着改善我们当前的项目布局，而随着影响力较大的项目已经放置在合适的 DC 中，随着进一步的迁移，这种改进会迅速降低。</p><p>我们的项目迁移策略还可用于解决新的项目放置问题。我们首先根据 DC 的负载将新项目放置在 DC 中，然后通过将 MigCount 设置为新项目的数量来解决项目迁移问题。</p><h3 id="数据拷贝"><a href="#数据拷贝" class="headerlink" title="数据拷贝"></a>数据拷贝</h3><p>给定上一节计算出的项目放置计划 P，我们然后找到一个表复制计划（即，找到每个 DC d 中每个表 i 的寿命 L<sub>i</sub>（d））以最小化跨 DC 带宽的总成本， 同时满足存储空间约束。 我们首先假设连续两天的表访问模式相同，针对不同 DC 中所有表的寿命设计一种启发式方法。然后我们删除该假设，并考虑动态维护表副本的生命周期，因为表访问模式实际上随着时间逐渐变化。 请注意，我们的解决方案中的表访问矩阵 R<sub>i</sub><sup>t</sup>（d）仅包含不属于 DC d 中项目的表，即 X<sub>p（i），d</sub> = 0，因为我们仅关心远程读取。为简单起见，我们在随后的讨论中省略了 DC d。</p><h4 id="DP-解法"><a href="#DP-解法" class="headerlink" title="DP 解法"></a>DP 解法</h4><p>我们可以通过 DP 算法来获得给定复制存储大小和给定项目放置计划下的最佳表复制计划。 我们将 dp（i，s）表示为可以通过考虑复制存储大小约束 s 下的前 i 个表获得的最小跨 DC 带宽成本，定义表 i 的寿命是 L<sub>i</sub>。 用于存储表 i 的副本的存储大小为 L<sub>i</sub>×S<sub>i</sub>。 则读取表 i 的分区所产生的跨 DC 带宽成本为：</p><ol><li>寿命未涵盖的部分的所有远程读取的总成本和。</li><li>寿命涵盖部分的复制成本。</li></ol><p><img src="/maxcompute-yugong-thesis/dp_1.png" srcset="/img/loading.gif" lazyload alt></p><p>因此 dp 算法的转移函数可以定义如下：</p><p><img src="/maxcompute-yugong-thesis/dp_2.png" srcset="/img/loading.gif" lazyload alt></p><p>存储预算为 s 的前 i 个表的最小跨 DC 带宽成本是枚举表 i 的所有可能寿命 L<sub>i</sub> 并取其中的最小值。</p><p>DP 算法的时间复杂度为 O（| T | | L | | storage |），其中 | T | 是表的数量（从几万到几百万），| L | 是每个表的可能寿命（通常为几百个），并且 | storage | 是 DP 公式中使用的复制存储单位的数量（大约十亿：大约是存储总预算（PB 级别）除以分区大小（MB 级别））。因此，DP 算法太昂贵了。</p><h4 id="贪心解法"><a href="#贪心解法" class="headerlink" title="贪心解法"></a>贪心解法</h4><p>作为 DP 算法的替代方法，我们提出了一种有效的贪心算法。 在每一步中，算法都会将表 i 的当前寿命 L<sub>i</sub> 最多提高 k 个单位，这由边际增益贪心地确定，其定义（公式 15）如下：</p><p><img src="/maxcompute-yugong-thesis/greedy.png" srcset="/img/loading.gif" lazyload alt></p><p>直观地，分子是通过将 L<sub>i</sub> 提前 k 个单位可以节省的跨 DC 带宽总成本，而分母是存储额外的 k 个分区副本所需的存储空间。 如果 Gain<sub>i</sub><sup>k</sup> &gt; 0，则意味着复制多余的 k 个分区可以进一步节省跨 DC 带宽。 请注意，当 L<sub>i</sub> = 0 时，我们需要从 Gain<sub>i</sub><sup>k</sup> 中减去 S<sub>i</sub>，因为我们需要使用跨 DC 带宽来复制分区 tp<sub>i</sub><sup>t<sub>cur</sub></sup>，而对于 L<sub>i</sub> &gt; 0，此成本 i 已经被 L<sub>i</sub>  = 0 时所覆盖。</p><p>下图就是提出的贪心算法（算法 1）。 该算法首先初始化最大优先队列（maxPQ），以在所有表 i 的 L<sub>i</sub> = 0 时，如果 Gain<sub>i</sub><sup>k</sup> &gt; 0，则保留所有可能的 Gain<sub>i</sub>。 然后，它将继续使 maxPQ 的最大增益出队，直到队列变空。 假设对于某个表 i，当前的最大增益为 Gain<sub>i</sub><sup>k’</sup> ，如果存储预算仍允许其他 k’ 个副本，则将 L<sub>i</sub> 提前 k’ 个单位。”l<sub>i</sub> = L<sub>i</sub>“ 条件是确保对于所有基于当前 L<sub>i</sub> 计算的 Gain<sub>i</sub><sup>k’</sup>，其中 0 ≤ k’&lt; k，i 只能使用一个 k’ 来推进 L<sub>i</sub>。 在 L<sub>i</sub> 前进之后，将基于更新的 L<sub>i</sub> 来计算新增益 Gain<sub>i</sub><sup>k</sup> 并将其放入 maxPQ 中。</p><p><img src="/maxcompute-yugong-thesis/kprobe.png" srcset="/img/loading.gif" lazyload alt></p><p>以上算法的时间复杂度为 O（k | T || L | log（k | T || L |）），由于 k 仅为数百个数量级，因此它的耗费时间大大小于 DP 算法。 此外，我们证明了贪心算法在给定足够的存储预算的情况下可以获得最佳带宽成本，如下所示。</p><p>定理 1:</p><blockquote><p>将 STO<sub>rep</sub> 设置为达到等式 12 中的最佳带宽成本且 k 为最大寿命时使用的实际复制存储大小，算法 1 计算出的表复制计划能够给出与等式 12 相同的最佳带宽成本。</p></blockquote><p>当达到公式 12 中的最佳带宽成本时，令 L<sub>i</sub><sup>opt</sup> 为表 i 的寿命。 考虑算法 1 中表 i 的当前寿命 L<sub>i</sub>。我们有 L<sub>i</sub> &lt; L<sub>i</sub><sup>opt</sup>，并且将 L<sub>i</sub> 提升到 L<sub>i</sub><sup>opt</sup> 的收益高于任何 l &gt; L<sub>i</sub><sup>opt</sup> 的收益，因为 L<sub>i</sub><sup>opt</sup> 需要较少的存储空间，并且产生相同的读取次数（ 请注意，在给定无限复制存储预算的情况下，因此只要从该分区的远程读取大小大于该分区的大小，就可以复制任何分区，如公式 12 所示）因此，如果我们的存储预算与等式 12 中用于获得最佳带宽成本的实际复制存储大小相同，则在某一点上表 i 将从 maxPQ 出队，并得到 L<sub>i</sub> 到 L<sub>opt</sub> 的增益。 之后进一步提升 L<sub>i</sub> 的增益将变为 0，从而不会再入队。</p><h4 id="动态维护"><a href="#动态维护" class="headerlink" title="动态维护"></a>动态维护</h4><p>我们的贪心解决方案目前仅考虑固定的表访问模式。实际上，由于业务的增长和偶尔的临时工作，表访问模式实际上在随时间变化（尽管缓慢）。 因此，我们需要定期更新表复制计划。 假设计划每 δ 天更新一次。 现在的问题是，给定当前的复制计划 R，我们需要找到一个新的复制计划 R’，以便它可以用作接下来 δ 天的良好复制计划，以及最小化从 R 至 R’ 状态迁移的带宽消耗。 作为过渡成本的示例，假设表 i 的寿命是 R 中的 L<sub>i</sub> 和 R’ 中的 L’<sub>i</sub>，并且 L<sub>i</sub> &lt; L’<sub>i</sub>，这意味着 R’ 对表 i 的覆盖范围比 R 多。 为了将较旧的分区从（t<sub>cur</sub> -L’<sub>i</sub>）复制到（t<sub>cur</sub> -L<sub>i</sub>），需要额外的带宽以保证从 R 过渡到 R’。</p><p>更新复制计划的最简单方法是每 δ 天重新运行一次算法 1，但这可能会导致相当大的过渡成本。考虑到复制较旧分区所产生的成本，我们建议对增益函数进行简单的修改。 设 I<sub>i，t</sub> 为指标，如果 tp<sub>i</sub><sup>t</sup> 被 R 覆盖，则 I<sub>i，t</sub>  = 1，否则，I<sub>i，t</sub> = 0。 我们将 G<sub>i，t</sub> 定义为如果新计划涵盖 tp<sub>i</sub><sup>t</sup> 可以节省的带宽量。</p><p><img src="/maxcompute-yugong-thesis/incremental_maintenance_1.png" srcset="/img/loading.gif" lazyload alt></p><p>直觉是，如果分区 tp<sub>i</sub><sup>t</sup> 不在复制计划中，则将其包括在计划中需要付出一定的代价，该损失等于在 δ 天内复制 tp<sub>i</sub><sup>t</sup> 的摊余带宽成本。也就是说，除非收益很大，否则我们不鼓励复制较旧的分区。通过在公式 15 中用 G<sub>i</sub><sup>t</sup> 代替 R<sub>i</sub><sup>t</sup>，我们获得了一个新的增益函数：</p><p><img src="/maxcompute-yugong-thesis/incremental_maintenance_2.png" srcset="/img/loading.gif" lazyload alt></p><p>除了使用新的增益函数外，我们还取了前 δ 天的表访问矩阵 R<sub>i</sub><sup>t</sup> 的平均值以减少表访问模式中振荡的影响。</p><h3 id="计算调度"><a href="#计算调度" class="headerlink" title="计算调度"></a>计算调度</h3><p>计算调度，即将作业调度到非默认 DC 进行处理，该 DC 可能包含作业所需的全部或部分输入表。当输入数据较大时，计算调度可以减少跨 DC 的带宽使用。这也可以用于在分布式控制系统之间平衡负载和各种资源（例如，中央处理器、内存、磁盘、网络等）的利用率来提高整体资源利用率（从而节省生产成本）。</p><p>对比前两种离线方式，因为调度决策需要考虑分布式控制系统的负载和资源利用率，所以计算调度需要在线解决方案。此外我们还需要考虑远程分布式控制系统是否有空闲资源来运行该作业，以及预期的作业完成时间（包括远程分布式控制系统中的等待时间）是否短于作业的默认 DC 时间。因此，我们设计了一个简单的评分函数来决定是否将工作 j 调度给 DC d：</p><p><img src="/maxcompute-yugong-thesis/job_outsourcing.png" srcset="/img/loading.gif" lazyload alt></p><p>其中 Cost（j，d）和 WaitT（j，d）是跨 DC 带宽的总成本以及如果将工作 j 外包给 DC d 的估计等待时间，而 AvailResrc（d）是 DC d 中的可用资源量。请注意，Cost（j，d）包括将所有必要的信息/数据发送到 DC d 以执行作业，并将作业输出传回默认的 DC。我们仔细调整了参数 α 和 β，以降低跨 DC 带宽的成本。</p><h3 id="效果评估"><a href="#效果评估" class="headerlink" title="效果评估"></a>效果评估</h3><p>首先报告愚公在阿里巴巴投入生产的整体表现。下图显示了在典型的一天中每个 DC 传入的跨 DC 带宽使用量的减少。 愚公将不同 DC 的跨 DC 带宽使用率从 14％ 降低到 88％ 。 DC2 具有最大的减少量，因为它具有最大的远程依赖性。当天，愚公总共减少了总带宽使用量的 76％。</p><p><img src="/maxcompute-yugong-thesis/performance.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="创新之处"><a href="#创新之处" class="headerlink" title="创新之处"></a>创新之处</h2><ul><li>根据实际业务的工作流来将如何减少跨域流量的难题解耦为三个容易分开解决的子问题。</li><li>在数据拷贝部分进行了系统的分析与设计并就此过程中的取舍进行了讨论。</li></ul><h2 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h2><ul><li>很多简化部分很直接，这可能是容易想到的最直接最容易实现的方法，但也可能还有一定的可优化空间。</li><li>如果能够将存储空间成本和带宽成本量化似乎模型会更准确。</li></ul><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><h3 id="地理分布式调度"><a href="#地理分布式调度" class="headerlink" title="地理分布式调度"></a>地理分布式调度</h3><p>最近有关分析工作负载的地理分布调度工作仅考虑了少量作业，并假设数据在地理分布的 DC 之间进行了分区，并且一项任务可以在多个 DC 中运行。 Iridium 优化了任务调度和数据放置，以实现分析查询的低延迟。 Geode 和 WANalytics 使查询计划了解 WAN，并为整个 DC 的数据分析提供以网络为中心的优化。 Clarinet 通过考虑网络带宽，任务位置，网络传输调度和多个并发查询，提出了一种支持 WAN 的查询优化器。Tetrium 考虑了地理分布的 DC 中用于任务放置和作业调度的计算和网络资源。Pixida 应用图分区来最大程度地减少数据分析作业中的跨 DC 任务依赖性。Hung 提出了地理分布的作业调度算法，以最大程度地减少整体作业的运行时间，但并未考虑 DC 之间的 WAN 带宽使用情况。 Bohr 利用地理分布的 OLAP 数据立方体展示了不同 DC 中数据之间的相似性。 Lube 实时检测和缓解地理分布数据分析查询中的瓶颈。</p><p>还有其他使数据流分析，分布式机器学习和图形分析可感知 WAN 的工作。 JetStream 提出了显式的编程模型，以减少分析流数据集所需的带宽。对于机器学习工作负载，Gaia 和 GDML 开发了地理分布式解决方案，以有效利用稀缺的 WAN 带宽，同时保留 ML 算法的正确性。 Monarch 和 ASAP 提出了一种地理分布图模式挖掘的近似解决方案。</p><h3 id="云原生数据仓库"><a href="#云原生数据仓库" class="headerlink" title="云原生数据仓库"></a>云原生数据仓库</h3><p>Google BigQuery，Amazon Redshift，Microsoft Azure Cosmos DB 和 Alibaba MaxCompute 是大型数据仓库产品。 MaxCompute 中的 “project” 概念对应于 Redshift 中的 “database” 和 BigQuery 中的 “project”。 尽管愚公在此工作中主要是用作 MaxCompute 的插件构建的，但类似的想法也可以应用于其他地理分布的数据仓库平台。</p><h3 id="缓存和打包"><a href="#缓存和打包" class="headerlink" title="缓存和打包"></a>缓存和打包</h3><p>从 CPU 高速缓存，内存高速缓存到应用程序级高速缓存，高速缓存管理是在不同级别的计算机体系结构上经过充分研究的主题。 Memcached 和 Redis 是高度可用的分布式键值存储，可在磁盘上提供内存缓存。EC-Cache 和 SP-Cache 为数据密集型群集和对象存储提供了内存中缓存。Piccolo，Spark，PACMan 和 Tachyon 结合了用于集群计算框架的内存缓存。在这项工作中，我们使用磁盘存储作为远程分区的缓存，以减少跨 DC 带宽。 表复制问题是背包问题的变体，项目放置问题是装箱问题的变体。 Tetris 将多资源分配问题与多维 bin 打包问题进行了类比，以进行任务调度。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="http://www.vldb.org/pvldb/vol12/p2155-huang.pdf" target="_blank" rel="noopener">论文</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>论文阅读</tag>
      
      <tag>分布式调度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JProfile 远程配置</title>
    <link href="/jprofile-remote/"/>
    <url>/jprofile-remote/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>JProfile 是 Java 常用的性能分析工具，常被用来查看内存占用，CPU 时间消耗等数据。本地配置 JProfile 较为简单，可以参考此 <a href="https://www.javatt.com/p/48237" target="_blank" rel="noopener">博客</a>。在一些情况下，监控的 Java 服务跑在服务器上，因此不能使用本地的 JProfile 来监控。不过 JProfile 能够支持远程连接监控，只不过需要一些额外的配置。此博客的内容就是介绍如何使用 JProfile 监控远程的 Java 应用。</p><h2 id="配置方案一：ssh-免密连接"><a href="#配置方案一：ssh-免密连接" class="headerlink" title="配置方案一：ssh 免密连接"></a>配置方案一：ssh 免密连接</h2><ol><li>配置与服务器的免密登陆，可参考此 <a href="https://blog.csdn.net/jeikerxiao/article/details/84105529" target="_blank" rel="noopener">博客</a>。</li><li>从 <a href="https://www.ej-technologies.com/download/jprofiler/files" target="_blank" rel="noopener">官方网站</a> 上根据操作系统下载对应本地和服务器的 JProfile（需要确保两者版本一致）。注意服务端选择下载 <code>Setup Executable</code> 的可执行脚本。</li><li>客户端安装配置好本地的 JProfile， 然后将服务器的 JProfile 利用 scp 等工具传到服务器上去（也可在上述网页中直接复制链接在服务器上 wget 或者 curl -O 下载）。</li><li>服务端执行 <code>sh ./jprofiler_linux_11_1_4.sh</code> 来安装 JProfile，无脑同意 OK 和 Enter 就能够让其正确安装并且后台运行起来。</li><li>服务端启动要监控的应用程序，如 IoTDB。</li><li>客户端打开 JProfile，点击 <code>Profile a demo session or a saved session</code>，选择 <code>New Session</code> 栏的 <code>New Session</code> 手动创建一个远程连接。<br><img src="/jprofile-remote/jprofile_0.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_2.png" srcset="/img/loading.gif" lazyload alt></li><li>填好 <code>Session name</code>，<code>Attach type</code> 选择 <code>Attach to remote JVM</code>，连接方式选择 <code>SSH tunnel</code>，然后点击 <code>Edit</code> 开始配置服务器 ip, host, ssh 秘钥等信息。<br><img src="/jprofile-remote/jprofile_3.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_4.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_5.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_6.png" srcset="/img/loading.gif" lazyload alt></li><li>配置完后点击 finish 再点击 ok 即可连接到远程的 JProfile，接着选择对应要监控的 Java 应用程序。<br><img src="/jprofile-remote/jprofile_7.png" srcset="/img/loading.gif" lazyload alt></li><li>配置监控模式，一般选择 <code>Async sampling</code>，该模式对性能影响最小。<br><img src="/jprofile-remote/jprofile_8.png" srcset="/img/loading.gif" lazyload alt></li><li>配置调用树的过滤器，该参数一般用来指示 jprofile 来记录 cpu view 时的函数耗时统计。加上要统计的包的前缀即可，比如 <code>org.apache.iotdb</code>。<br><img src="/jprofile-remote/jprofile_9.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_10.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_11.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_12.png" srcset="/img/loading.gif" lazyload alt></li><li>可以开始监控分析了！<br><img src="/jprofile-remote/jprofile_13.png" srcset="/img/loading.gif" lazyload alt></li><li>之后每次远程连接都可以直接到 <code>Open Session</code> 栏选择这次建好的 session 即可，不用再进行配置了。<br><img src="/jprofile-remote/jprofile_14.png" srcset="/img/loading.gif" lazyload alt></li></ol><h2 id="配置方案二：http-端口连接"><a href="#配置方案二：http-端口连接" class="headerlink" title="配置方案二：http 端口连接"></a>配置方案二：http 端口连接</h2><ol><li>从 <a href="https://www.ej-technologies.com/download/jprofiler/files" target="_blank" rel="noopener">官方网站</a> 上根据操作系统下载对应本地和服务器的 JProfile（需要确保两者版本一致）。注意服务端选择下载 <code>TAR.GZ Archive</code> 的压缩包。</li><li>客户端安装配置好本地的 JProfile， 然后将服务器的 JProfile 利用 scp 等工具传到服务器上去（也可在上述网页中直接复制链接在服务器上 wget 或者 curl -O 下载）。</li><li>服务端启动要监控的应用程序，如 IoTDB。</li><li>服务端执行<code>tar -zxvf jprofiler_linux_11_1_4.tar.gz</code>解压压缩包，然后执行 <code>jprofiler11.1.4/bin/jpenable -p 10000</code> 手动指定 10000 端口来启动 JProfile。（注，必须有运行的 JVM 才可以启动，并且程序一旦关闭重启服务端的 jprofile 也需要重新启动。）</li><li>客户端打开 JProfile，点击 <code>Profile a demo session or a saved session</code>，选择 <code>New Session</code> 栏的 <code>New Session</code> 手动创建一个远程连接。<br><img src="/jprofile-remote/jprofile_0.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_2.png" srcset="/img/loading.gif" lazyload alt></li><li>填好 <code>Session name</code>，<code>Attach type</code> 选择 <code>Attach to remote JVM</code>，连接方式选择 <code>Directly connection to</code>，配置好 host 并指定 <code>Profiling port</code> 为服务端手动指定的端口 10000。<br><img src="/jprofile-remote/jprofile_15.png" srcset="/img/loading.gif" lazyload alt></li><li>配置完后点击 ok 即可连接到远程的 JProfile，接着选择对应要监控的 Java 应用程序。<br><img src="/jprofile-remote/jprofile_7.png" srcset="/img/loading.gif" lazyload alt></li><li>配置监控模式，一般选择 <code>Async sampling</code>，该模式对性能影响最小。<br><img src="/jprofile-remote/jprofile_8.png" srcset="/img/loading.gif" lazyload alt></li><li>配置调用树的过滤器，该参数一般用来指示 jprofile 来记录 cpu view 时的函数耗时统计。加上要统计的包的前缀即可，比如 <code>org.apache.iotdb</code>。<br><img src="/jprofile-remote/jprofile_9.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_10.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_11.png" srcset="/img/loading.gif" lazyload alt><br><img src="/jprofile-remote/jprofile_12.png" srcset="/img/loading.gif" lazyload alt></li><li>可以开始监控分析了！<br><img src="/jprofile-remote/jprofile_13.png" srcset="/img/loading.gif" lazyload alt></li><li>之后每次远程连接都可以直接到 <code>Open Session</code> 栏选择这次建好的 session 即可，不用再进行配置了。<br><img src="/jprofile-remote/jprofile_14.png" srcset="/img/loading.gif" lazyload alt></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本博客傻瓜式介绍了使用 JProfile 来对远程服务器上运行的 Java 服务进行监控分析的两种方式。其中 ssh 免密连接方式更方便，其启动时不需要有启动的 JVM 且能够自动检测随后启动的 JVM 让客户端在连接时再挑选。 http 连接方式在监控的 JVM 关闭重启后服务端的 jprofile 也需要手动重启，较为麻烦。因此建议大家都使用第一种连接方式。</p>]]></content>
    
    
    
    <tags>
      
      <tag>IoTDB</tag>
      
      <tag>开发工具配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BASE 定理介绍</title>
    <link href="/base-theory/"/>
    <url>/base-theory/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>CAP 理论表明，对于一个分布式系统而言，它是无法同时满足 Consistency（强一致性）、Availability（可用性）和 Partition tolerance（分区容忍性）这三个条件的，最多只能满足其中两个。</p><p>对于绝大多数互联网应用来说，由于网络环境是不可信的，所以分区容错性（P）必须满足。</p><p>如果只能在一致性和可用性之间做出选择的话，大部分情况下大家都会选择牺牲一部分一致性来保证可用性。因为如果不返回给用户数据，用户的体验会十分差，因此很多应用宁肯拒绝服务也不会能访问却没有数据。当然，在一些较为严格的场景比如支付场景下，强一致性是必须要满足的。</p><p>好了，我们只能放弃一致性，但是我们真这样做了，将一致性放弃了，现在这个系统返回的数据你敢信吗？没有一致性，系统中的数据也就从根本上变得不可信了，那这数据拿来有什么用，那这个系统也就没有任何价值，根本没用。</p><p>如上所述，由于我们三者都无法抛弃，但 CAP 定理限制了我们三者无法同时满足。在这种情况下，我们只能选择尽量靠近 CAP 定理，即尽量让 C、A、P 都满足。在此大势所趋下，eBay 的架构师 Dan Pritchett 源于对大规模分布式系统的实践总结，在 ACM 上发表文章提出 BASE 理论，其是基于 CAP 定理逐步演化而来的。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>BASE 理论是 Basically Available（基本可用），Soft State（软状态）和 Eventually Consistent（最终一致性）三个短语的缩写。</p><p>其核心思想是：</p><blockquote><p>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p></blockquote><h3 id="Basically-Available"><a href="#Basically-Available" class="headerlink" title="Basically Available"></a>Basically Available</h3><p>基本可用是相对于正常的系统来说的，常见如下情况：</p><ul><li><p>响应时间上的损失：正常情况下的搜索引擎 0.5 秒即返回给用户结果，而基本可用的搜索引擎可以在 2 秒作用返回结果。</p></li><li><p>功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。</p></li></ul><h3 id="Soft-state"><a href="#Soft-state" class="headerlink" title="Soft state"></a>Soft state</h3><p>软状态是相对原子性来说的：</p><ul><li>原子性（硬状态）：要求多个节点的数据副本都是一致的，这是一种”硬状态”。</li><li>软状态（弱状态）：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延迟。</li></ul><h3 id="Eventually-Consistent"><a href="#Eventually-Consistent" class="headerlink" title="Eventually Consistent"></a>Eventually Consistent</h3><p>最终一致性是相对强一致性来说的：</p><ul><li>系统并不保证连续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。最终一致性是弱一致性的特定形式。</li><li>对于软状态，我们允许中间状态存在，但不可能一直是中间状态，必须要有个期限，系统保证在没有后续更新的前提下，在这个期限后，系统最终返回上一次更新操作的值，从而达到数据的最终一致性，这个容忍期限（不一致窗口的时间）取决于通信延迟，系统负载，数据复制方案设计，复制副本个数等。DNS 就是一个典型的最终一致性系统。</li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>讲完了定义，大家对于 BASE 到底是什么，到底有什么用可能还存在质疑，可以参照这篇 <a href="https://zhuanlan.zhihu.com/p/341700125" target="_blank" rel="noopener">博客</a>。</p><h2 id="最终一致性的种类"><a href="#最终一致性的种类" class="headerlink" title="最终一致性的种类"></a>最终一致性的种类</h2><p>在实际工程实践中，最终一致性常被分为 5 种：</p><h3 id="因果一致性（Causal-consistency）"><a href="#因果一致性（Causal-consistency）" class="headerlink" title="因果一致性（Causal consistency）"></a>因果一致性（Causal consistency）</h3><p>如果节点 A 在更新完某个数据后通知了节点 B，那么节点 B 之后对该数据的访问和修改都是基于 A 更新后的值。与此同时，和节点 A 无因果关系的节点 C 的数据访问则没有这样的限制。</p><h3 id="读己之所写（Read-your-writes）"><a href="#读己之所写（Read-your-writes）" class="headerlink" title="读己之所写（Read your writes）"></a>读己之所写（Read your writes）</h3><p>节点 A 更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</p><h3 id="会话一致性（Session-consistency）"><a href="#会话一致性（Session-consistency）" class="headerlink" title="会话一致性（Session consistency）"></a>会话一致性（Session consistency）</h3><p>系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</p><h3 id="单调读一致性（Monotonic-read-consistency）"><a href="#单调读一致性（Monotonic-read-consistency）" class="headerlink" title="单调读一致性（Monotonic read consistency）"></a>单调读一致性（Monotonic read consistency）</h3><p>如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</p><h3 id="单调写一致性（Monotonic-write-consistency）"><a href="#单调写一致性（Monotonic-write-consistency）" class="headerlink" title="单调写一致性（Monotonic write consistency）"></a>单调写一致性（Monotonic write consistency）</h3><p>一个系统要能够保证来自同一个节点的写操作被顺序的执行。</p><p><img src="/base-theory/consistency_serializable.png" srcset="/img/loading.gif" lazyload alt></p><blockquote><p>在实际的实践中，这 5 种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。</p></blockquote><p>事实上，最终一致性并不是只有那些大型分布式系统才设计的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往存在延时，这取决于日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的的数据将是旧的，因此就出现了不一致的情况。当然，无论是采用多次重试还是将数据修正，关系型数据库还是能够保证最终数据达到一致——这就是关系数据库提供最终一致性保证的经典案例。</p><p>生产系统的最终一致性示例可参考此 <a href="https://zhuanlan.zhihu.com/p/344235098" target="_blank" rel="noopener">博客</a>。</p><h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>ACID，是指数据库管理系统在写入或更新数据的过程中，为保证事务（transaction）是正确可靠的，所必须具备的四个特性：</p><ul><li>原子性（atomicity，或称不可分割性）</li><li>一致性（consistency）</li><li>隔离性（isolation，又称独立性）</li><li>持久性（durability）</li></ul><h4 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h4><p>一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。</p><h4 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h4><p>在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。</p><h4 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h4><p>数据库允许多个并发事务同时对齐数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p><h4 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h4><p>事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p><h3 id="与-BASE-的联系"><a href="#与-BASE-的联系" class="headerlink" title="与 BASE 的联系"></a>与 BASE 的联系</h3><p>可以参考 <a href="https://people.eecs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf" target="_blank" rel="noopener">PODC</a> 的介绍：</p><p><img src="/base-theory/podc.jpeg" srcset="/img/loading.gif" lazyload alt></p><ul><li>ACID 是传统数据库常用的设计理念，追求强一致性模型。</li><li>BASE 支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。</li></ul><h3 id="与-CAP-的联系"><a href="#与-CAP-的联系" class="headerlink" title="与 CAP 的联系"></a>与 CAP 的联系</h3><p>CAP 理论的一致性是保证同样一个数据在所有不同服务器上的拷贝都是相同的，这是一种逻辑保证，而不是物理，因为光速限制，在不同服务器上这种复制是需要时间的，集群通过阻止客户端查看不同节点上还未同步的数据维持逻辑视图。</p><p>当跨分布式系统提供 ACID 时，这两个概念会混淆在一起，Google’s Spanner system 能够提供分布式系统的 ACID，其包含 ACID+CAP 的设计：</p><p><img src="/base-theory/spanner.png" srcset="/img/loading.gif" lazyload alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总体来说 BASE 理论面向的是大型高可用、可扩展的分布式系统。与传统 ACID 特性相反，不同于 ACID 的强一致性模型，BASE 理论基于 CAP 定理提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID，BASE 和 CAP 理论往往又会结合使用。</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Monarch 论文阅读</title>
    <link href="/monarch/"/>
    <url>/monarch/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Monarch 是谷歌的一个全球分布的内存时间序列数据库系统，它被广泛用在监控谷歌上十亿用户规模的应用程序和系统的可用性、正确性、性能、负载和其他方面。</p><p>Monarch 自 2010 年开始持续运行，收集、组织、存储、查询大量全球范围内快速增长的时间序列数据。它目前在内存中存储近 PB 的压缩时间序列数据，每秒摄入 TB 的数据，每秒处理数百万次查询。</p><p>本文介绍了系统的结构，以及在区域分布式架构下实现可靠、灵活的统一系统的新机制。我们也分享了十年来在谷歌中开发和运行 Monarch 作为服务的经验教训。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>谷歌有大量的计算机系统监控需求。数以千计的团队正在运营面向全球用户的服务（如 YouTube、GMail 和 Google Maps)，或者为这些服务（如 Spanner、Borg 和 F1) 提供硬件和软件基础设施。这些团队需要监视不断增长和变化的异构实体（例如设备、虚拟机和容器）集合，这些实体数量达数十亿，分布在全球各地。</p><p>谷歌必须从这些实体中收集度量，以时间序列的形式存储，并进行查询，以支持以下用例：</p><ol><li>当被监视的服务没有正确执行时检测和警报；</li><li>显示显示服务状态和运行状况的图形仪表板；</li><li>针对问题的不可知性执行特别查询，探索性能和资源使用情况。</li></ol><p>Borgmon 是谷歌内部的初代监控系统。随着大数据时代的到来，Borgmon 的部署规模逐渐扩大，暴露了一些弊端：</p><ol><li>Borgmon 常被鼓励使用成一种分散的架构，即每个团队都建立并管理自己的 Borgmon 实例，这导致一些人力资源的浪费。此外，用户经常需要跨应用程序和基础设施边界检查和关联监控数据以解决问题，而跨多个 Borgmon 实例来操作是很难或不可能实现的；</li><li>Borgmon 缺乏度量符号和度量值的图表化，导致了查询的语义歧义，限制了查询语言在数据分析过程中的表达能力；</li><li>Borgmon 不支持分布（即柱状图）值类型，这是一种强大的数据结构，能够进行复杂的统计分析（例如，计算跨多个服务器的请求延迟的 99%);</li><li>Borgmon 要求用户手动跨多个实例对大量被监视的全局服务实体进行切分，并建立查询评估树。</li></ol><p>考虑到这些经验教训，Monarch 成为了谷歌的下一代大规模监控系统。它的设计是为了适应持续增长的流量，并支持不断扩展的用例集。它为所有团队提供单一的统一服务，从而最大限度地减少了操作的工作量。它有一个简化的数据模型，便于复杂的查询和分布式类型时间序列的全面支持。</p><h2 id="系统概述"><a href="#系统概述" class="headerlink" title="系统概述"></a>系统概述</h2><p>Monarch 的设计理念：</p><ul><li>Monarch 技术上被设计成了一个 AP 系统而不是 CP 系统。他们认为在监控报警的场景下可用性比一致性重要得多，因为这能够显著增加检测到异常情况和减轻异常影响的平均时间。</li><li>Monarch 的关键报警路径上不能产生循环依赖，即不能使用谷歌内部的 Bigtable, Colossus (the successor to GFS), Spanner, Blobstore, and F1 等存储系统再去监控这些存储系统的集群（非关键路径可以适当使用）。</li><li>结合全局管理和查询对区域 zone 进行本地监控。在降低延迟，减少可靠性问题的同时能够提供全球视角。</li><li>为了可靠性，Monarch 的全局组件在地理上进行复制，并使用最接近的副本与地域性组件交互以利用局部性，其区域 zone 中的组件将跨集群复制。</li></ul><p><img src="/monarch/system_overview.png" srcset="/img/loading.gif" lazyload alt></p><p>从功能上讲，为了可靠性，Monarch 组件可以分为三类：持有状态组件、数据存储组件和查询执行组件。</p><p>持有状态组件：</p><ul><li>叶子（Leaves）将监视数据存储在内存中的时间序列存储中。</li><li>恢复日志（Recover Logs）将与叶子相同的监视数据存储在磁盘上，这些数据最终会被重写到一个长期时间序列存储库中。</li><li>全局配置服务器及其分区镜将配置数据保存在 Spanner 数据库中。</li></ul><p>数据存储组件：</p><ul><li>摄取路由器（Ingestion Routers）使用时间序列键中的信息来路由数据到适当的 Monarch 区域中的叶路由器。</li><li>叶路由器（Leaf Routers）接受数据存储在一个区域 zone，并路由到叶子存储。</li><li>范围分配管理器（Range Assigner）将数据分配到叶子，以平衡在一个区域的叶子之间的负载。</li></ul><p>查询执行组件：</p><ul><li>混合器（Mixers）将查询划分为多个子查询，将其路由到叶子去执行并合并子查询结果。查询可以在根级别（由根混合器）或在区域 zone 级别（由区域混合器）发出。根级查询同时涉及根和区域 zone 混合器。</li><li>索引服务器（Index Server）为每个区域 zone 和叶节点索引数据，并指导分布式查询执行。</li><li>评估器（Evaluator）定期向混合器发出长期查询并将结果写回叶子。</li></ul><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p><img src="/monarch/data_model.png" srcset="/img/loading.gif" lazyload alt><br>从概念上讲，Monarch 将监控数据存储为结构化表中的时间序列。每个表由多个键列组成时间序列键和一个值列组成时间序列点的历史，如图 2 所示。键列也称为字段，有两个源：目标（Target）和指标（Metric）。</p><h3 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h3><p>Monarch 使用 Target 将每个时间序列与它的源实体（或监视实体）相关联。例如，源实体就是生成时间序列的进程或 VM。每个 Target 表示一个受监视的实体，并符合一个 Target Schema，该模式定义了一组有序的 Target 字段名和相关字段类型。上图显示了一个名为 ComputeTask 的流行目标模式：每个 ComputeTask 目标标识 Borg 集群中正在运行的任务，具有四个字段：user、job、clsuter 和 task_num。</p><p>Monarch 将数据存储在离生成数据很近的位置。每个 Target Schema 都有一个标注为 location 的字段；这个位置字段的值决定了时间序列被路由和存储到的特定 Moranch zone。</p><p>在每个 zone 内，Monarch 将同一目标的时间序列存储在同一叶子中，因为它们来自同一实体，并且更有可能在一个 join 中被一起查询。Monarch 还将目标以<code>[S_start,S_end]</code>的形式分组为不同的目标范围，其中 S_start 和 S_end 是开始和结束目标字符串。目标字符串通过有序连接 Target Schema 名称来表示。</p><p>Target 范围用于字典分片和叶节点间的负载均衡；这允许在查询中更有效地跨邻近目标聚合。</p><h3 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h3><p>Metric 测量被监视目标的一个方面，如任务所服务的 RPC 数量、VM 的内存使用情况等。与 Target 类似，Metric 也有 Metric Schema，该模式定义时间序列值类型和一组指标字段。指标的命名类似于文件。图 2 显示了一个称为 /rpc/server/latency 的示例度量，它测量 RPC 到服务器的延迟；它有两个度量字段，通过 service 和 command 来区分 RPC。</p><p><img src="/monarch/metric.png" srcset="/img/loading.gif" lazyload alt><br>值类型可以是 bool、int64、double、string、分布类型或其他类型的元组。除了分布类型之外，它们都是标准类型，分布类型是一种紧凑类型，表示大量双精度值。分布包括一个直方图，该直方图将一组 double 值划分到称为 bucket 的子集中，并使用总体统计信息（如平均值、计数和标准差）汇总每个 bucket 中的值。桶边界是可配置的，可以在数据粒度（即精度）和存储成本之间进行权衡：用户可以为更流行的值范围指定更细的桶。图 3 显示了一个测试组分布类型的 /rpc/server/latency 时间序列，它测量服务器在处理 RPC 时的延迟；它有一个固定的桶大小为 10ms。</p><p>Exemplars：分布中的每个桶可以包含该桶中的值的一个范例。这会便于用户轻易的从直方图中找到慢 RPC 的详细信息。</p><p>Metric types：可以是度量类型或累积类型。累积 Metric 对于支持由许多服务器组成的分布式系统非常重要，这些服务器可能由于作业调度而定期重新启动，在重新启动期间可能会丢失一些点。</p><h2 id="可扩展收集"><a href="#可扩展收集" class="headerlink" title="可扩展收集"></a>可扩展收集</h2><p>为了实时摄取大量的时间序列数据，Monarch 采用了两种分治策略和一种关键的优化，在收集过程中对数据进行聚合。</p><h3 id="数据收集概述"><a href="#数据收集概述" class="headerlink" title="数据收集概述"></a>数据收集概述</h3><p>摄取路由器根据位置字段将时间序列数据划分给 zone，叶路由器根据范围分配管理器将数据分布在叶子之间。</p><p>一些细节：</p><ul><li>客户端会按照特定频率将数据发送到离其最近的摄取路由器（全球分布）。</li><li>location-to-zone 的映射配置在摄取路由器中且可以动态更新。</li><li>每个叶路由器维护一个持续更新的 range map，该映射将每个目标范围映射到三个叶子副本。注意叶路由器从叶子而不是从范围分配管理器获得范围映射的更新。</li><li>最小化内存碎片和分配混乱。为了在 CPU 和内存之间实现平衡，内存存储只执行少量压缩，比如时间戳共享和增量编码。时间戳共享非常有效：一个时间戳序列平均被大约 10 个时间序列共享。</li><li>尽最大努力异步向分布式文件系统写恢复日志但不需要确认来隔离分布式文件系统的故障。 </li><li>叶子收集的数据还会触发用于约束读放大的 zone 和 root 索引服务器中的更新。</li></ul><h3 id="zone-内部的负载均衡"><a href="#zone-内部的负载均衡" class="headerlink" title="zone 内部的负载均衡"></a>zone 内部的负载均衡</h3><p>一个表模式由一个 target 模式和 schema 模式组成。target 模式的编码是 Monarch 用来分片的依据，这减少了写放大，即一次 RPC 可以携带一个 target 和几百个 metric，且这些数据最终最多被送到 3 个叶副本（不是有个 range map 吗，如果刚好在边界呢？）。这样的分配有利于查询操作的下推。</p><p>一些细节：</p><ul><li>副本数（1-3）可自由配置。</li><li>通常，Monarch zone 包含多个故障域（集群）中的叶子；分配者会将范围的副本分配到不同的故障域。</li><li>范围分配管理器会根据 CPU 负载，内存使用量等变量来对不同的 Range 进行分裂或合并。</li><li>迁移时新节点利用恢复日志来重新构建数据，此外迁移过程中是新旧双写的，这样就不影响上层应用的可用性。</li></ul><h3 id="收集聚合"><a href="#收集聚合" class="headerlink" title="收集聚合"></a>收集聚合</h3><p>在有些监控场景下，用户只想知道整个人或某个集群的某个监控信息一段时间内的统计值而不是每个值。<br><img src="/monarch/collection_aggregation.png" srcset="/img/loading.gif" lazyload alt></p><p>Monarch 利用分组连续聚合的方式收集数据并抛弃过时的数据，还用了 TrueTime 大杀器来确保时间分组的正确，实现了实时收集聚合。</p><h2 id="可扩展查询"><a href="#可扩展查询" class="headerlink" title="可扩展查询"></a>可扩展查询</h2><p>为了查询时间序列数据，Monarch 提供了一种由分布式引擎支持的表达语言，该分布式引擎使用静态不变量和新的索引来本地化查询执行。</p><h3 id="查询语言"><a href="#查询语言" class="headerlink" title="查询语言"></a>查询语言</h3><p><img src="/monarch/query_language.png" srcset="/img/loading.gif" lazyload alt><br>听他吹的很牛逼就完事了。类似于 SQL，表达能力比较强吧。</p><h3 id="读流程概述"><a href="#读流程概述" class="headerlink" title="读流程概述"></a>读流程概述</h3><p>系统中有两种查询：临时查询和长期查询。前者是系统外的用户偶尔执行的，后者是 Monarch 周期性执行的物化视图，还会被重新写入到 Monarch 中来提高查询效率和报警。</p><p>查询时也会分三层，即先从根混合器分配到 zone 混合器，然后再被分配到叶子中去。当然为了减少读放大，混合器都会向同一级别的索引服务器请教来剪枝（类似于布隆过滤器）。</p><p>Monarch 叶子的不同副本之间不是完全实时一致（最终一致），其会有一个质量参数，查询时混合器会对该时间序列不同 range 的分片挑选其质量最高的副本来读数据。</p><p>Monarch 做了租户隔离，会跟踪每个用户在集群中查询时使用的总内存，并在越界时取消查询，同时也为每个用户分配了公平的 CPU 时间。</p><h3 id="查询下推"><a href="#查询下推" class="headerlink" title="查询下推"></a>查询下推</h3><p>查询下推增加了可评估的查询规模，并减少了查询延迟，原因如下：</p><ul><li>更低级别的评估越多，意味着更稳定和均匀分布的负载。</li><li>在较低级别计算的全部或部分聚合大大减少传输到较高级别节点的数据量。</li></ul><h3 id="提示字段索引"><a href="#提示字段索引" class="headerlink" title="提示字段索引"></a>提示字段索引</h3><p>为了实现高可伸缩性，Monarch 使用存储在索引服务器中的字段提示索引 (FHI) 来限制从父节点向子节点发送查询时放大，方法是跳过不相关的子节点（那些没有向特定查询输入数据的子节点）。一个 FHI 是一个简明的，持续更新的索引时间序列字段值。FHIs 通过分析查询中的字段谓词跳过不相关的子字段，并有效地处理正则表达式谓词，而无需遍历精确的字段值。FHI 工作的区域有数万亿个时间序列键和超过 10000 个叶子，同时保持足够小的大小以存储在内存中。</p><h3 id="可靠查询"><a href="#可靠查询" class="headerlink" title="可靠查询"></a>可靠查询</h3><ul><li>Monarch 的查询能够在文件系统或全局组件失效时继续工作。</li><li>Monarch 时间序列的不同分片之间存在重叠。即适度的冗余存储有助于读性能的提升。</li><li>Monarch 查询时还会有一些回退叶子来防止某些慢叶子对查询的影响。即 zone 混合器会在主叶和回退叶之间并行地继续进行，并从两个中较快的叶中提取和删除响应。</li></ul><h2 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h2><p>由于 Monarch 作为分布式的、多租户的服务运行的特性，需要一个集中的配置管理系统来为用户提供方便的、细粒度的控制，以便在整个系统中对其监视和分布配置进行控制。用户与影响所有 Monarch zone 的单一全局配置视图交互。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><img src="/monarch/evalution.png" srcset="/img/loading.gif" lazyload alt></p><p>数据量很大，增速很快，节点很多，我很牛逼。..</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>目前有许多开源时间序列数据库：Graphite，InfluxDB， OpenTSDB， Prometheus，和 tsdb 是最受欢迎的。它们将数据存储在辅助存储上（本地或分布式存储，如 HBase)；辅助存储的使用使它们在关键监视时的可使用性降低。它们通过类似于 Monarch zone 的水平扩展来支持分布式部署，但是它们缺乏 Monarch 所提供的全局配置管理和查询聚合。</p><h2 id="教训"><a href="#教训" class="headerlink" title="教训"></a>教训</h2><ul><li>时间序列键的字典序分片改进了摄取和查询的可伸缩性，使 Monarch zone 能够扩展到数以万计的叶子。</li><li>基于推的数据收集模式提高了系统的健壮性，同时简化了系统架构。</li><li>系统化的数据模型提高了健壮性和性能。</li><li>系统扩展是一个连续的过程。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Monarch 可以在很大规模下高效可靠地运行，这是由于它将自治 zone 监控子系统通过全局配置和查询平面整合成一个连贯的整体。它采用了一种新颖的、类型丰富的关系时间序列数据模型，允许高效和可伸缩的数据存储，同时为数据分析提供了一种表达性查询语言。为了适应这种大规模，Monarch 在数据收集和查询执行方面使用了各种优化技术。对于数据收集，Monarch 服务器执行区域内负载平衡和收集聚合，以提高可靠性和效率。对于查询执行，Monarch 以分布式、分层的方式执行每个查询，执行积极的过滤和聚合下推以提高性能和吞吐量，并利用紧凑而强大的分布式索引进行高效的数据修剪。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="http://www.vldb.org/pvldb/vol13/p3181-adams.pdf" target="_blank" rel="noopener">论文</a></p><p><a href="https://www.datacouncil.ai/talks/monarch-googles-planet-scale-streaming-monitoring-infrastructure" target="_blank" rel="noopener">PPT</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式存储</tag>
      
      <tag>论文阅读</tag>
      
      <tag>Google</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Raft 博士论文翻译</title>
    <link href="/raft-thesis-translate/"/>
    <url>/raft-thesis-translate/</url>
    
    <content type="html"><![CDATA[<p>参考我的 <a href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn" target="_blank" rel="noopener">Github Repo</a>。</p><p>由于作者能力有限，描述必然会有纰漏，欢迎提交 PR、创建 Issue 进一步交流。</p><p>如果看完之后有所收获，求求给个 Star 以表支持。😊</p>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Raft 算法介绍</title>
    <link href="/raft/"/>
    <url>/raft/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h3><p>共识算法允许一组节点像一个整体一样一起工作，即使其中一些节点出现故障也能够继续工作下去，其正确性主要源于复制状态机的性质：</p><blockquote><p>任何初始状态一样的状态机，如果执行的命令序列一样，则最终达到的状态也一样。如果将此特性应用在多参与者进行协商共识上，可以理解为系统中存在多个具有完全相同的状态机（参与者），这些状态机能最终保持一致的关键就是起始状态完全一致和执行命令序列完全一致。</p></blockquote><p>共识算法常被用来确保每一个节点上的状态机一定都会按相同的顺序执行相同的命令， 并且最终会处于相同的状态。换句话说，可以理解为共识算法就是用来确保每个节点上的日志顺序都是一致的。（不过需要注意的是，只确保“提交给状态机的日志”顺序是一致的，而有些日志项可能只是暂时添加，尚未决定要提交给状态机）。正因为如此，共识算法在构建可容错的大规模分布式系统中扮演着重要的角色。</p><p><img src="/raft/rsm.png" srcset="/img/loading.gif" lazyload alt></p><p>上图就是每个节点的状态机，日志模块，共识模块与客户端交互的过程。</p><p>当然，实际使用系统中的共识算法一般满足以下特性：</p><ul><li>在非拜占庭条件下保证共识的一致性。（非拜占庭条件，指的就是每一个节点都是诚实可信的，每一次信息的传递都是真实的且符合协议要求的，当节点无法满足协议所要求的条件时，就停止服务，节点仅会因为网络延迟或崩溃出现不一致，而不会有节点传递错误的数据或故意捏造假数据。）</li><li>在多数节点存活时，保持可用性。（“多数”永远指的是配置文件中所有节点的多数，而不是存活节点的多数。）</li><li>不依赖于时间，错误的时钟和高延迟只会导致可用性问题，而不会导致一致性问题。</li><li>在多数节点一致后就返回结果，而不会受到个别慢节点的影响。</li></ul><h3 id="Raft-的由来与宗旨"><a href="#Raft-的由来与宗旨" class="headerlink" title="Raft 的由来与宗旨"></a>Raft 的由来与宗旨</h3><p>众所周知，Paxos 是一个非常划时代的共识算法。在 Raft 出现之前的 10 年里，Paxos 几乎统治着共识算法这一领域：因为绝大多数共识算法的实现都是基于 Paxos 或者受其影响，同时 Paxos 也成为了教学领域里讲解共识问题时的示例。</p><p>但是不幸的是，尽管有很多工作都在尝试降低 Paxos 的复杂性，但是它依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。比如 <code>Google Chubby</code> 的论文就提到，因为 Paxos 的描述和现实差距太大，所以最终人们总会实现一套未经证实的类 Paxos 协议。</p><p>基于以上背景，<code>Diego Ongaro</code> 在就读博士期间，深入研究 Paxos 协议后提出了 Raft 协议，旨在提供更为易于理解的共识算法。Raft 的宗旨在于可实践性和可理解性，并且相比 Paxos 几乎没有牺牲多少性能。</p><blockquote><p>趣闻：<a href="https://groups.google.com/forum/#!topic/raft-dev/95rZqptGpmU" target="_blank" rel="noopener">Raft 名字的来源</a>。简而言之，其名字即来自于 <code>R{eliable|plicated|dundant} And Fault-Tolerant</code>， 也来自于这是一艘可以帮助你逃离 Paxos 小岛的救生筏（Raft）。</p></blockquote><h3 id="工业界的实现"><a href="#工业界的实现" class="headerlink" title="工业界的实现"></a>工业界的实现</h3><ul><li><code>tikv</code></li><li><code>consul</code></li><li><code>etcd</code></li><li><code>sofajraft</code></li><li>…</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这一部分会简单介绍 Raft 的一些基本概念。若暂时没看懂并没有关系，后面会一一介绍清楚，带着问题耐心读完此博客即可。</p><h3 id="子问题"><a href="#子问题" class="headerlink" title="子问题"></a>子问题</h3><p>Raft 将共识算法这个难解决的问题分解成了多个易解决，相对独立的子问题，这些问题都会在接下来的章节中进行介绍。</p><ul><li><code>Leader election</code>：选出集群的 leader 来统筹全局。</li><li><code>Log replication</code>：leader 负责从客户端接收请求，并且在集群中扩散同步。</li><li><code>Safety</code>：各节点间状态机的一致性保证。</li></ul><p>在博士论文和实际生产系统中，还有更多可以探讨的模块或细节功能：</p><ul><li><code>Log compaction</code>：压缩日志以节约磁盘空间；加速重启后节点恢复速率；加速新节点 catch up 速率。 </li><li><code>Leader transfer</code>：能够将 leader 禅让另一个 follower，便于平滑的负载均衡。</li><li><code>Pre vote</code>：在竞选开始时先进行一轮预备竞选，若被允许再转变为 candidate，这样有助于防止某些异常节点扰乱整个集群的正常工作。</li><li><code>Membership change</code>：集群动态增删节点。</li><li><code>Client interaction</code>：客户端交互。</li><li><code>Linearizable read</code>：线性一致性读。</li><li><code>Optimization</code>：业界常见优化。</li><li>…</li></ul><h3 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h3><p>Raft 将所有节点分为三个身份：</p><ul><li><code>Leader</code>：集群内最多只会有一个 leader，负责发起心跳，响应客户端，创建日志，同步日志。</li><li><code>Candidate</code>：leader 选举过程中的临时角色，由 follower 转化而来，发起投票参与竞选。</li><li><code>Follower</code>：接受 leader 的心跳和日志同步数据，投票给 candidate。</li></ul><p><img src="/raft/state.png" srcset="/img/loading.gif" lazyload alt></p><p>上图可以看出 Raft 中节点状态之间变迁的条件。</p><p>在博士论文和实际生产系统中，其实又增加了两种身份：</p><ul><li><code>Learner</code>：不具有选举权，参与日志复制过程但不计数的节点。可以作为新节点加入集群时的过渡状态以提升可用性，也可以作为一种类似于 binlog 的对 leader 日志流进行订阅的角色，比如可以参考 PingCAP 公司 tikv 和 tiflash 的架构。</li><li><code>Pre candidate</code>：刚刚发起竞选，还在等待 <code>Pre-Vote</code> 结果的临时状态， 取决于 <code>Pre-Vote</code> 的结果，可能进化为 candidate，可能退化为 follower。</li></ul><h3 id="节点状态"><a href="#节点状态" class="headerlink" title="节点状态"></a>节点状态</h3><p>每一个节点都应该有的持久化状态：</p><ul><li><code>currentTerm</code>：当前任期，保证重启后任期不丢失。</li><li><code>votedFor</code>：在当前 term，给哪个节点投了票，值为 null 或 <code>candidate id</code>。即使节点重启，Raft 算法也能保证每个任期最多只有一个 leader。</li><li><code>log[]</code>：已经 committed 的日志，保证状态机可恢复。</li></ul><p>每一个节点都应该有的非持久化状态：</p><ul><li><code>commitindex</code>：已提交的最大 index。leader 节点重启后可以通过 appendEntries rpc 逐渐得到不同节点的 matchIndex，从而确认 commitIndex，follower 只需等待 leader 传递过来的 commitIndex 即可。</li><li><code>lastApplied</code>：已被状态机应用的最大 index。raft 算法假设了状态机本身是易失的，所以重启后状态机的状态可以通过 log[] （部分 log 可以压缩为 snapshot) 来恢复。</li></ul><p>leader 的非持久化状态：</p><ul><li><code>nextindex[]</code>：为每一个 follower 保存的，应该发送的下一份 <code>entry index</code>；初始化为本地 last index + 1。</li><li><code>matchindex[]</code>：已确认的，已经同步到每一个 follower 的 <code>entry index</code>。初始化为 0，根据复制状态不断递增，<br>（注：每次选举后，leader 的此两个数组都应该立刻重新初始化并开始探测）</li></ul><h3 id="任期"><a href="#任期" class="headerlink" title="任期"></a>任期</h3><p><img src="/raft/term.png" srcset="/img/loading.gif" lazyload alt></p><p>Raft 将时间划分成为任意不同长度的 term。term 用连续的数字进行表示。每一个 term 的开始都是一次选举，一个或多个 candidate 会试图成为 leader。如果一个  candidate 赢得了选举，它就会在该 term 担任 leader。在某些情况下，选票会被均分，即 <code>split vote</code>（例如总数为偶数节点时两个 candidate 节点各获得了两票），此时无法选出该 term 的 leader，那么在该 term 的选举超时后将会开始另一个 term 的选举。</p><p>不同的服务器节点可能多次观察到 term 之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个 term 全程。term 在 Raft 算法中充当逻辑时钟（类似于 Lamport timestamp）的作用，这会允许服务器节点查明一些过期的信息比如过期的 leader。</p><p>每个节点都会存储当前 term 号，这一编号在整个时间内单调增长。当服务器之间通信的时候会交换当前 term 号；如果一个服务器的当前 term 号比其他人小，那么他会更新自己的 term 到较大的 term 值。如果一个 candidate 或者 leader 发现自己的 term 过期了，那么他会立即退回 follower。如果一个节点接收到一个包含过期 term 号的请求，那么它会拒绝或忽略这个请求。这实际上就是一个 Lamport 逻辑时钟的具体实现。</p><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><ul><li><p><code>entry</code>：Raft 中，将每一个事件都称为一个 entry，每一个 entry 都有一个表明它在 log 中位置的 index（之所以从 1 开始是为了方便 <code>prevLogIndex</code> 从 0 开始）。只有 leader 可以创建 entry。entry 的内容为 <code>&lt;term, index, cmd&gt;</code>，其中 cmd 是可以应用到状态机的操作。在 raft 组大部分节点都接收这条 entry 后，entry 可以被称为是 committed 的。</p></li><li><p><code>log</code>：由 entry 构成的数组，只有 leader 可以改变其他节点的 log。 entry 总是先被 leader 添加进本地的 log 数组中去，然后才发起共识请求，获得 quorum 同意后才会被 leader 提交给状态机。follower 只能从 leader 获取新日志和当前的 commitIndex，然后应用对应的 entry 到自己的状态机。</p></li></ul><h3 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h3><ul><li><code>Election Safety</code>：每个 term 最多只会有一个 leader；集群同时最多只会有一个可以读写的 leader。</li><li><code>Leader Append-Only</code>：leader 的日志是只增的。</li><li><code>Log Matching</code>：如果两个节点的日志中有两个 entry 有相同的 index 和 term，那么它们就是相同的 entry。</li><li><code>Leader Completeness</code>：一旦一个操作被提交了，那么在之后的 term 中，该操作都会存在于日志中。</li><li><code>State Machine Safety</code>：一致性，一旦一个节点应用了某个 index 的 entry 到状态机，那么其他所有节点应用的该 index 的操作都是一致的。</li></ul><h2 id="领导人选举"><a href="#领导人选举" class="headerlink" title="领导人选举"></a>领导人选举</h2><p>Raft 使用心跳来维持 leader 身份。任何节点都以 follower 的身份启动。 leader 会定期的发送心跳给所有的 follower 以确保自己的身份。 每当 follower 收到心跳后，就刷新自己的 electionElapsed，重新计时。</p><p>（后文中，会将预设的选举超时称为 electionTimeout，而将当前经过的选举耗时称为 electionElapsed）</p><p>一旦一个 follower 在指定的时间内没有收到任何 RPC（称为 electionTimeout），则会发起一次选举。 当 follower 试图发起选举后，其身份转变为 candidate，在增加自己的 term 后， 会向所有节点发起 RequestVoteRPC 请求，candidate 的状态会一直持续直到：</p><ul><li>赢得选举</li><li>其他节点赢得选举</li><li>一轮选举结束，无人胜出</li></ul><p>选举的方式非常简单，谁能获取到多数选票 <code>(N/2 + 1)</code>，谁就成为 leader。 在一个 candidate 节点等待投票响应的时候，它有可能会收到其他节点声明自己是 leader 的心跳， 此时有两种情况：</p><ul><li>该请求的 term 和自己一样或更大：说明对方已经成为 leader，自己立刻退为 follower。</li><li>该请求的 term 小于自己：拒绝请求并返回当前 term 以让请求节点更新 term。</li></ul><p>为了防止在同一时间有太多的 follower 转变为 candidate 导致无法选出绝对多数， Raft 采用了随机选举超时（<code>randomized election timeouts</code>）的机制， 每一个 candidate 在发起选举后，都会随机化一个新的选举超时时间， 一旦超时后仍然没有完成选举，则增加自己的 term，然后发起新一轮选举。 在这种情况下，应该能在较短的时间内确认出 leader。 （因为 term 较大的有更大的概率压倒其他节点）</p><p>etcd 中将随机选举超时设置为 <code>[electiontimeout, 2 * electiontimeout - 1]</code>。</p><p>通过一个节点在一个 term 只能给一个节点投票，Raft 保证了对于给定的一个 term 最多只有一个 leader，从而避免了选举导致的 <code>split brain</code> 以确保 safety；通过不同节点每次随机化选举超时时间，Raft 在实践中（注意：并没有在理论上）避免了活锁以确保 liveness。</p><p>以下是 6.824 lab2 中选举相关逻辑的具体实现，以供参考。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs GO"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">RequestVote</span><span class="hljs-params">(request *RequestVoteRequest, response *RequestVoteResponse)</span></span> &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">defer</span> rf.persist()<br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">"&#123;Node %v&#125;'s state is &#123;state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v&#125; before processing requestVoteRequest %v and reply requestVoteResponse %v"</span>, rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), request, response)<br><br><span class="hljs-keyword">if</span> request.Term &lt; rf.currentTerm || (request.Term == rf.currentTerm &amp;&amp; rf.votedFor != <span class="hljs-number">-1</span> &amp;&amp; rf.votedFor != request.CandidateId) &#123;<br>response.Term, response.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-keyword">if</span> request.Term &gt; rf.currentTerm &#123;<br>rf.ChangeState(StateFollower)<br>rf.currentTerm, rf.votedFor = request.Term, <span class="hljs-number">-1</span><br>&#125;<br><span class="hljs-keyword">if</span> !rf.isLogUpToDate(request.LastLogTerm, request.LastLogIndex) &#123;<br>response.Term, response.VoteGranted = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br>rf.votedFor = request.CandidateId<br>rf.electionTimer.Reset(RandomizedElectionTimeout())<br>response.Term, response.VoteGranted = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">StartElection</span><span class="hljs-params">()</span></span> &#123;<br>request := rf.genRequestVoteRequest()<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; starts election with RequestVoteRequest %v"</span>, rf.me, request)<br><span class="hljs-comment">// use Closure</span><br>grantedVotes := <span class="hljs-number">1</span><br>rf.votedFor = rf.me<br>rf.persist()<br><span class="hljs-keyword">for</span> peer := <span class="hljs-keyword">range</span> rf.peers &#123;<br><span class="hljs-keyword">if</span> peer == rf.me &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(peer <span class="hljs-keyword">int</span>)</span></span> &#123;<br>response := <span class="hljs-built_in">new</span>(RequestVoteResponse)<br><span class="hljs-keyword">if</span> rf.sendRequestVote(peer, request, response) &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; receives RequestVoteResponse %v from &#123;Node %v&#125; after sending RequestVoteRequest %v in term %v"</span>, rf.me, response, peer, request, rf.currentTerm)<br><span class="hljs-keyword">if</span> rf.currentTerm == request.Term &amp;&amp; rf.state == StateCandidate &#123;<br><span class="hljs-keyword">if</span> response.VoteGranted &#123;<br>grantedVotes += <span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> grantedVotes &gt; <span class="hljs-built_in">len</span>(rf.peers)/<span class="hljs-number">2</span> &#123;<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; receives majority votes in term %v"</span>, rf.me, rf.currentTerm)<br>rf.ChangeState(StateLeader)<br>rf.BroadcastHeartbeat(<span class="hljs-literal">true</span>)<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> response.Term &gt; rf.currentTerm &#123;<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; finds a new leader &#123;Node %v&#125; with term %v and steps down in term %v"</span>, rf.me, peer, response.Term, rf.currentTerm)<br>rf.ChangeState(StateFollower)<br>rf.currentTerm, rf.votedFor = response.Term, <span class="hljs-number">-1</span><br>rf.persist()<br>&#125;<br>&#125;<br>&#125;<br>&#125;(peer)<br>&#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="日志同步"><a href="#日志同步" class="headerlink" title="日志同步"></a>日志同步</h2><p>leader 被选举后，则负责所有的客户端请求。每一个客户端请求都包含一个命令，该命令可以被作用到 RSM。</p><p>leader 收到客户端请求后，会生成一个 entry，包含 <code>&lt;index, term, cmd&gt;</code>，再将这个 entry 添加到自己的日志末尾后，向所有的节点广播该 entry。</p><p>follower 如果同意接受该 entry，则在将 entry 添加到自己的日志后，返回同意。</p><p>如果 leader 收到了多数的成功答复，则将该 entry 应用到自己的 RSM， 之后可以称该 entry 是 committed 的。该 committed 信息会随着随后的 AppendEntries 或 Heartbeat RPC 被传达到其他节点。</p><p><img src="/raft/log.png" srcset="/img/loading.gif" lazyload alt></p><p>Raft 保证下列两个性质：</p><ul><li>如果在两个日志（节点）里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd；</li><li>如果在两个日志（节点）里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同。</li></ul><p>通过”仅有 leader 可以生成 entry”来确保第一个性质， 第二个性质则通过一致性检查（consistency check）来保证，该检查包含几个步骤：</p><p>leader 在通过 AppendEntriesRPC 和 follower 通讯时，会带上上一块 entry 的信息， 而 follower 在收到后会对比自己的日志，如果发现这个 entry 的信息（index、term）和自己日志内的不符合，则会拒绝该请求。一旦 leader 发现有 follower 拒绝了请求，则会与该 follower 再进行一轮一致性检查， 找到双方最大的共识点，然后用 leader 的 entries 记录覆盖 follower 所有在最大共识点之后的数据。</p><p>寻找共识点时，leader 还是通过 AppendEntriesRPC 和 follower 进行一致性检查， 方法是发送再上一块的 entry， 如果 follower 依然拒绝，则 leader 再尝试发送更前面的一块，直到找到双方的共识点。 因为分歧发生的概率较低，而且一般很快能够得到纠正，所以这里的逐块确认一般不会造成性能问题。当然，在这里进行二分查找或者某些规则的查找可能也能够在理论上得到收益。</p><p>每个 leader 都会为每一个 follower 保存一个 nextIndex 的变量， 标志了下一个需要发送给该 follower 的 entry 的 index。 在 leader 刚当选时，该值初始化为该 leader 的 log 的 index+1。 一旦 follower 拒绝了 entry，则 leader 会执行 nextIndex—，然后再次发送。直到 follower 接收后将 matchIndex 设置为此时的 nextIndex - 1，然后开始正常的复制。这里还可以做一些更细粒度的优化，比如在正常复制时可以批量复制日志以减少系统调用的开销；在寻找共识点时可以只携带一条日志以减少不必要的流量传输，具体可以参考 etcd 的 <a href="https://github.com/etcd-io/etcd/blob/main/raft/tracker/state.go" target="_blank" rel="noopener">设计</a>。</p><p>以下是 6.824 lab2 中 日志同步相关逻辑的具体实现，以供参考。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">replicateOneRound</span><span class="hljs-params">(peer <span class="hljs-keyword">int</span>)</span></span> &#123;<br>rf.mu.RLock()<br><span class="hljs-keyword">if</span> rf.state != StateLeader &#123;<br>rf.mu.RUnlock()<br><span class="hljs-keyword">return</span><br>&#125;<br>prevLogIndex := rf.nextIndex[peer] - <span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> prevLogIndex &lt; rf.getFirstLog().Index &#123;<br><span class="hljs-comment">// only snapshot can catch up</span><br>request := rf.genInstallSnapshotRequest()<br>rf.mu.RUnlock()<br>response := <span class="hljs-built_in">new</span>(InstallSnapshotResponse)<br><span class="hljs-keyword">if</span> rf.sendInstallSnapshot(peer, request, response) &#123;<br>rf.mu.Lock()<br>rf.handleInstallSnapshotResponse(peer, request, response)<br>rf.mu.Unlock()<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// just entries can catch up</span><br>request := rf.genAppendEntriesRequest(prevLogIndex)<br>rf.mu.RUnlock()<br>response := <span class="hljs-built_in">new</span>(AppendEntriesResponse)<br><span class="hljs-keyword">if</span> rf.sendAppendEntries(peer, request, response) &#123;<br>rf.mu.Lock()<br>rf.handleAppendEntriesResponse(peer, request, response)<br>rf.mu.Unlock()<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">AppendEntries</span><span class="hljs-params">(request *AppendEntriesRequest, response *AppendEntriesResponse)</span></span> &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">defer</span> rf.persist()<br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">"&#123;Node %v&#125;'s state is &#123;state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v&#125; before processing AppendEntriesRequest %v and reply AppendEntriesResponse %v"</span>, rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), request, response)<br><br><span class="hljs-keyword">if</span> request.Term &lt; rf.currentTerm &#123;<br>response.Term, response.Success = rf.currentTerm, <span class="hljs-literal">false</span><br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">if</span> request.Term &gt; rf.currentTerm &#123;<br>rf.currentTerm, rf.votedFor = request.Term, <span class="hljs-number">-1</span><br>&#125;<br><br>rf.ChangeState(StateFollower)<br>rf.electionTimer.Reset(RandomizedElectionTimeout())<br><br><span class="hljs-keyword">if</span> request.PrevLogIndex &lt; rf.getFirstLog().Index &#123;<br>response.Term, response.Success = <span class="hljs-number">0</span>, <span class="hljs-literal">false</span><br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; receives unexpected AppendEntriesRequest %v from &#123;Node %v&#125; because prevLogIndex %v &lt; firstLogIndex %v"</span>, rf.me, request, request.LeaderId, request.PrevLogIndex, rf.getFirstLog().Index)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">if</span> !rf.matchLog(request.PrevLogTerm, request.PrevLogIndex) &#123;<br>response.Term, response.Success = rf.currentTerm, <span class="hljs-literal">false</span><br>lastIndex := rf.getLastLog().Index<br><span class="hljs-keyword">if</span> lastIndex &lt; request.PrevLogIndex &#123;<br>response.ConflictTerm, response.ConflictIndex = <span class="hljs-number">-1</span>, lastIndex+<span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>firstIndex := rf.getFirstLog().Index<br>response.ConflictTerm = rf.logs[request.PrevLogIndex-firstIndex].Term<br>index := request.PrevLogIndex - <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> index &gt;= firstIndex &amp;&amp; rf.logs[index-firstIndex].Term == response.ConflictTerm &#123;<br>index--<br>&#125;<br>response.ConflictIndex = index<br>&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>firstIndex := rf.getFirstLog().Index<br><span class="hljs-keyword">for</span> index, entry := <span class="hljs-keyword">range</span> request.Entries &#123;<br><span class="hljs-keyword">if</span> entry.Index-firstIndex &gt;= <span class="hljs-built_in">len</span>(rf.logs) || rf.logs[entry.Index-firstIndex].Term != entry.Term &#123;<br>rf.logs = shrinkEntriesArray(<span class="hljs-built_in">append</span>(rf.logs[:entry.Index-firstIndex], request.Entries[index:]...))<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br><br>rf.advanceCommitIndexForFollower(request.LeaderCommit)<br><br>response.Term, response.Success = rf.currentTerm, <span class="hljs-literal">true</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><h3 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h3><p>因为 leader 的强势地位，所以 Raft 在投票阶段就确保选举出的 leader 一定包含了整个集群中目前已 committed 的所有日志。</p><p>当 candidate 发送 RequestVoteRPC 时，会带上最后一个 entry 的信息。 所有的节点收到该请求后，都会比对自己的日志，如果发现自己的日志更新一些，则会拒绝投票给该 candidate。 （Pre-Vote 同理，如果 follower 认为 Pre-Candidate 没有资格的话，会拒绝 PreVote）</p><p>判断日志新旧的方式：获取请求的 entry 后，比对自己日志中的最后一个 entry。 首先比对 term，如果自己的 term 更大，则拒绝请求。 如果 term 一样，则比对 index，如果自己的 index 更大（说明自己的日志更长），则拒绝请求。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs GO"><span class="hljs-comment">// used by RequestVote Handler to judge which log is newer</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">isLogUpToDate</span><span class="hljs-params">(term, index <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">bool</span></span> &#123;<br>lastLog := rf.getLastLog()<br><span class="hljs-keyword">return</span> term &gt; lastLog.Term || (term == lastLog.Term &amp;&amp; index &gt;= lastLog.Index)<br>&#125;<br></code></pre></div></td></tr></table></figure><p><img src="/raft/leader_restriction.png" srcset="/img/loading.gif" lazyload alt></p><p>在上图中，raft 为了避免出现一致性问题，要求 leader 绝不会提交过去的 term 的 entry （即使该 entry 已经被复制到了多数节点上）。leader 永远只提交当前 term 的 entry， 过去的 entry 只会随着当前的 entry 被一并提交。（上图中的 c，term2 只会跟随 term4 被提交。）</p><p>如果一个 candidate 能取得多数同意，说明它的日志已经是多数节点中最完备的， 那么也就可以认为该 candidate 已经包含了整个集群的所有 committed entries。</p><p>因此 leader 当选后，应当立刻发起 AppendEntriesRPC 提交一个 no-op entry。注意，这是一个 <code>Must</code>，不是一个 <code>Should</code>，否则会有许多 corner case 存在问题。比如：</p><ul><li>读请求：leader 此时的状态机可能并不是最新的，若服务读请求可能会违反线性一致性，即出现 safety 的问题；若不服务读请求则可能会有 liveness 的问题。</li><li>配置变更：可能会导致数据丢失，具体原因和例子可以参考此 <a href="https://zhuanlan.zhihu.com/p/359206808" target="_blank" rel="noopener">博客</a>。</li></ul><p>实际上，leader 当选后提交一个 no-op entry 日志的做法就是 Raft 算法解决 “幽灵复现” 问题的解法，感兴趣的可以看看此 <a href="https://mp.weixin.qq.com/s/jzx05Q781ytMXrZ2wrm2Vg" target="_blank" rel="noopener">博客</a>。</p><h3 id="节点崩溃"><a href="#节点崩溃" class="headerlink" title="节点崩溃"></a>节点崩溃</h3><p>如果 leader 崩溃，集群中的所有节点在 electionTimeout 时间内没有收到 leader 的心跳信息就会触发新一轮的选主。总而言之，最终集群总会选出唯一的 leader 。按论文中的说法，计算一次 RPC 耗时高达 <code>30～40ms</code> 时，<code>99.9%</code> 的选举依然可以在 <code>3s</code> 内完成，但一般一个机房内一次 RPC 只需 1ms。当然，选主期间整个集群对外是不可用的。 </p><p>如果 follower 和 candidate 奔溃相对而言就简单很多， 因为 Raft 所有的 RPC 都是幂等的，所以 Raft 中所有的请求，只要超时，就会无限的重试。follower 和 candidate 崩溃恢复后，可以收到新的请求，然后按照上面谈论过的追加或拒绝 entry 的方式处理请求。</p><h3 id="时间与可用性"><a href="#时间与可用性" class="headerlink" title="时间与可用性"></a>时间与可用性</h3><p>Raft 原则上可以在绝大部分延迟情况下保证一致性， 不过为了保证选择和 leader 的正常工作，最好能满足下列时间条件：</p><figure class="highlight armasm"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs armasm"><span class="hljs-keyword">broadcastTime </span>&lt;&lt; electionTimeout &lt;&lt; MTBF<br></code></pre></div></td></tr></table></figure><ul><li><code>broadcastTime</code>：向其他节点并发发送消息的平均响应时间；</li><li><code>electionTimeout</code>：follower 判定 leader 已经故障的时间（heartbeat 的最长容忍间隔）；</li><li><code>MTBF(mean time between failures)</code>：单台机器的平均健康时间；</li></ul><p>一般来说，broadcastTime 一般为 <code>0.5～20ms</code>，electionTimeout 可以设置为 <code>10～500ms</code>，MTBF 一般为一两个月。</p><h2 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h2><p>Raft 的日志在正常运行期间会增长以合并更多的客户请求，但是在实际的系统中，Raft 的日志无法不受限制地增长。随着日志的增长，日志会占用更多空间，并且需要花费更多时间进行重放。如果没有某种机制可以丢弃日志中累积的过时信息，这最终将导致可用性问题。因此需要定时去做 snapshot。</p><p>snapshot 会包括：</p><ul><li>状态机当前的状态。</li><li>状态机最后一条应用的 entry 对应的 index 和 term。</li><li>集群最新配置信息。</li><li>为了保证 exactly-once 线性化语义的去重表（之后会介绍到）。</li></ul><p>各个节点自行择机完成自己的 snapshot 即可，如果 leader 发现需要发给某一个 follower 的 nextIndex 已经被做成了 snapshot，则需要将 snapshot 发送给该 follower。注意 follower 拿到非过期的 snapshot 之后直接覆盖本地所有状态即可，不需要留有部分 entry，也不会出现 snapshot 之后还存在有效的 entry。因此 follower 只需要判断 <code>InstallSnapshot RPC</code> 是否过期即可。过期则直接丢弃，否则直接替换全部状态即可。 </p><p>snapshot 可能会带来两个问题：</p><ol><li><p>做 snapshot 的策略？<br>一般为定时或者定大小，达到阈值即做 snapshot，做完后对状态机和 raft log 进行原子性替换即可。</p></li><li><p>做 snapshot 时是否还可继续提供写请求？<br>一般情况下，做 snapshot 期间需要保证状态机不发生变化，也就是需要保证 snapshot 期间状态机不处理写请求。当然 raft 层依然可以去同步，只是状态机不能变化，即不能 apply 新提交的日志到状态机中而已。要想做的更好，可以对状态机采用 <code>copy-on-write</code> 的复制来不阻塞写请求。</p></li></ol><p>以下是 6.824 lab2 中 日志压缩相关逻辑的具体实现，以供参考。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">Snapshot</span><span class="hljs-params">(index <span class="hljs-keyword">int</span>, snapshot []<span class="hljs-keyword">byte</span>)</span></span> &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br>snapshotIndex := rf.getFirstLog().Index<br><span class="hljs-keyword">if</span> index &lt;= snapshotIndex &#123;<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; rejects replacing log with snapshotIndex %v as current snapshotIndex %v is larger in term %v"</span>, rf.me, index, snapshotIndex, rf.currentTerm)<br><span class="hljs-keyword">return</span><br>&#125;<br>rf.logs = shrinkEntriesArray(rf.logs[index-snapshotIndex:])<br>rf.logs[<span class="hljs-number">0</span>].Command = <span class="hljs-literal">nil</span><br>rf.persister.SaveStateAndSnapshot(rf.encodeState(), snapshot)<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125;'s state is &#123;state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v&#125; after replacing log with snapshotIndex %v as old snapshotIndex %v is smaller"</span>, rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), index, snapshotIndex)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">InstallSnapshot</span><span class="hljs-params">(request *InstallSnapshotRequest, response *InstallSnapshotResponse)</span></span> &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br><span class="hljs-keyword">defer</span> DPrintf(<span class="hljs-string">"&#123;Node %v&#125;'s state is &#123;state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v&#125; before processing InstallSnapshotRequest %v and reply InstallSnapshotResponse %v"</span>, rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), request, response)<br><br>response.Term = rf.currentTerm<br><br><span class="hljs-keyword">if</span> request.Term &lt; rf.currentTerm &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">if</span> request.Term &gt; rf.currentTerm &#123;<br>rf.currentTerm, rf.votedFor = request.Term, <span class="hljs-number">-1</span><br>rf.persist()<br>&#125;<br><br>rf.ChangeState(StateFollower)<br>rf.electionTimer.Reset(RandomizedElectionTimeout())<br><br><span class="hljs-comment">// outdated snapshot</span><br><span class="hljs-keyword">if</span> request.LastIncludedIndex &lt;= rf.commitIndex &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>rf.applyCh &lt;- ApplyMsg&#123;<br>SnapshotValid: <span class="hljs-literal">true</span>,<br>Snapshot:      request.Data,<br>SnapshotTerm:  request.LastIncludedTerm,<br>SnapshotIndex: request.LastIncludedIndex,<br>&#125;<br>&#125;()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">CondInstallSnapshot</span><span class="hljs-params">(lastIncludedTerm <span class="hljs-keyword">int</span>, lastIncludedIndex <span class="hljs-keyword">int</span>, snapshot []<span class="hljs-keyword">byte</span>)</span> <span class="hljs-title">bool</span></span> &#123;<br>rf.mu.Lock()<br><span class="hljs-keyword">defer</span> rf.mu.Unlock()<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; service calls CondInstallSnapshot with lastIncludedTerm %v and lastIncludedIndex %v to check whether snapshot is still valid in term %v"</span>, rf.me, lastIncludedTerm, lastIncludedIndex, rf.currentTerm)<br><br><span class="hljs-comment">// outdated snapshot</span><br><span class="hljs-keyword">if</span> lastIncludedIndex &lt;= rf.commitIndex &#123;<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125; rejects the snapshot which lastIncludedIndex is %v because commitIndex %v is larger"</span>, rf.me, lastIncludedIndex, rf.commitIndex)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><br><span class="hljs-keyword">if</span> lastIncludedIndex &gt; rf.getLastLog().Index &#123;<br>rf.logs = <span class="hljs-built_in">make</span>([]Entry, <span class="hljs-number">1</span>)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>rf.logs = shrinkEntriesArray(rf.logs[lastIncludedIndex-rf.getFirstLog().Index:])<br>rf.logs[<span class="hljs-number">0</span>].Command = <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-comment">// update dummy entry with lastIncludedTerm and lastIncludedIndex</span><br>rf.logs[<span class="hljs-number">0</span>].Term, rf.logs[<span class="hljs-number">0</span>].Index = lastIncludedTerm, lastIncludedIndex<br>rf.lastApplied, rf.commitIndex = lastIncludedIndex, lastIncludedIndex<br><br>rf.persister.SaveStateAndSnapshot(rf.encodeState(), snapshot)<br>DPrintf(<span class="hljs-string">"&#123;Node %v&#125;'s state is &#123;state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v&#125; after accepting the snapshot which lastIncludedTerm is %v, lastIncludedIndex is %v"</span>, rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), lastIncludedTerm, lastIncludedIndex)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="禅让"><a href="#禅让" class="headerlink" title="禅让"></a>禅让</h2><p>有时候，会希望取消当前 leader 的管理权，比如：</p><ul><li>leader 节点因为运维原因需要重启；</li><li>有其他更适合当 leader 的节点；</li></ul><p>直接将 leader 节点停机的话，其他节点会等待 electionTimeout 后进入选举状态， 这期间会集群会停止响应。为了避免这一段不可用的时间，可以采用禅让机制（<code>leadership transfer</code>）。</p><p>禅让的步骤为：</p><ol><li>leader 停止响应客户端请求；</li><li>leader 向 target 节点发起一次日志同步；</li><li>leader 向 target 发起一次 TimeoutNowRPC，target 收到该请求后立刻发起一轮投票。</li></ol><p>etcd 中实现了更多的细节（也有一些改动）：</p><ol><li>leader 先检查禅让对象（leadTransferee）的身份，如果是 follower，直接忽略；</li><li>leader 检查是否有正在进行的禅让，如果有，则中止之前的禅让状态，开始处理最新的请求；</li><li>检查禅让对象是否是自己，如果是，忽略；</li><li>将禅让状态信息计入 leader 的状态，并且重置 electionElapsed（因为禅让应该在 electionTimeout 内完成）；</li><li>检查禅让对象的日志是否是最新的</li><li>如果禅让对象已经是最新，则直接发送 TimeoutNowRPC</li><li>如果不是，则发送 AppendEntriesRPC，待节点响应成功后，再发送 TimeoutNowRPC</li></ol><p>可以看出，在 etcd 中，leader 除了重置 electionElapsed 外，不会改动自己的状态。 既不会停止对客户端的响应，同时还会继续发送心跳。</p><p>因为 target 机器会更新自己的 term，而且率先发起投票，其有很大的概率赢得选举。 需要注意的是，target 发起的 RequestVoteRPC 中的 <code>isLeaderTransfer=true</code>， 以防止被其他节点忽略。</p><p>如果 target 机器没能在一次 electionTimeout 内完成选举，那么 leader 认为本次禅让失败， 立刻恢复响应客户端的请求。（这时可以再次重新发起一次禅让请求）</p><p>在 etcd/raft 中，RequestVoteRPC.context 会被设置为 campaignTransfer, 表明本次投票请求来源于 leader transfer，可以强行打断 follower 的租约发起选举。</p><h2 id="预投票"><a href="#预投票" class="headerlink" title="预投票"></a>预投票</h2><p>一个暂时脱离集群网络的节点，在重新加入集群后会干扰到集群的运行。</p><p>因为当一个节点和集群失去联系后，在等待 electionTimeout 后，它就会增加自己的 term 并发起选举， 因为联系不上其他节点，所以在 electionTimeout 后，它会继续增加自己的 term 并继续发起选举。</p><p>一段时间以后，它的 term 就会显著的高于原集群的 term。如果此后该节点重新和集群恢复了联络， 它的高 term 会导致 leader 立刻退位，并重新举行选举。</p><p>为了避免这一情形，引入了 Pre-Vote 的机制。在该机制下，一个 candidate 必须在获得了多数赞同的情形下， 才会增加自己的 term。一个节点在满足下述条件时，才会赞同一个 candidate：</p><ul><li>该 candidate 的日志足够新；</li><li>当前节点已经和 leader 失联（electionTimeout）。</li></ul><p>也就是说，candidate 会先发起一轮 Pre-Vote，获得多数同意后，更新自己的 term， 再发起一轮 RequestVoteRPC。</p><p>这种情形下，脱离集群的节点，只会不断的发起 Pre-Vote，而不会更新自己的 term。</p><p>在 etcd 的实现中，如果某个节点赞同了某个 candidate， 是不需要更新自己的状态的，它依然可以赞同其他 candidate。 而且，即使收到的 PreVote 的 term 大于自己，也不会更新自己的 term。 也就是说，PreVote 不会改变其他节点的任何状态。</p><p>etcd 中还有一个设计是，当发起 PreVote 的时候，针对的是下一轮的 term， 所以会向所有的节点发送一个 term+1 的 PreVoteReq。</p><figure class="highlight go"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs GO"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *raft)</span> <span class="hljs-title">campaign</span><span class="hljs-params">(t CampaignType)</span></span> &#123;<br><span class="hljs-keyword">var</span> term <span class="hljs-keyword">uint64</span><br><span class="hljs-keyword">var</span> voteMsg pb.MessageType<br><span class="hljs-keyword">if</span> t == campaignPreElection &#123;<br>r.becomePreCandidate()<br>voteMsg = pb.MsgPreVote<br><span class="hljs-comment">// 这里需要注意的是，PreVote 会针对“下一轮 term”发起投票，</span><br><span class="hljs-comment">// 而 Vote 则是针对当前 term</span><br><span class="hljs-comment">// PreVote RPCs are sent for the next term before we've incremented r.Term.</span><br>term = r.Term + <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>r.becomeCandidate()<br>voteMsg = pb.MsgVote<br>term = r.Term<br>&#125;<br>    <br>    <span class="hljs-comment">// ...</span><br>    <br>    <span class="hljs-comment">// 发送投票请求</span><br>    r.send(pb.Message&#123;Term: term, To: id, Type: voteMsg, Index: r.raftLog.lastIndex(), LogTerm: r.raftLog.lastTerm(), Context: ctx&#125;)<br>    <br>    <span class="hljs-comment">// ...</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="配置变更"><a href="#配置变更" class="headerlink" title="配置变更"></a>配置变更</h2><p>raft 的配置变更一般分为两种方式：一次变更一个和一次变更多个，前者实现相对简单（谬误，其实并不简单，感兴趣可以参考该 <a href="https://zhuanlan.zhihu.com/p/342319702" target="_blank" rel="noopener">博客</a>），改动多个节点的配置变更可以被分成多个一次变更一个来执行；后者相对复杂，并且在某些场景下可用性更强，具体可参考 TiDB 5.0 的 <a href="https://mp.weixin.qq.com/s/nLWbEEBBVYuNGde0IbE3XQ" target="_blank" rel="noopener">介绍</a>。</p><p>以下仅会简单介绍两种成员变更方式，具体可以参考 raft 作者博士论文的 <a href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md#4-%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E6%9B%B4%E6%94%B9" target="_blank" rel="noopener">第四章</a> 和 <a href="https://zhuanlan.zhihu.com/p/359206808" target="_blank" rel="noopener">Raft 成员变更的工程实践</a>。</p><h3 id="一次变更一台"><a href="#一次变更一台" class="headerlink" title="一次变更一台"></a>一次变更一台</h3><p>因为在 Raft 算法中，集群中每一个节点都存有整个集群的信息，而集群的成员有可能会发生变更（节点增删、替换节点等）。 Raft 限制一次性只能增／删一个节点，在一次变更结束后，才能继续进行下一次变更。</p><p>如果一次性只变更一个节点，那么只需要简单的要求“在新／旧集群中，都必须取得多数（N/2+1）”， 那么这两个多数中必然会出现交集，这样就可以保证不会因为配置不一致而导致脑裂。</p><p><img src="/raft/singlechange.png" srcset="/img/loading.gif" lazyload alt></p><p>当 leader 收到集群变更的请求后，就会生成一个特殊的 entry 项用来保存配置， 在将配置项添加到 log 后，该配置立刻生效（也就是说任何节点在收到新配置后，就立刻启用新配置）。 然后 leader 将该 entry 扩散至多数节点，成功后则提交该 entry。 一旦一个新配置项被 committed，则视为该次变更已结束，可以继续处理下一次变更了。</p><p>为了保证可用性，需要新增一项规则，节点在响应 RPC 时，不考虑来源节点是否在自己的配置文件之中。 也就是说，即使收到了一个并不在自己配置文件之中的节点发来的 RPC， 也需要正常处理和响应，包括 AppendEntriesRPC 和 RequestVoteRPC。</p><h3 id="一次变更多台"><a href="#一次变更多台" class="headerlink" title="一次变更多台"></a>一次变更多台</h3><p>这种变更方式可以一次性变更多个节点（arbitrary configuration）。</p><p>当集群成员在变更时，为了保证服务的可用性（不发生中断），以及避免因为节点变更导致的一致性问题， Raft 提出了两阶段变更，当接收到新的配置文件后，集群会首先进入 joint consensus 状态， 待新的配置文件提交成功后，再回到普通状态。</p><p>更具体的，joint consensus 指的是包含新／旧配置文件全部节点的中间状态：</p><ul><li>entries 会被复制到新／旧配置文件中的所有节点；</li><li>新／旧配置文件中的任何一个节点都有可能被选为 leader；</li><li>共识（选举或提交）需要同时在新／旧配置文件中分别获取到多数同意（<code>separate majorities</code>）</li></ul><p>（注：<code>separate majorities</code>的意思是需要新／旧集群中的多数都同意。比如如果是从 3 节点切换为全新的 9 节点， 那么要求旧配置中的 2 个节点，和新配置中的 5 个节点都同意，才被认为达成了一次共识）</p><p>所以，在一次配置变更中，一共有三个状态：</p><ul><li><code>C_old</code>：使用旧的配置文件；</li><li><code>C_old,new</code>：同时使用新旧配置文件，也就是新／旧节点的并集；</li><li><code>C_new</code>：使用新的配置文件。</li></ul><p>配置文件使用特殊的 entries 进行存储，一个节点一旦获取到新的配置文件， 即使该配置 entry 并没有 committed，也会立刻使用该配置。 所以一次完整的配置变更可以表示为下图：</p><p><img src="/raft/jointchange.png" srcset="/img/loading.gif" lazyload alt></p><ol><li>C_old,new 被创建，集群进入 joint consensus，leader 开始传播该 entry；</li><li>C_old,new 被 committed，也就是说此时多数节点都拥有了 C_old,new，此后 C_old 已经不再可能被选为 leader；</li><li>leader 创建并传播 C_new；</li><li>C_new 被提交，此后不在 C_new 内的节点不允许被选为 leader，如有 leader 不在 C_new 则自行退位。</li></ol><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>不在 C_new 的节点可能会干扰集群。</p><p>当 C_new 开始生效后，被移除的节点就会收不到 heartbeat，所以在 electionTimeout 后， 这些节点会更新自己的 term 然后开始尝试竞选，这会导致目前的 leader 被迫退回 follower 并启动一轮投票。 这会反复发生，严重影响效率。</p><p>解决办法是，每一个 follower 增加一个机制，当节点处于 minimum election timeout 之内时， 也就是当一个节点认为自己的 leader 依然存活时，将会拒绝 RequestVoteRPC，既不会同意投票， 也不会根据 RequestVoteRPC 更新自己的 term。</p><p>但如果此时集群正好处于选举之中，那么 C_old 集群的节点可能还是会造成干扰， 所以结合 PreVote 更为可靠。</p><p>这一机制会干扰到 leader transfer 机制，因为在 leader transfer 中，即使 electionTimeout 未到， RequestVoteRPC 也应该打断所有的节点，要求立刻开始进行选举。 所以需要给 RequestVoteRPC 增加一个 flag 来表明是否来自于 leader transfer。</p><p>etcd 中也是增加了一个 flag campaignTransfer 来做特殊标记，见上面的「禅让」一节。</p><h2 id="客户端交互"><a href="#客户端交互" class="headerlink" title="客户端交互"></a>客户端交互</h2><p>虽然说 raft 算法只是一个 RSM，其只需要保证不同节点上的日志相同即可，其他的事情它都不需要关心。但是要想保证线性一致性语义，对于基于 raft 的 KV 往往还需要额外做一些事情，比如即使客户端会超时重试，也要保证日志的 exactly-once 执行。</p><p><img src="/raft/client.png" srcset="/img/loading.gif" lazyload alt></p><p>考虑这样一个场景，客户端向服务端提交了一条日志，服务端将其在 raft 组中进行了同步并成功 commit，接着在 apply 后返回给客户端执行结果。然而不幸的是，该 rpc 在传输中发生了丢失，客户端并没有收到写入成功的回复。因此，客户端只能进行重试直到明确地写入成功或失败为止，这就可能会导致相同地命令被执行多次，从而违背线性一致性。</p><p>有人可能认为，只要写请求是幂等的，那重复执行多次也是可以满足线性一致性的，实际上则不然。考虑这样一个例子：对于一个仅支持 put 和 get 接口的 raftKV 系统，其每个请求都具有幂等性。设 x 的初始值为 0，此时有两个并发客户端，客户端 1 执行 put(x,1)，客户端 2 执行 get(x) 再执行 put(x,2)，问（客户端 2 读到的值，x 的最终值）是多少。对于线性一致的系统，答案可以是 (0,1)，(0,2) 或 (1,2)。然而，如果客户端 1 执行 put 请求时发生了上段描述的情况，然后客户端 2 读到 x 的值为 1 并将 x 置为了 2，最后客户端 1 超时重试且再次将 x 置为 1。对于这种场景，答案是 (1,1)，这就违背了线性一致性。归根究底还是由于幂等的 put(x,1) 请求在状态机上执行了两次，有两个 LZ 点。因此，即使写请求的业务语义能够保证幂等，不进行额外的处理让其重复执行多次也会破坏线性一致性。当然，读请求由于不改变系统的状态，重复执行多次是没问题的。</p><p>对于这个问题，raft 作者介绍了想要实现线性化语义，就需要保证日志仅被执行一次，即它可以被 commit 多次，但一定只能 apply 一次。其解决方案原文如下：</p><blockquote><p>The solution is for clients to assign unique serial numbers to every command. Then, the state machine tracks the latest serial number processed for each client, along with the associated response. If it receives a command whose serial number has already been executed, it responds immediately without re-executing the request.</p></blockquote><p>基本思路便是：</p><ul><li>每个 client 都需要一个唯一的标识符，它的每个不同命令需要有一个顺序递增的 commandId，clientId 和这个 commandId，clientId 可以唯一确定一个不同的命令，从而使得各个 raft 节点可以记录保存各命令是否已应用以及应用以后的结果。</li></ul><p>为什么要记录应用的结果？因为通过这种方式同一个命令的多次 apply 最终只会实际应用到状态机上一次，之后相同命令 apply 的时候实际上是不应用到状态机上的而是直接返回的，那么这时候应该返回什么呢？直接返回成功吗？不行，如果第一次应用时状态机报了什么例如 key not exist 等业务上的错而没有被记录，之后就很难捕捉到这个执行结果了，所以也需要将应用结果保存下来。</p><p>如果默认一个客户端只能串行执行请求的话，服务端这边只需要记录一个 map，其 key 是 clientId，其 value 是该 clientId 执行的最后一条日志的 commandId 和状态机的输出即可。</p><p>raft 论文中还考虑了对这个 map 进行一定大小的限制，防止其无线增长。这就带来了两个问题：</p><ul><li>集群间的不同节点如何就某个 clientId 过期达成共识。</li><li>不小心驱逐了活跃的 clientId 怎么办，其之后不论是新建一个 clientId 还是复用之前的 clientId 都可能导致命令的重执行。</li></ul><p>这些问题在工程实现上都较为麻烦。比如后者如果业务上是事务那直接 abort 就行，但如果不是事务就很难办了。</p><p>实际上，个人感觉 clientId 是与 session 绑定的，其生命周期应该与 session 一致，开启 session 时从 map 中保存该 clientId，关闭 session 时从 map 中删除该 clientId 及其对应的 value 即可。map 中一个 clientId 对应的内存占用可能都不足 30 字节，相比携带更多业务语义的 session 其实很小，所以感觉没太大必要去严格控制该 map 的内存占用，还不如考虑下怎么控制 session 更大地内存占用呢。这样就不用去纠结前面提到的两个问题了。</p><p>感兴趣的可以参照 raft 博士论文第六章-<a href="https://github.com/OneSizeFitsQuorum/raft-thesis-zh_cn/blob/master/raft-thesis-zh_cn.md#6-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%A4%E4%BA%92" target="_blank" rel="noopener">客户端交互</a> 和 dragonboat 作者在知乎上对其的 <a href="https://www.zhihu.com/question/278551592" target="_blank" rel="noopener">讨论</a>。</p><h2 id="线性一致性读"><a href="#线性一致性读" class="headerlink" title="线性一致性读"></a>线性一致性读</h2><p>有关 raft 一致性读的实现，可以参考本人写的另一篇 <a href="https://tanxinyu.work/consistency-and-consensus/#etcd-%E7%9A%84-Raft">博客</a>。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>业界的实践很多，可以参考 tikv 的 <a href="https://zhuanlan.zhihu.com/p/25735592" target="_blank" rel="noopener">优化</a> 和 dragonboat 的 <a href="https://zhuanlan.zhihu.com/p/52620657" target="_blank" rel="noopener">优化</a>。</p><p>以下简单列举几种：</p><ul><li>batching：降低 system call 的开销。</li><li>pipeline：提升 leader 向 follower 同步的吞吐量。</li><li>异步 apply：提升 raft 算法吞吐量。无法降低延迟，但能增加吞吐量。</li><li>并行同步日志与刷盘：并行 IO，提升 raft 算法吞吐量。</li><li>…</li></ul><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>所有节点间仅通过三种类型的 RPC 进行通信：</p><ul><li><code>AppendEntriesRPC</code>：最常用的，leader 向 follower 发送心跳或同步日志。</li><li><code>RequestVoteRPC</code>：选举时，candidate 发起的竞选请求。</li><li><code>InstallsnapshotRPC</code>：用于 leader 下发 snapshot。</li></ul><p>在 Diego 后续的博士论文中，又增加了一些 RPCs：</p><ul><li><code>AddServerRPC</code>：添加单台节点。</li><li><code>RemoveServerRPC</code>：移除一个节点。</li><li><code>TimeoutNowRPC</code>：立刻发起竞选。<br>（实际上 etcd 的实现中定义了几十种消息类型，甚至把内部事件也封装为消息一并处理。）</li></ul><h3 id="AppendEntriesRPC"><a href="#AppendEntriesRPC" class="headerlink" title="AppendEntriesRPC"></a>AppendEntriesRPC</h3><p>参数：</p><ul><li><code>term</code>：leader 当前的 term；</li><li><code>leaderId</code>：leader 的 节点 id，让 follower 可以重定向客户端的连接；</li><li><code>prevLogIndex</code>：前一块 entry 的 index；</li><li><code>prevlogterm</code>：前一块 entry 的 term；</li><li><code>entries[]</code>：给 follower 发送的 entry，可以一次发送多个，heartbeat 时该项可缺省；</li><li><code>leaderCommit</code>：leader 当前的 <code>committed index</code>，follower 收到后可用于自己的状态机。</li></ul><p>返回：</p><ul><li><code>term</code>：响应者自己的 term；</li><li><code>success</code>：bool，是否接受请求。<br>该请求通过 leaderCommit 通知 follower 提交相应的 entries 到。通过 entries[] 复制 leader 的日志到所有的 follower。</li></ul><p>实现细节：</p><ol><li>如果 <code>term &lt; currentTerm</code>，立刻返回 false</li><li>如果 prevLogIndex 不匹配，返回 false</li><li>如果自己有块 entry 和新的 entry 不匹配（在相同的 index 上有不同的 term）， 删除自己的那一块以及之后的所有 entry；</li><li>把新的 entries 添加到自己的 log；<br>5 。如果 <code>leaderCommit &gt; commitindex</code>，将 commitIndex 设置为 <code>min(leaderCommit, last index)</code>， 并且提交相应的 entries。</li></ol><h3 id="RequestVoteRPC"><a href="#RequestVoteRPC" class="headerlink" title="RequestVoteRPC"></a>RequestVoteRPC</h3><p>参数：</p><ul><li><code>term</code>：candidate 当前的 term；</li><li><code>candidateId</code>：candidate 的节点 id</li><li><code>lastlogindex</code>：candidate 最后一个 entry 的 index；</li><li><code>lastlogterm</code>：candidate 最后一个 entry 的 term。</li><li><code>isleaderTransfer</code>：用于表明该请求来自于禅让，无需等待 electionTimeout，必须立刻响应。</li><li><code>isPreVote</code>：用来表明当前是 PreVote 还是真实投票</li></ul><p>返回：</p><ul><li><code>term</code>：响应者当前的 term；</li><li><code>voteGranted</code>：bool，是否同意投票。</li></ul><p>实现细节：</p><ol><li>如果 <code>term &lt; currentTerm</code>，返回 false；</li><li>如果 votedFor 为空或者为该 <code>candidated id</code>，且日志项不落后于自己，则同意投票。</li></ol><h3 id="InstallsnapshotRPC"><a href="#InstallsnapshotRPC" class="headerlink" title="InstallsnapshotRPC"></a>InstallsnapshotRPC</h3><p>参数：</p><ul><li><code>term</code>：leader 的 term</li><li><code>leaderId</code>：leader 的 节点 id</li><li><code>lastIncludedindex</code>：snapshot 中最后一块 entry 的 index；</li><li><code>lastIncludedterm</code>：snapshot 中最后一块 entry 的 term；</li><li><code>offset</code>：该份 chunk 的 offset；</li><li><code>data[]</code>：二进制数据；</li><li><code>done</code>：是否是最后一块 chunk</li></ul><p>返回：</p><ul><li><code>term</code>：follower 当前的 term</li></ul><p>实现细节：</p><ol><li>如果 <code>term &lt; currentTerm</code> 就立即回复</li><li>如果是第一个分块（offset 为 0）就创建一个新的快照</li><li>在指定偏移量写入数据</li><li>如果 done 是 false，则继续等待更多的数据</li><li>保存快照文件，丢弃索引值小于快照的日志</li><li>如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保持</li><li>丢弃整个日志</li><li>使用快照重置状态机</li></ol><h3 id="AddServerRPC"><a href="#AddServerRPC" class="headerlink" title="AddServerRPC"></a>AddServerRPC</h3><p>参数：</p><ul><li><code>newServer</code>：新节点地址</li></ul><p>返回：</p><ul><li><code>status</code>：bool，是否添加成功；</li><li><code>leaderHint</code>：当前 leader 的信息。</li></ul><p>实现细节：</p><ol><li>如果节点不是 leader，返回 NOT_LEADER；</li><li>如果没有在 electionTimeout 内处理，则返回 TIMEOUT；</li><li>等待上一次配置变更完成后，再处理当前变更；</li><li>将新的配置项加入 log，然后发起多数共识，通过后再提交；</li><li>返回 OK。</li></ol><h3 id="RemoveServerRPC"><a href="#RemoveServerRPC" class="headerlink" title="RemoveServerRPC"></a>RemoveServerRPC</h3><p>参数：</p><ul><li><code>oldServer</code>：要删除的节点的地址</li></ul><p>返回：</p><ul><li><code>status</code>：bool，是否删除成功；</li><li><code>leaderHint</code>：当前 leader 的信息。</li></ul><p>实现细节：</p><ol><li>如果节点不是 leader，返回 NOT_LEADER；</li><li>等待上一次配置变更完成后，再处理当前变更；</li><li>将新的配置项加入 log，然后发起多数共识，通过后再提交；</li><li>返回 OK。</li></ol><h3 id="TimeoutNowRPC"><a href="#TimeoutNowRPC" class="headerlink" title="TimeoutNowRPC"></a>TimeoutNowRPC</h3><p>由 leader 发起，告知 target 节点立刻发起竞选，无视 electionTimeout。主要用于禅让。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇博客较为详细的介绍了 raft 算法的实现，希望能对读者理解 raft 算法有所帮助。</p><h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="https://raft.github.io/" target="_blank" rel="noopener">raft 官网</a></li><li><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">raft 动画教程</a></li><li><a href="https://raft.github.io/raft.pdf" target="_blank" rel="noopener">raft 会议论文</a></li><li><a href="https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf" target="_blank" rel="noopener">raft 博士论文</a></li><li><a href="https://blog.laisky.com/p/raft/#%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E5%8F%98%E6%9B%B4-ohtdR" target="_blank" rel="noopener">raft 论文笔记</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-raft.txt" target="_blank" rel="noopener">6.824 Raft 讲义 1</a></li><li><a href="http://nil.csail.mit.edu/6.824/2020/notes/l-raft2.txt" target="_blank" rel="noopener">6.824 Raft 讲义 2</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
      <tag>共识算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CAP 定理介绍</title>
    <link href="/cap-theory/"/>
    <url>/cap-theory/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在互联网行业飞速发展的 21 世纪，分布式系统正变得越来越重要，大型互联网公司如 Google，Amazon，MicroSoft，Alibaba，Tencent 等之所以被认为技术很厉害，很大程度上是因为其后台十分强悍，而这些后台一定是由若干个大的分布式系统组成的，因此理解分布式系统的运行原理对于程序员有非常重要的意义。</p><p>CAP 定理是分布式系统方向一个比较宽泛但很重要的基本定理，也可以作为理解分布式系统的起点。</p><p>这篇博客将简单介绍一下 CAP 定理。</p><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>2000 年，柏克莱加州大学（University of California, Berkeley）的计算机科学家 Eric Brewer 在分布式计算原则研讨会（Symposium on Principles of Distributed Computing）提出，分布式系统有三个指标。</p><ul><li>Consistency（可用性）</li><li>Availability（一致性）</li><li>Partition tolerance（网络分区容错性）</li></ul><p>它们的第一个字母分别是 C、A、P。</p><p>理论上，只能从 CAP 三者中选择两者，然而，这种选择的边界并非是非此即彼的（not binary），很多时候混合考虑不同程度的各个因素，结果可能是更好的。（ <code>The whole spectrum in between is useful; mixing different levels of Availability and Consistency usually yields a better result</code>）</p><p>需要注意的是，尽管我们常说某个系统能够满足 CAP 属性中的 2 个，但并不是必须满足 2 个，许多系统只具有 0 或 1 个 CAP 属性。</p><p>此外，很多同学会纠结单机系统到底是 CA 系统还是 CP 系统，个人觉得纠结这个问题没有任何意义，注意 CAP 定律的完整表述：<code>Any networked shared-data system can have at most two of the three desired properties</code>，也就是说 CAP 定理并不针对单机系统做限定，因此将这个不属于单机的概念强加在单机系统上并无意义。</p><h2 id="定义-amp-证明"><a href="#定义-amp-证明" class="headerlink" title="定义 &amp; 证明"></a>定义 &amp; 证明</h2><p>其实 CAP 定理已经被大家讲烂了，网上一搜都会出现很多附带个人解读且不一定正确的博客，我自己之前也写过一版，后面也觉得太烂了。</p><p>幸运的是我找到了一篇 <a href="https://zhuanlan.zhihu.com/p/338835258" target="_blank" rel="noopener">博客</a>，这篇博客的后半部分（ <code>对 CAP 的常见误解</code> 章节， <code>CAP 理论的一些疑问</code> 章节和 <code>CAP 的不足</code> 章节）总结的很清晰中肯，在这里分享给大家，我之前写的垃圾就删了吧。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人认为，CAP 定理的核心在于，在网络分区的情况下，我们需要对 C 和 A 做出相应的妥协，我们不可能完全满足 CA，但是我们可以合理控制 C 和 A 之间的比例让我们的应用/中间件正常提供服务，同时也尽量提升基础设施的稳定性来保障 P。</p><h2 id="附录-1"><a href="#附录-1" class="headerlink" title="附录 1"></a>附录 1</h2><p>《Spanner，真时，CAP 理论》是 Google VP，CAP 理论之父在情人节当天撰写的，主要介绍了 Google 的 Spanner 数据库的真时（TrueTime）服务和 CA 特性，以及结合 CAP 理论的一些思考，建议阅读，阅读 Spanner 论文后阅读更佳。</p><ul><li><p><a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45855.pdf" target="_blank" rel="noopener">《Spanner，真时，CAP 理论》</a></p></li><li><p><a href="https://toutiao.io/posts/zdqrx0/preview" target="_blank" rel="noopener">《Spanner，真时，CAP 理论》中文</a></p></li></ul><h2 id="附录-2"><a href="#附录-2" class="headerlink" title="附录 2"></a>附录 2</h2><p>DDIA 的作者针对 CAP 定理也有一番见地，建议阅读。</p><ul><li><a href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html" target="_blank" rel="noopener">Please stop calling databases CP or AP</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>分布式系统理论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>iTerm2 快捷键介绍</title>
    <link href="/iTerm2-hotkeys/"/>
    <url>/iTerm2-hotkeys/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>iTerm2 是 MacOS 独有的终端工具，其有许多快捷键可以使用。为了便于开发并节约之后再次在搜索引擎上查询的时间成本，特写此博客以供自己日后查看。</p><h2 id="快捷键介绍"><a href="#快捷键介绍" class="headerlink" title="快捷键介绍"></a>快捷键介绍</h2><h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><ul><li>新建标签：Command + T</li><li>关闭标签：Command + W</li><li>切换标签：Command + 数字 或 Command + 左右方向键</li></ul><h3 id="分屏"><a href="#分屏" class="headerlink" title="分屏"></a>分屏</h3><ul><li>垂直分屏：Command + D</li><li>水平分屏：Command + Shift + D</li><li>切换屏幕：Command + Option + 方向键 或 Command + [ / ]</li></ul><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><ul><li>局部搜索（包含单个终端）：Command + F</li><li>全局搜索（包含所有 Tab)：Command + Option + E</li><li>搜索历史指令：Ctrl + R</li></ul><h3 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h3><ul><li>查看历史命令：Command + ;</li><li>查看剪贴板历史：Command + Shift + H</li><li>上一条命令：Ctrl + P 或 上方向键</li></ul><h3 id="单行"><a href="#单行" class="headerlink" title="单行"></a>单行</h3><ul><li>光标到行首：Ctrl + A</li><li>光标到行尾：Ctrl + E</li><li>删除当前行：Ctrl + U</li><li>删除当前光标的字符：Ctrl + D</li><li>删除光标之前的字符：Ctrl + H</li><li>删除光标之前的单词：Ctrl + W</li><li>删除到文本末尾：Ctrl + K</li></ul><h3 id="内容大小"><a href="#内容大小" class="headerlink" title="内容大小"></a>内容大小</h3><ul><li>放大终端：Command + +</li><li>缩小终端：Command + - </li></ul><h3 id="常用快捷功能"><a href="#常用快捷功能" class="headerlink" title="常用快捷功能"></a>常用快捷功能</h3><ul><li>清屏：Command + R 或 Crtl + L</li><li>切换全屏：Command + Enter</li><li>选中即复制：在 iTerm2 界面，选择了一行就已经复制了</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>开发工具配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的高效 Macbook 工作环境配置</title>
    <link href="/mac-configuration/"/>
    <url>/mac-configuration/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>工欲善其事，必先利其器，工具永远都是用来解决问题的，没必要为了工具而工具，一切工具都是为了能快速准确的完成工作和学习任务而服务。</p><p>我呢，在使用了 Windows，Ubuntu 和 MacOS 三种操作系统之后。结合种种体验和踩坑，最终还是觉得 MacOS 更舒适一点。每个人都有每个人的看法，每个人都有每个人的舒适点，MacOS 恰好捏住了我的舒适点。因此，我之后都将从 MacOS 上工作学习。</p><p>前一段时间我从公司实习离职，上交了公司发给我的 MacBook（<del>停止薅羊毛</del>），然而我又不想回到 Windows，于是打算自己买一台 MacBook。但是 MacBook 从 2016 年开始更换的蝶式键盘很让我恶心，姑且不说故障率高，触感实在太差劲了。尽管 2020 年新出的 16 寸 Pro 已经重回剪刀脚键盘了，但是我的需求是轻薄的 13 寸而不是 16 寸（<del>只是没钱而已</del>）。尽管听到业界的呼声说 2020 年的 MacBook 应该都会回到剪刀脚键盘，但由于 2020 年会换新模具，我也不想踩第一代模具的坑，因而暂且将目标定为 2021 年的 MacBook，目前一年多买个二手过渡下就可以了。</p><p>1 月份我在某宝平台上买了一台 2014 款 8+256 的二手 MacBook Pro，即使前期做了许多选店和辨伪的功课，拿到手之后却依然中招，总是无理由黑屏然后再无法开机一天，十分坑爹。所幸可以十五天无理由退换货，就赶快退了。之前早就听说二手 Mac 的水很深，被坑一次之后更加确信。接着我做了更多的功课，学到了许多辨伪技巧，浏览了许多店铺，也算有点心得，之后要是有时间可以写出来分享给大家。</p><p>前几天经过慎重选择我又在某东平台上入手了一台 2015 款 8+128 的二手 MacBook Pro。这次总算没什么问题，但比较有趣的一点是我买的 8+128 的，老板发给我的是 8+256 的，平白无故赚了 128G 的固态，只能说真的舒服了。</p><p><img src="/mac-configuration/mac-configuration.jpeg" srcset="/img/loading.gif" lazyload alt></p><p>这是一个新的 MacBook 刚打开后的主页，接下来我要通过一系列的配置使其成为一个十分符合我开发习惯的机器，可供大家参考。</p><h2 id="系统篇"><a href="#系统篇" class="headerlink" title="系统篇"></a>系统篇</h2><h3 id="触屏板"><a href="#触屏板" class="headerlink" title="触屏板"></a>触屏板</h3><ul><li>2016 年及之后的 MacBook 触屏板都有 Force touch 的功能，即可以按压两次来实现更多的功能，但是我一直用不来这个功能，因此我的第一件事就是调整触摸屏板，首先先关掉 Force touch 的功能，然后开启轻点来点按的点击方式，个人觉得这样才符合 MacBook 轻巧的特性嘛，每次都按下去多麻烦啊，现在手指轻轻一碰触摸板，就达到鼠标单击的顺滑效果。</li><li>除此以外，可以根据自己的习惯开启或关闭一些手势。</li></ul><p><img src="/mac-configuration/touch_1.png" srcset="/img/loading.gif" lazyload alt><br><img src="/mac-configuration/touch_2.png" srcset="/img/loading.gif" lazyload alt><br><img src="/mac-configuration/touch_3.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h3><ul><li>由于 MacBook 默认的重复前延迟和按键重复配置太慢，限制了程序员们优秀的打字速度，所以建议都调整到最快的速度。</li><li>可以在闲置 5 分钟后关闭键盘背光灯来省点电。</li></ul><p><img src="/mac-configuration/keyboard.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="输入法"><a href="#输入法" class="headerlink" title="输入法"></a>输入法</h3><ul><li>由于 MacBook 默认的切换大小写的方式是长按 Caps 键，时间较慢需要等待，较为影响开发效率，建议关闭长按改为短按，配合极低的按键延迟会十分舒爽。</li></ul><p><img src="/mac-configuration/input.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>建议安装搜狗输入法 Mac 版替代系统自带输入法。</li></ul><h3 id="快速锁定屏幕"><a href="#快速锁定屏幕" class="headerlink" title="快速锁定屏幕"></a>快速锁定屏幕</h3><ul><li><p>如果你长时间离开电脑，最好锁定你的屏幕，以防止数据泄露。 那如何快速的锁定你的 MacBook 呢？ 答案是只需要一摸触摸板就可以了。</p><ul><li><p>打开系统偏好设置，点击桌面与屏幕保护程序图标，选择屏幕保护程序这个 Tab，再点击触发角，在弹出的如下界面里面，右下角选择将显示器置入睡眠状态，再确定即可。</p><p><img src="/mac-configuration/screen_saver.png" srcset="/img/loading.gif" lazyload alt></p></li><li><p>再打开系统偏好设置，点击安全性与隐私图标，在通用 Tab 内，勾选为进入睡眠或开始屏幕保护程序<strong>立即</strong>要求输入密码。</p><p><img src="/mac-configuration/screen_security.png" srcset="/img/loading.gif" lazyload alt></p></li></ul></li></ul><h2 id="开发环境篇"><a href="#开发环境篇" class="headerlink" title="开发环境篇"></a>开发环境篇</h2><h3 id="Xcode"><a href="#Xcode" class="headerlink" title="Xcode"></a>Xcode</h3><ul><li><p>首先安装 Xcode，然后使用下面的命令安装 Xcode command line tools，这将为我们安装很多终端下面常用的命令，将来很可能会使用到。</p>  <figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Shell">xcode-select --install<br></code></pre></div></td></tr></table></figure></li></ul><h3 id="Homebrew"><a href="#Homebrew" class="headerlink" title="Homebrew"></a>Homebrew</h3><ul><li><p>Homebrew 是一款终端下的命令程序包管理器，安装非常简单，复制如下命令在终端下运行，按回车并输入密码后等待安装成功：</p>  <figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Shell">/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"<br></code></pre></div></td></tr></table></figure></li></ul><h3 id="iTerm2-Zsh-Z"><a href="#iTerm2-Zsh-Z" class="headerlink" title="iTerm2 + Zsh + Z"></a>iTerm2 + Zsh + Z</h3><ul><li>常用终端 iTerm2 + 优秀 Shell Zsh + 扁平目录跳转命令 Z，安装好之后开发十分舒适。具体安装可参考这个 <a href="https://www.zcfy.cc/article/become-a-command-line-power-user-with-oh-my-zsh-and-z" target="_blank" rel="noopener">博客</a>。</li></ul><h3 id="快捷键迅速打开-iTerm2"><a href="#快捷键迅速打开-iTerm2" class="headerlink" title="快捷键迅速打开 iTerm2"></a>快捷键迅速打开 iTerm2</h3><ul><li>可以设置快捷键再 Home 页面输入 Command + , 直接打开 iTerm2，这样就不用再去点击 iTerm2 了。</li></ul><p><img src="/mac-configuration/iTerm2_hotkey.png" srcset="/img/loading.gif" lazyload alt></p><ul><li>可以设置 iTerm2 默认占满全屏，这样子快捷键打开之后就直接是一个全屏的 iTerm2 可以使用了</li></ul><p><img src="/mac-configuration/iTerm2_screen.png" srcset="/img/loading.gif" lazyload alt> </p><h3 id="VScode-命令行迅速打开"><a href="#VScode-命令行迅速打开" class="headerlink" title="VScode 命令行迅速打开"></a>VScode 命令行迅速打开</h3><ul><li>打开 VScode 后输入 Command + Shift + P 打开命令面板，再输入 code，再确定</li></ul><p><img src="/mac-configuration/vscode_code.png" srcset="/img/loading.gif" lazyload alt></p><h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><ul><li>创建新的公钥私钥并与自己的 Github 账户连起来，这样就可以开始在 Github 遨游啦。</li></ul><h3 id="Alfred"><a href="#Alfred" class="headerlink" title="Alfred"></a>Alfred</h3><ul><li>安装 macOS 提升效率神器 Alfred，具体用法可以参考 <a href="https://juejin.cn/post/6844904062484217863" target="_blank" rel="noopener">博客</a>。</li></ul><h2 id="常用软件"><a href="#常用软件" class="headerlink" title="常用软件"></a>常用软件</h2><ul><li>网易云音乐</li><li>微信</li><li>QQ</li><li>腾讯会议</li><li>V2Ray</li><li>Chrome</li><li>VScode</li><li>GoLand</li><li>IDEA</li><li>JProfile</li><li>Docker</li><li>…</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>开发工具配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
